{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Codes\\datasets\\190829_Kanshan_zjfx\n"
     ]
    }
   ],
   "source": [
    "cd ../../../datasets/190829_Kanshan_zjfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 F 中的卷是 存储\n",
      " 卷的序列号是 C14D-581B\n",
      "\n",
      " F:\\Codes\\datasets\\190829_Kanshan_zjfx 的目录\n",
      "\n",
      "2019/11/19  08:48    <DIR>          .\n",
      "2019/11/19  08:48    <DIR>          ..\n",
      "2019/09/26  19:08     5,805,965,112 answer_info_0926.txt\n",
      "2019/11/08  14:33               188 assert.py\n",
      "2019/09/26  18:10       333,836,065 invite_info_0926.txt\n",
      "2019/09/28  12:14        37,860,903 invite_info_evaluate_1_0926.txt\n",
      "2019/09/26  17:12       552,574,982 member_info_0926.txt\n",
      "2019/11/08  21:28     1,144,346,559 question_info_0926.sql\n",
      "2019/09/26  18:01     1,074,273,891 question_info_0926.txt\n",
      "2019/10/18  16:35    <DIR>          sample\n",
      "2019/08/05  17:19        15,951,125 single_word_vectors_64d.txt\n",
      "2019/08/05  17:20        69,411,196 topic_vectors_64d.txt\n",
      "2019/11/18  18:20     4,006,275,165 train.csv\n",
      "2019/11/18  17:11     3,456,569,215 train.sql\n",
      "2019/11/18  17:38       484,214,123 val.csv\n",
      "2019/08/05  17:19     1,230,810,962 word_vectors_64d.txt\n",
      "2019/11/06  09:59     9,418,974,739 zhihu2019_dataset.sql\n",
      "              14 个文件 27,631,064,225 字节\n",
      "               3 个目录 398,478,372,864 可用字节\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pymysql\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 65536\n",
    "DB_NAME = 'zhihu2019_dataset'\n",
    "DO_DATASET_BALANCE = True\n",
    "EPOCH = 80\n",
    "LR = 0.1\n",
    "TRAIN_ALL = True\n",
    "\n",
    "PKL_DIR_READ = '../../jupyter/190919_DataMiningHW/project3/storage/train_param.pkl'\n",
    "PKL_DIR_OUT = '../../jupyter/190919_DataMiningHW/project3/storage/train_param.pkl'\n",
    "RESULT_DIR_OUT = '../../jupyter/190919_DataMiningHW/project3/storage/result.txt'\n",
    "\n",
    "DEVICE = torch.device('cuda:3') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 加载数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取训练集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with DB() as db:\n",
    "#     db.execute('select * from train')\n",
    "#     train = pd.DataFrame(db.fetchall())\n",
    "\n",
    "train = pd.read_csv('train.csv', header=0, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with DB() as db:\n",
    "#     db.execute('select * from val')\n",
    "#     test = pd.DataFrame(db.fetchall())\n",
    "\n",
    "test = pd.read_csv('val.csv', header=0, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并二集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['q_id', 'u_id', 'do_answer', 'invite_hour', 'follow_topic_hit', \n",
    "             'interest_topic_hit', 'sex', 'access_freq', 'bin_feat_a', 'bin_feat_b', \n",
    "             'bin_feat_c', 'bin_feat_d', 'bin_feat_e', 'multi_feat_a', 'multi_feat_b',\n",
    "             'multi_feat_c', 'multi_feat_d', 'multi_feat_e', 'salt', 'u_answer', \n",
    "             'u_good_answer', 'u_recommand_answer', 'u_image_answer', 'u_video_answer', \n",
    "             'u_word_avg', 'u_like_avg', 'u_unlike_avg', 'u_comment_avg', \n",
    "             'u_collect_avg', 'u_thanks_avg', 'u_report_avg','u_nohelp_avg', \n",
    "             'u_oppose_avg', 'q_answer', 'q_good_answer', 'q_recommand_answer',\n",
    "             'q_image_answer', 'q_video_answer', 'q_word_avg', 'q_like', 'q_comment', \n",
    "             'q_collect', 'q_thanks']\n",
    "# train = train[col_list]\n",
    "# test = test[col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['q_id', 'u_id', 'do_answer', 'invite_hour', 'follow_topic_hit',\n",
       "       'interest_topic_hit', 'sex', 'access_freq', 'bin_feat_a', 'bin_feat_b',\n",
       "       'bin_feat_c', 'bin_feat_d', 'bin_feat_e', 'multi_feat_a',\n",
       "       'multi_feat_b', 'multi_feat_c', 'multi_feat_d', 'multi_feat_e', 'salt',\n",
       "       'u_answer', 'u_good_answer', 'u_recommand_answer', 'u_image_answer',\n",
       "       'u_video_answer', 'u_word_avg', 'u_like_avg', 'u_unlike_avg',\n",
       "       'u_comment_avg', 'u_collect_avg', 'u_thanks_avg', 'u_report_avg',\n",
       "       'u_nohelp_avg', 'u_oppose_avg', 'q_answer', 'q_good_answer',\n",
       "       'q_recommand_answer', 'q_image_answer', 'q_video_answer', 'q_word_avg',\n",
       "       'q_like', 'q_comment', 'q_collect', 'q_thanks'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([train, test], axis=0)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "for i in ['invite_hour', 'follow_topic_hit', \n",
    "             'interest_topic_hit', 'bin_feat_a', 'bin_feat_b', \n",
    "             'bin_feat_c', 'bin_feat_d', 'bin_feat_e', 'salt', 'u_answer', \n",
    "             'u_good_answer', 'u_recommand_answer', 'u_image_answer', 'u_video_answer', \n",
    "             'u_word_avg', 'u_like_avg', 'u_unlike_avg', 'u_comment_avg', \n",
    "             'u_collect_avg', 'u_thanks_avg', 'u_report_avg','u_nohelp_avg', \n",
    "             'u_oppose_avg', 'q_answer', 'q_good_answer', 'q_recommand_answer',\n",
    "             'q_image_answer', 'q_video_answer', 'q_word_avg', 'q_like', 'q_comment', \n",
    "             'q_collect', 'q_thanks']:\n",
    "    data[i] = scale(data[i].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.5 清洗准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算数据相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invite_hour\t\t-0.0319\t-0.0310\t-0.0253\n",
      "follow_topic_hit\t\t0.0297\t0.0265\t0.0252\n",
      "interest_topic_hit\t\t0.0078\t0.0080\t0.0075\n",
      "bin_feat_a\t\t0.0147\t0.0145\t0.0141\n",
      "bin_feat_b\t\t-0.0117\t-0.0123\t-0.0120\n",
      "bin_feat_c\t\t-0.0082\t-0.0085\t-0.0082\n",
      "bin_feat_d\t\t0.0012\t0.0010\t0.0010\n",
      "bin_feat_e\t\t-0.0000\t-0.0001\t-0.0001\n",
      "salt\t\t0.0404\t0.0526\t0.0417\n",
      "u_answer\t\t0.1213\t0.1572\t0.1295\n",
      "u_good_answer\t\t0.0025\t0.0039\t0.0038\n",
      "u_recommand_answer\t\t0.0003\t0.0002\t0.0002\n",
      "u_image_answer\t\t-0.0121\t0.0209\t0.0190\n",
      "u_video_answer\t\t-0.0065\t0.0101\t0.0097\n",
      "u_word_avg\t\t-0.0024\t0.0629\t0.0509\n",
      "u_like_avg\t\t-0.0063\t-0.0116\t-0.0106\n",
      "u_unlike_avg\t\t-0.0075\t-0.0163\t-0.0156\n",
      "u_comment_avg\t\t-0.0083\t0.0073\t0.0067\n",
      "u_collect_avg\t\t-0.0028\t-0.0118\t-0.0112\n",
      "u_thanks_avg\t\t-0.0039\t-0.0196\t-0.0187\n",
      "u_report_avg\t\t-0.0005\t-0.0004\t-0.0004\n",
      "u_nohelp_avg\t\t-0.0045\t-0.0089\t-0.0086\n",
      "u_oppose_avg\t\t-0.0075\t-0.0163\t-0.0156\n",
      "q_answer\t\t0.0867\t0.3735\t0.3184\n",
      "q_good_answer\t\t0.0238\t0.0249\t0.0241\n",
      "q_recommand_answer\t\t0.0026\t0.0029\t0.0028\n",
      "q_image_answer\t\t0.0600\t0.1606\t0.1499\n",
      "q_video_answer\t\t0.0218\t0.0546\t0.0528\n",
      "q_word_avg\t\t0.1102\t0.3398\t0.2791\n",
      "q_like\t\t0.0170\t0.2100\t0.1878\n",
      "q_comment\t\t0.0268\t0.2064\t0.1853\n",
      "q_collect\t\t0.0058\t0.1424\t0.1323\n",
      "q_thanks\t\t0.0115\t0.1722\t0.1581\n"
     ]
    }
   ],
   "source": [
    "for i in ['invite_hour', 'follow_topic_hit', \n",
    "             'interest_topic_hit', 'bin_feat_a', 'bin_feat_b', \n",
    "             'bin_feat_c', 'bin_feat_d', 'bin_feat_e', 'salt', 'u_answer', \n",
    "             'u_good_answer', 'u_recommand_answer', 'u_image_answer', 'u_video_answer', \n",
    "             'u_word_avg', 'u_like_avg', 'u_unlike_avg', 'u_comment_avg', \n",
    "             'u_collect_avg', 'u_thanks_avg', 'u_report_avg','u_nohelp_avg', \n",
    "             'u_oppose_avg', 'q_answer', 'q_good_answer', 'q_recommand_answer',\n",
    "             'q_image_answer', 'q_video_answer', 'q_word_avg', 'q_like', 'q_comment', \n",
    "             'q_collect', 'q_thanks']:\n",
    "    k1 = data['do_answer'].corr(data[i], method='pearson')\n",
    "    k2 = data['do_answer'].corr(data[i], method='spearman')\n",
    "    k3 = data['do_answer'].corr(data[i], method='kendall')\n",
    "    print('%s\\t\\t%.4f\\t%.4f\\t%.4f' % (i, k1, k2, k3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 处理数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清洗数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['q_id', 'u_id', 'do_answer', 'invite_hour', 'follow_topic_hit',\n",
       "       'interest_topic_hit', 'bin_feat_a', 'bin_feat_b', 'bin_feat_c',\n",
       "       'bin_feat_d', 'bin_feat_e', 'salt', 'u_answer', 'u_good_answer',\n",
       "       'u_recommand_answer', 'u_image_answer', 'u_video_answer', 'u_word_avg',\n",
       "       'u_like_avg', 'u_unlike_avg', 'u_comment_avg', 'u_collect_avg',\n",
       "       'u_thanks_avg', 'u_report_avg', 'u_nohelp_avg', 'u_oppose_avg',\n",
       "       'q_answer', 'q_good_answer', 'q_recommand_answer', 'q_image_answer',\n",
       "       'q_video_answer', 'q_word_avg', 'q_like', 'q_comment', 'q_collect',\n",
       "       'q_thanks', 'sex', 'access_freq', 'multi_feat_a', 'multi_feat_b',\n",
       "       'multi_feat_c', 'multi_feat_d', 'multi_feat_e'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stable_col_list = ['q_id', 'u_id', 'do_answer']\n",
    "good_col_list = ['follow_topic_hit', 'interest_topic_hit', 'bin_feat_a',\n",
    "                 'salt', 'u_answer', 'u_image_answer', 'u_video_answer', \n",
    "                 'u_word_avg', 'q_answer', 'q_good_answer',\n",
    "                 'q_image_answer', 'q_video_answer', 'q_word_avg', 'q_like', 'q_comment', \n",
    "                 'q_collect', 'q_thanks']\n",
    "good_bad_col_list = ['invite_hour', 'follow_topic_hit', \n",
    "             'interest_topic_hit', 'bin_feat_a', 'bin_feat_b', \n",
    "             'bin_feat_c', 'bin_feat_d', 'bin_feat_e', 'salt', 'u_answer', \n",
    "             'u_good_answer', 'u_recommand_answer', 'u_image_answer', 'u_video_answer', \n",
    "             'u_word_avg', 'u_like_avg', 'u_unlike_avg', 'u_comment_avg', \n",
    "             'u_collect_avg', 'u_thanks_avg', 'u_report_avg','u_nohelp_avg', \n",
    "             'u_oppose_avg', 'q_answer', 'q_good_answer', 'q_recommand_answer',\n",
    "             'q_image_answer', 'q_video_answer', 'q_word_avg', 'q_like', 'q_comment', \n",
    "             'q_collect', 'q_thanks']\n",
    "other_col_list = ['sex', 'access_freq', 'multi_feat_a', 'multi_feat_b', \n",
    "                  'multi_feat_c','multi_feat_d','multi_feat_e']\n",
    "data = data[stable_col_list + good_bad_col_list + other_col_list]\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "离散特征的`LabelEncoder`编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>u_id</th>\n",
       "      <th>do_answer</th>\n",
       "      <th>invite_hour</th>\n",
       "      <th>follow_topic_hit</th>\n",
       "      <th>interest_topic_hit</th>\n",
       "      <th>bin_feat_a</th>\n",
       "      <th>bin_feat_b</th>\n",
       "      <th>bin_feat_c</th>\n",
       "      <th>bin_feat_d</th>\n",
       "      <th>...</th>\n",
       "      <th>q_comment</th>\n",
       "      <th>q_collect</th>\n",
       "      <th>q_thanks</th>\n",
       "      <th>sex</th>\n",
       "      <th>access_freq</th>\n",
       "      <th>multi_feat_a</th>\n",
       "      <th>multi_feat_b</th>\n",
       "      <th>multi_feat_c</th>\n",
       "      <th>multi_feat_d</th>\n",
       "      <th>multi_feat_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2166419046</td>\n",
       "      <td>M401693808</td>\n",
       "      <td>0</td>\n",
       "      <td>1.546644</td>\n",
       "      <td>1.313413</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>-1.404298</td>\n",
       "      <td>1.532982</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1917</td>\n",
       "      <td>170</td>\n",
       "      <td>244</td>\n",
       "      <td>799</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1550017551</td>\n",
       "      <td>M3392373099</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.389192</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070538</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>249</td>\n",
       "      <td>657</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q604029601</td>\n",
       "      <td>M2317670257</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314748</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1380</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q2350061229</td>\n",
       "      <td>M1618461867</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.389192</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>2.528689</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>1.690382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063124</td>\n",
       "      <td>-0.028304</td>\n",
       "      <td>-0.041673</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>244</td>\n",
       "      <td>799</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q2443223942</td>\n",
       "      <td>M3544409350</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.621091</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066831</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>506</td>\n",
       "      <td>204</td>\n",
       "      <td>175</td>\n",
       "      <td>705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q640765464</td>\n",
       "      <td>M2818659842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490733</td>\n",
       "      <td>1.313413</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1380</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q795459266</td>\n",
       "      <td>M2818659842</td>\n",
       "      <td>0</td>\n",
       "      <td>1.194672</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055711</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1380</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q190554387</td>\n",
       "      <td>M1581217469</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.917147</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066831</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.041673</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q1958712851</td>\n",
       "      <td>M3021021791</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018691</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>-1.404298</td>\n",
       "      <td>1.532982</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1486</td>\n",
       "      <td>170</td>\n",
       "      <td>249</td>\n",
       "      <td>657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q311993584</td>\n",
       "      <td>M1766315480</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314748</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048297</td>\n",
       "      <td>-0.028304</td>\n",
       "      <td>-0.036537</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>370</td>\n",
       "      <td>1252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          q_id         u_id  do_answer  invite_hour  follow_topic_hit  \\\n",
       "0  Q2166419046   M401693808          0     1.546644          1.313413   \n",
       "1  Q1550017551  M3392373099          0    -0.389192         -0.438017   \n",
       "2   Q604029601  M2317670257          0     0.314748         -0.438017   \n",
       "3  Q2350061229  M1618461867          0    -0.389192         -0.438017   \n",
       "4  Q2443223942  M3544409350          0    -1.621091         -0.438017   \n",
       "5   Q640765464  M2818659842          0     0.490733          1.313413   \n",
       "6   Q795459266  M2818659842          0     1.194672         -0.438017   \n",
       "7   Q190554387  M1581217469          1    -0.917147         -0.438017   \n",
       "8  Q1958712851  M3021021791          0     1.018691         -0.438017   \n",
       "9   Q311993584  M1766315480          0     0.314748         -0.438017   \n",
       "\n",
       "   interest_topic_hit  bin_feat_a  bin_feat_b  bin_feat_c  bin_feat_d  ...  \\\n",
       "0           -0.274834   -1.404298    1.532982   -0.201699   -0.591582  ...   \n",
       "1           -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "2           -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "3            2.528689    0.712100   -0.652323   -0.201699    1.690382  ...   \n",
       "4           -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "5           -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "6           -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "7           -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "8           -0.274834   -1.404298    1.532982   -0.201699   -0.591582  ...   \n",
       "9           -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "\n",
       "   q_comment  q_collect  q_thanks  sex  access_freq  multi_feat_a  \\\n",
       "0  -0.074245  -0.028820 -0.044241    2            4          1917   \n",
       "1  -0.070538  -0.028820 -0.044241    2            1          1092   \n",
       "2  -0.074245  -0.028820 -0.044241    2            4          1380   \n",
       "3  -0.063124  -0.028304 -0.041673    2            0          1092   \n",
       "4  -0.066831  -0.028820 -0.044241    2            1           506   \n",
       "5  -0.074245  -0.028820 -0.044241    1            0          1380   \n",
       "6  -0.055711  -0.028820 -0.044241    1            0          1380   \n",
       "7  -0.066831  -0.028820 -0.041673    2            1          1092   \n",
       "8  -0.074245  -0.028820 -0.044241    2            4          1486   \n",
       "9  -0.048297  -0.028304 -0.036537    1            0          1092   \n",
       "\n",
       "   multi_feat_b  multi_feat_c  multi_feat_d  multi_feat_e  \n",
       "0           170           244           799             1  \n",
       "1           115           249           657             0  \n",
       "2           206             0           440             1  \n",
       "3           115           244           799             1  \n",
       "4           204           175           705             1  \n",
       "5           206             0           440             1  \n",
       "6           206             0           440             1  \n",
       "7           115             0           128             1  \n",
       "8           170           249           657             1  \n",
       "9           115           370          1252             1  \n",
       "\n",
       "[10 rows x 43 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 离散值编码\n",
    "encoder = LabelEncoder()\n",
    "for i in other_col_list:\n",
    "    data[i] = encoder.fit_transform(data[i])\n",
    "    \n",
    "data.iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 包装数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# if DO_DATASET_BALANCE:\n",
    "#     temp = data[data['do_answer'] == 1]  # 用于均衡的数据\n",
    "#     print('用于均衡的数据有 %d 条.' % len(temp))\n",
    "#     train_x = data[data['do_answer']>-1].append([temp, temp, temp])\n",
    "# else:\n",
    "#     train_x = data[data['do_answer']>-1]\n",
    "# train_x, train_y = train_x[col_list[3:]].values, train_x[['do_answer']].values[:, 0]\n",
    "\n",
    "test_x = data[data['do_answer']==-1]\n",
    "test_x, test_y = test_x[good_bad_col_list + other_col_list].values, test_x['do_answer'].values\n",
    "# print('ok.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_len: 1682914\n",
      "neg_len: 7806219\n"
     ]
    }
   ],
   "source": [
    "# 正负样本df\n",
    "positive_samples = data[data['do_answer'] == 1]\n",
    "negative_samples = data[data['do_answer'] == 0]\n",
    "print('pos_len:', len(positive_samples))\n",
    "print('neg_len:', len(negative_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"每次new都会随机均衡数据集。\"\"\"\n",
    "    def __init__(self, mode='train'):\n",
    "        self.mode = mode\n",
    "        if mode == 'train':\n",
    "            train_x = pd.concat([\n",
    "                positive_samples,\n",
    "                negative_samples.sample(n=len(positive_samples), axis=0)\n",
    "            ], axis=0)\n",
    "            train_x, train_y = train_x[good_bad_col_list + other_col_list].values, train_x['do_answer'].values\n",
    "            self.data = {\n",
    "                'x': train_x,\n",
    "                'y': train_y,\n",
    "            }\n",
    "        elif mode == 'test':\n",
    "            self.data = {\n",
    "                'x': test_x,\n",
    "                'y': test_y,\n",
    "            }\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        return self.data['x'][index], self.data['y'][index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data['x'])\n",
    "    \n",
    "    \n",
    "print('ok.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size, val_size, test_size = 0, 0, 0\n",
    "train_len, val_len, test_len = 0, 0, 0\n",
    "data_loader = {}\n",
    "\n",
    "def flush_dataloader(log=True):\n",
    "    global train_size, val_size, test_size, train_len, val_len, test_len, data_loader\n",
    "    \n",
    "    full_train_dataset = MyDataset(mode='train')\n",
    "    test_dataset = MyDataset(mode='test')\n",
    "\n",
    "    if TRAIN_ALL:\n",
    "        data_loader = {\n",
    "            'train': DataLoader(dataset=full_train_dataset, \n",
    "                                batch_size=BATCH_SIZE, \n",
    "#                                 num_workers=5,\n",
    "                                shuffle=True),\n",
    "            'test': DataLoader(dataset=test_dataset,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "#                                num_workers=5,\n",
    "                               shuffle=False),\n",
    "        }\n",
    "        train_size = len(full_train_dataset)\n",
    "        test_size = len(test_dataset)\n",
    "    else:\n",
    "        train_size = int(0.8 * len(full_train_dataset))\n",
    "        val_size = len(full_train_dataset) - train_size\n",
    "        train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "        data_loader = {\n",
    "            'train': DataLoader(dataset=train_dataset, \n",
    "                                batch_size=BATCH_SIZE, \n",
    "                               num_workers=5,\n",
    "                                shuffle=True),\n",
    "            'val': DataLoader(dataset=val_dataset, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                               num_workers=5,\n",
    "                              shuffle=False),\n",
    "            'test': DataLoader(dataset=test_dataset,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               num_workers=5,\n",
    "                               shuffle=False),\n",
    "        }\n",
    "        train_size = len(train_dataset)\n",
    "        val_size = len(val_dataset)\n",
    "        test_size = len(test_dataset)\n",
    "\n",
    "    if log:\n",
    "        print('train_size:', train_size)\n",
    "        print('val_size:', val_size)\n",
    "        print('test_size:', test_size)\n",
    "\n",
    "    # 计算一轮enumerate的长度\n",
    "    train_len = math.ceil(train_size / BATCH_SIZE)\n",
    "    val_len = math.ceil(val_size / BATCH_SIZE)\n",
    "    test_len = math.ceil(test_size / BATCH_SIZE)\n",
    "\n",
    "    if log:\n",
    "        print('train_len:', train_len)\n",
    "        print('val_len:', val_len)\n",
    "        print('test_len:', test_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class MyNet_v2(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim=2, norm='dropout'):\n",
    "        super(MyNet_v2, self).__init__()\n",
    "        self.norm = norm\n",
    "\n",
    "        in_dim = in_dim+1+1+4+2+2+3\n",
    "        self.embed_sex = nn.Embedding(3, 2)\n",
    "        self.embed_access_freq = nn.Embedding(5, 2)\n",
    "        self.embed_multi_a = nn.Embedding(2561, 5)\n",
    "        self.embed_multi_b = nn.Embedding(291, 3)\n",
    "        self.embed_multi_c = nn.Embedding(428, 3)\n",
    "        self.embed_multi_d = nn.Embedding(1556, 4)\n",
    "        self.embed_multi_e = nn.Embedding(2, 1)\n",
    "        self.fc1 = nn.Linear(in_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, out_dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        if self.norm == 'batchnorm':\n",
    "            self.bn0 = nn.BatchNorm1d(in_dim)\n",
    "            self.bn1 = nn.BatchNorm1d(512)\n",
    "            self.bn2 = nn.BatchNorm1d(256)\n",
    "            self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        sex = self.embed_sex(x[:, -7].long())\n",
    "        access_freq = self.embed_access_freq(x[:, -6].long())\n",
    "        multi_a = self.embed_multi_a(x[:, -5].long())\n",
    "        multi_b = self.embed_multi_b(x[:, -4].long())\n",
    "        multi_c = self.embed_multi_c(x[:, -3].long())\n",
    "        multi_d = self.embed_multi_d(x[:, -2].long())\n",
    "        multi_e = self.embed_multi_e(x[:, -1].long())\n",
    "\n",
    "        out = x[:, :-7]\n",
    "        out = torch.cat(\n",
    "            (out, sex, access_freq, multi_a, multi_b, multi_c, multi_d, multi_e), dim=1)\n",
    "        \n",
    "        if self.norm is None:\n",
    "            out = self.fc1(out)\n",
    "            out = self.fc2(self.relu(out))\n",
    "            out = self.fc3(self.relu(out))\n",
    "            out = self.fc4(self.relu(out))\n",
    "        elif self.norm == 'dropout':\n",
    "            out = self.fc1(out)\n",
    "            out = F.dropout(out, p=0.5, training=self.training)\n",
    "            out = self.fc2(self.relu(out))\n",
    "            out = F.dropout(out, p=0.5, training=self.training)\n",
    "            out = self.fc3(self.relu(out))\n",
    "            out = F.dropout(out, p=0.5, training=self.training)\n",
    "            out = self.fc4(self.relu(out))\n",
    "        else:\n",
    "            out = self.fc1(self.bn0(out))\n",
    "            out = self.fc2(self.relu(self.bn1(out)))\n",
    "            out = self.fc3(self.relu(self.bn2(out)))\n",
    "            out = self.fc4(self.relu(self.bn3(out)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNet_v2(\n",
       "  (embed_sex): Embedding(3, 2)\n",
       "  (embed_access_freq): Embedding(5, 2)\n",
       "  (embed_multi_a): Embedding(2561, 5)\n",
       "  (embed_multi_b): Embedding(291, 3)\n",
       "  (embed_multi_c): Embedding(428, 3)\n",
       "  (embed_multi_d): Embedding(1556, 4)\n",
       "  (embed_multi_e): Embedding(2, 1)\n",
       "  (fc1): Linear(in_features=53, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (relu): ReLU(inplace)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from my_model import MyNet_v2_1\n",
    "\n",
    "net = MyNet_v2(len(good_bad_col_list + other_col_list)).to(DEVICE)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取现有的\n",
    "if torch.cuda.is_available():\n",
    "    net.load_state_dict(torch.load(PKL_DIR_READ))\n",
    "else:\n",
    "    net.load_state_dict(torch.load(PKL_DIR_READ, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 优化器、损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "LR = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import optim, nn\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.75)  # 步进\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max',verbose=1,patience=3)\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = (EPOCH // 9) + 1)\n",
    "\n",
    "'ok'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.5165, Acc: 0.7380, Lr: 0.10000: 100%|██████████| 52/52 [01:59<00:00,  1.87s/it]\n",
      "Epoch: 1, Loss: 0.5170, Acc: 0.7377, Lr: 0.10000: 100%|██████████| 52/52 [01:57<00:00,  1.86s/it]\n",
      "Epoch: 2, Loss: 0.5165, Acc: 0.7381, Lr: 0.10000: 100%|██████████| 52/52 [01:56<00:00,  1.83s/it]\n",
      "Epoch: 3, Loss: 0.5167, Acc: 0.7379, Lr: 0.10000: 100%|██████████| 52/52 [01:57<00:00,  1.87s/it]\n",
      "Epoch: 4, Loss: 0.5167, Acc: 0.7383, Lr: 0.10000: 100%|██████████| 52/52 [01:56<00:00,  1.84s/it]\n",
      "Epoch: 5, Loss: 0.5161, Acc: 0.7384, Lr: 0.10000: 100%|██████████| 52/52 [01:56<00:00,  1.81s/it]\n",
      "Epoch: 6, Loss: 0.5163, Acc: 0.7383, Lr: 0.10000: 100%|██████████| 52/52 [01:56<00:00,  1.87s/it]\n",
      "Epoch: 7, Loss: 0.5157, Acc: 0.7386, Lr: 0.10000: 100%|██████████| 52/52 [01:57<00:00,  1.86s/it]\n",
      "Epoch: 8, Loss: 0.5156, Acc: 0.7388, Lr: 0.10000: 100%|██████████| 52/52 [01:56<00:00,  1.83s/it]\n",
      "Epoch: 9, Loss: 0.5150, Acc: 0.7393, Lr: 0.10000: 100%|██████████| 52/52 [01:57<00:00,  1.83s/it]\n",
      "Epoch: 10, Loss: 0.5148, Acc: 0.7394, Lr: 0.10000: 100%|██████████| 52/52 [01:56<00:00,  1.83s/it]\n",
      "Epoch: 11, Loss: 0.5149, Acc: 0.7394, Lr: 0.10000: 100%|██████████| 52/52 [01:57<00:00,  1.89s/it]\n",
      "Epoch: 12, Loss: 0.5146, Acc: 0.7394, Lr: 0.10000: 100%|██████████| 52/52 [01:57<00:00,  1.83s/it]\n",
      "Epoch: 13, Loss: 0.5146, Acc: 0.7397, Lr: 0.10000: 100%|██████████| 52/52 [01:58<00:00,  1.82s/it]\n",
      "Epoch: 14, Loss: 0.5143, Acc: 0.7400, Lr: 0.10000: 100%|██████████| 52/52 [01:59<00:00,  1.88s/it]\n",
      "Epoch: 15, Loss: 0.5139, Acc: 0.7402, Lr: 0.10000: 100%|██████████| 52/52 [02:00<00:00,  1.85s/it]\n",
      "Epoch: 16, Loss: 0.5139, Acc: 0.7399, Lr: 0.10000: 100%|██████████| 52/52 [02:01<00:00,  1.96s/it]\n",
      "Epoch: 17, Loss: 0.5139, Acc: 0.7400, Lr: 0.10000: 100%|██████████| 52/52 [01:58<00:00,  1.85s/it]\n",
      "Epoch: 18, Loss: 0.5137, Acc: 0.7402, Lr: 0.10000: 100%|██████████| 52/52 [01:59<00:00,  1.91s/it]\n",
      "Epoch: 19, Loss: 0.5136, Acc: 0.7403, Lr: 0.10000: 100%|██████████| 52/52 [01:58<00:00,  1.82s/it]\n",
      "Epoch: 20, Loss: 0.5137, Acc: 0.7402, Lr: 0.10000: 100%|██████████| 52/52 [01:59<00:00,  1.85s/it]\n",
      "Epoch: 21, Loss: 0.5135, Acc: 0.7404, Lr: 0.10000: 100%|██████████| 52/52 [01:59<00:00,  1.86s/it]\n",
      "Epoch: 22, Loss: 0.5131, Acc: 0.7404, Lr: 0.10000: 100%|██████████| 52/52 [01:58<00:00,  1.83s/it]\n",
      "Epoch: 23, Loss: 0.5131, Acc: 0.7405, Lr: 0.10000: 100%|██████████| 52/52 [02:01<00:00,  1.92s/it]\n",
      "Epoch: 24, Loss: 0.5132, Acc: 0.7405, Lr: 0.10000: 100%|██████████| 52/52 [01:59<00:00,  1.85s/it]\n",
      "Epoch: 25, Loss: 0.5127, Acc: 0.7410, Lr: 0.10000: 100%|██████████| 52/52 [01:59<00:00,  1.91s/it]\n",
      "Epoch: 26, Loss: 0.5129, Acc: 0.7406, Lr: 0.10000: 100%|██████████| 52/52 [01:59<00:00,  1.91s/it]\n",
      "Epoch: 27, Loss: 0.5124, Acc: 0.7410, Lr: 0.10000: 100%|██████████| 52/52 [02:00<00:00,  1.95s/it]\n",
      "Epoch: 28, Loss: 0.5128, Acc: 0.7408, Lr: 0.10000: 100%|██████████| 52/52 [02:00<00:00,  1.94s/it]\n",
      "Epoch: 29, Loss: 0.5121, Acc: 0.7413, Lr: 0.10000: 100%|██████████| 52/52 [02:00<00:00,  1.92s/it]\n",
      "Epoch: 30, Loss: 0.5123, Acc: 0.7412, Lr: 0.10000: 100%|██████████| 52/52 [01:58<00:00,  1.86s/it]\n",
      "Epoch: 31, Loss: 0.5119, Acc: 0.7415, Lr: 0.10000: 100%|██████████| 52/52 [01:59<00:00,  1.91s/it]\n",
      "Epoch: 32, Loss: 0.5116, Acc: 0.7414, Lr: 0.10000: 100%|██████████| 52/52 [01:57<00:00,  1.83s/it]\n",
      "Epoch: 33, Loss: 0.5123, Acc: 0.7413, Lr: 0.10000: 100%|██████████| 52/52 [01:59<00:00,  1.95s/it]\n",
      "Epoch: 34, Loss: 0.5119, Acc: 0.7414, Lr: 0.10000: 100%|██████████| 52/52 [01:58<00:00,  1.90s/it]\n",
      "Epoch: 35, Loss: 0.5121, Acc: 0.7413, Lr: 0.10000: 100%|██████████| 52/52 [01:59<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Loss: 0.5098, Acc: 0.7431, Lr: 0.01000: 100%|██████████| 52/52 [01:58<00:00,  1.89s/it]\n",
      "Epoch: 37, Loss: 0.5092, Acc: 0.7432, Lr: 0.01000: 100%|██████████| 52/52 [01:58<00:00,  1.84s/it]\n",
      "Epoch: 38, Loss: 0.5087, Acc: 0.7435, Lr: 0.01000: 100%|██████████| 52/52 [01:57<00:00,  1.85s/it]\n",
      "Epoch: 39, Loss: 0.5088, Acc: 0.7435, Lr: 0.01000: 100%|██████████| 52/52 [02:01<00:00,  1.97s/it]\n",
      "Epoch: 40, Loss: 0.5089, Acc: 0.7434, Lr: 0.01000: 100%|██████████| 52/52 [02:01<00:00,  1.85s/it]\n",
      "Epoch: 41, Loss: 0.5084, Acc: 0.7439, Lr: 0.01000: 100%|██████████| 52/52 [01:57<00:00,  1.84s/it]\n",
      "Epoch: 42, Loss: 0.5087, Acc: 0.7436, Lr: 0.01000: 100%|██████████| 52/52 [01:59<00:00,  1.93s/it]\n",
      "Epoch: 43, Loss: 0.5086, Acc: 0.7435, Lr: 0.01000: 100%|██████████| 52/52 [01:59<00:00,  1.95s/it]\n",
      "Epoch: 44, Loss: 0.5087, Acc: 0.7434, Lr: 0.01000: 100%|██████████| 52/52 [01:58<00:00,  1.84s/it]\n",
      "Epoch: 45, Loss: 0.5082, Acc: 0.7440, Lr: 0.01000: 100%|██████████| 52/52 [02:00<00:00,  1.87s/it]\n",
      "Epoch: 46, Loss: 0.5089, Acc: 0.7435, Lr: 0.01000: 100%|██████████| 52/52 [01:58<00:00,  1.90s/it]\n",
      "Epoch: 47, Loss: 0.5085, Acc: 0.7438, Lr: 0.01000: 100%|██████████| 52/52 [01:59<00:00,  1.82s/it]\n",
      "Epoch: 48, Loss: 0.5083, Acc: 0.7440, Lr: 0.01000: 100%|██████████| 52/52 [02:00<00:00,  1.84s/it]\n",
      "Epoch: 49, Loss: 0.5089, Acc: 0.7434, Lr: 0.01000: 100%|██████████| 52/52 [01:57<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Loss: 0.5084, Acc: 0.7439, Lr: 0.00100: 100%|██████████| 52/52 [01:57<00:00,  1.86s/it]\n",
      "Epoch: 51, Loss: 0.5087, Acc: 0.7436, Lr: 0.00100: 100%|██████████| 52/52 [01:58<00:00,  1.88s/it]\n",
      "Epoch: 52, Loss: 0.5082, Acc: 0.7442, Lr: 0.00100: 100%|██████████| 52/52 [01:58<00:00,  1.85s/it]\n",
      "Epoch: 53, Loss: 0.5081, Acc: 0.7441, Lr: 0.00100: 100%|██████████| 52/52 [01:58<00:00,  1.84s/it]\n",
      "Epoch: 54, Loss: 0.5084, Acc: 0.7440, Lr: 0.00100: 100%|██████████| 52/52 [01:59<00:00,  1.92s/it]\n",
      "Epoch: 55, Loss: 0.5082, Acc: 0.7440, Lr: 0.00100: 100%|██████████| 52/52 [01:58<00:00,  1.84s/it]\n",
      "Epoch: 56, Loss: 0.5081, Acc: 0.7440, Lr: 0.00100: 100%|██████████| 52/52 [02:00<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 57, Loss: 0.5082, Acc: 0.7441, Lr: 0.00010: 100%|██████████| 52/52 [01:57<00:00,  1.88s/it]\n",
      "Epoch: 58, Loss: 0.5079, Acc: 0.7442, Lr: 0.00010: 100%|██████████| 52/52 [01:57<00:00,  1.83s/it]\n",
      "Epoch: 59, Loss: 0.5079, Acc: 0.7443, Lr: 0.00010: 100%|██████████| 52/52 [01:58<00:00,  1.82s/it]\n",
      "Epoch: 60, Loss: 0.5081, Acc: 0.7442, Lr: 0.00010: 100%|██████████| 52/52 [01:58<00:00,  1.89s/it]\n",
      "Epoch: 61, Loss: 0.5080, Acc: 0.7443, Lr: 0.00010: 100%|██████████| 52/52 [01:57<00:00,  1.84s/it]\n",
      "Epoch: 62, Loss: 0.5079, Acc: 0.7444, Lr: 0.00010: 100%|██████████| 52/52 [01:58<00:00,  1.87s/it]\n",
      "Epoch: 63, Loss: 0.5081, Acc: 0.7442, Lr: 0.00010: 100%|██████████| 52/52 [01:58<00:00,  1.86s/it]\n",
      "Epoch: 64, Loss: 0.5079, Acc: 0.7443, Lr: 0.00010: 100%|██████████| 52/52 [01:56<00:00,  1.83s/it]\n",
      "Epoch: 65, Loss: 0.5083, Acc: 0.5505, Lr: 0.00010:  73%|███████▎  | 38/52 [01:26<00:31,  2.26s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    count, running_correct, running_loss = 0, 0, 0\n",
    "    flush_dataloader(log=False)\n",
    "    \n",
    "    net.train()\n",
    "    with tqdm(total=train_len) as pbar:\n",
    "        for step, (bx, by) in enumerate(data_loader['train']):\n",
    "            # 训练\n",
    "            bx = bx.float().to(DEVICE)\n",
    "            by = by.long().to(DEVICE)\n",
    "\n",
    "            prediction = net(bx)\n",
    "            loss = loss_function(prediction, by)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 统计成效\n",
    "            pre = torch.argmax(torch.softmax(prediction, dim=1), dim=1)\n",
    "            my_loss = float(loss.data.cpu().numpy())\n",
    "            my_correct = sum(pre.cpu().numpy() == by.cpu().numpy())\n",
    "            my_acc = my_correct / BATCH_SIZE\n",
    "            count += 1\n",
    "            running_loss += my_loss\n",
    "            running_correct += my_correct\n",
    "            \n",
    "            # 更新进度条\n",
    "            pbar.update(1)\n",
    "            pbar.set_description('Epoch: %d, Loss: %.4f, Acc: %.4f, Lr: %.5f' % (\n",
    "                                   epoch,\n",
    "                                   running_loss / count,\n",
    "                                   running_correct / train_size,\n",
    "                                   optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    \n",
    "    # 输出一轮结果\n",
    "#     print('Epoch: %d, Loss: %.4f, Acc: %.4f, Lr: %.5f' % (\n",
    "#            epoch,\n",
    "#            running_loss / count,\n",
    "#            running_correct / train_size,\n",
    "#            optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    \n",
    "    # 保存参数\n",
    "    torch.save(net.state_dict(), PKL_DIR_OUT)\n",
    "    \n",
    "    # lr scheduler\n",
    "#     scheduler.step()\n",
    "    scheduler.step(running_correct / train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 存储网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), PKL_DIR_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 导出 test 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q_id                  Q2590286630\n",
       "u_id                  M3168697168\n",
       "do_answer                      -1\n",
       "invite_hour             -0.741162\n",
       "follow_topic_hit        -0.438017\n",
       "interest_topic_hit      -0.274834\n",
       "bin_feat_a                 0.7121\n",
       "bin_feat_b              -0.652323\n",
       "bin_feat_c              -0.201699\n",
       "bin_feat_d              -0.591582\n",
       "bin_feat_e              -0.283857\n",
       "salt                      1.73948\n",
       "u_answer                 -0.27225\n",
       "u_good_answer          -0.0516322\n",
       "u_recommand_answer    -0.00862002\n",
       "u_image_answer            1.61585\n",
       "u_video_answer          -0.103026\n",
       "u_word_avg                1.47854\n",
       "u_like_avg               0.134793\n",
       "u_unlike_avg              1.01912\n",
       "u_comment_avg             1.51127\n",
       "u_collect_avg           0.0976203\n",
       "u_thanks_avg             0.174823\n",
       "u_report_avg           -0.0378529\n",
       "u_nohelp_avg           -0.0296287\n",
       "u_oppose_avg              1.01912\n",
       "q_answer                -0.204937\n",
       "q_good_answer          -0.0647244\n",
       "q_recommand_answer     -0.0177534\n",
       "q_image_answer          -0.153848\n",
       "q_video_answer         -0.0639039\n",
       "q_word_avg              -0.437234\n",
       "q_like                 -0.0547829\n",
       "q_comment              -0.0742448\n",
       "q_collect              -0.0288203\n",
       "q_thanks               -0.0442414\n",
       "sex                             1\n",
       "access_freq                     0\n",
       "multi_feat_a                 1092\n",
       "multi_feat_b                  115\n",
       "multi_feat_c                    6\n",
       "multi_feat_d                  980\n",
       "multi_feat_e                    1\n",
       "Name: 1141682, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flush_dataloader(log=False)\n",
    "result = data[data['do_answer'] == -1]\n",
    "result.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:13<00:00,  1.53it/s]\n",
      "C:\\RAYIOOO\\Programmings\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>u_id</th>\n",
       "      <th>do_answer</th>\n",
       "      <th>invite_hour</th>\n",
       "      <th>follow_topic_hit</th>\n",
       "      <th>interest_topic_hit</th>\n",
       "      <th>bin_feat_a</th>\n",
       "      <th>bin_feat_b</th>\n",
       "      <th>bin_feat_c</th>\n",
       "      <th>bin_feat_d</th>\n",
       "      <th>...</th>\n",
       "      <th>q_comment</th>\n",
       "      <th>q_collect</th>\n",
       "      <th>q_thanks</th>\n",
       "      <th>sex</th>\n",
       "      <th>access_freq</th>\n",
       "      <th>multi_feat_a</th>\n",
       "      <th>multi_feat_b</th>\n",
       "      <th>multi_feat_c</th>\n",
       "      <th>multi_feat_d</th>\n",
       "      <th>multi_feat_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1493039281</td>\n",
       "      <td>M64135255</td>\n",
       "      <td>0.056410</td>\n",
       "      <td>-0.741162</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>1.373489</td>\n",
       "      <td>-1.404298</td>\n",
       "      <td>1.532982</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>187</td>\n",
       "      <td>1193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2023398782</td>\n",
       "      <td>M2536956560</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>1.546644</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>-1.404298</td>\n",
       "      <td>1.532982</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>1.690382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>368</td>\n",
       "      <td>450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q4151338694</td>\n",
       "      <td>M3294926344</td>\n",
       "      <td>0.072103</td>\n",
       "      <td>0.314748</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>189</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q3271436624</td>\n",
       "      <td>M3744310794</td>\n",
       "      <td>0.660872</td>\n",
       "      <td>-1.621091</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>-1.404298</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055711</td>\n",
       "      <td>-0.028304</td>\n",
       "      <td>-0.036537</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>173</td>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q3314287018</td>\n",
       "      <td>M1349051752</td>\n",
       "      <td>0.037847</td>\n",
       "      <td>1.018691</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>-1.404298</td>\n",
       "      <td>1.532982</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>350</td>\n",
       "      <td>170</td>\n",
       "      <td>315</td>\n",
       "      <td>683</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q4214103875</td>\n",
       "      <td>M2007129506</td>\n",
       "      <td>0.026668</td>\n",
       "      <td>-0.037222</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>-1.404298</td>\n",
       "      <td>1.532982</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>1.690382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>175</td>\n",
       "      <td>657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q1421177878</td>\n",
       "      <td>M3927950819</td>\n",
       "      <td>0.093314</td>\n",
       "      <td>0.138763</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>-1.404298</td>\n",
       "      <td>1.532982</td>\n",
       "      <td>4.957871</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>532</td>\n",
       "      <td>170</td>\n",
       "      <td>187</td>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q3598252818</td>\n",
       "      <td>M2871943120</td>\n",
       "      <td>0.044356</td>\n",
       "      <td>-0.741162</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>-1.404298</td>\n",
       "      <td>1.532982</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>1.690382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1486</td>\n",
       "      <td>170</td>\n",
       "      <td>368</td>\n",
       "      <td>657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q568518135</td>\n",
       "      <td>M998566127</td>\n",
       "      <td>0.252524</td>\n",
       "      <td>0.842704</td>\n",
       "      <td>1.313413</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>258</td>\n",
       "      <td>657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q2242868437</td>\n",
       "      <td>M1307039867</td>\n",
       "      <td>0.042371</td>\n",
       "      <td>-0.389192</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>118</td>\n",
       "      <td>657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Q2356895615</td>\n",
       "      <td>M3400655156</td>\n",
       "      <td>0.076996</td>\n",
       "      <td>-0.741162</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>-1.404298</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>1.690382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>221</td>\n",
       "      <td>746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           q_id         u_id  do_answer  invite_hour  follow_topic_hit  \\\n",
       "0   Q1493039281    M64135255   0.056410    -0.741162         -0.438017   \n",
       "1   Q2023398782  M2536956560   0.000922     1.546644         -0.438017   \n",
       "2   Q4151338694  M3294926344   0.072103     0.314748         -0.438017   \n",
       "3   Q3271436624  M3744310794   0.660872    -1.621091         -0.438017   \n",
       "4   Q3314287018  M1349051752   0.037847     1.018691         -0.438017   \n",
       "5   Q4214103875  M2007129506   0.026668    -0.037222         -0.438017   \n",
       "6   Q1421177878  M3927950819   0.093314     0.138763         -0.438017   \n",
       "7   Q3598252818  M2871943120   0.044356    -0.741162         -0.438017   \n",
       "8    Q568518135   M998566127   0.252524     0.842704          1.313413   \n",
       "9   Q2242868437  M1307039867   0.042371    -0.389192         -0.438017   \n",
       "10  Q2356895615  M3400655156   0.076996    -0.741162         -0.438017   \n",
       "\n",
       "    interest_topic_hit  bin_feat_a  bin_feat_b  bin_feat_c  bin_feat_d  ...  \\\n",
       "0             1.373489   -1.404298    1.532982   -0.201699   -0.591582  ...   \n",
       "1            -0.274834   -1.404298    1.532982   -0.201699    1.690382  ...   \n",
       "2            -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "3            -0.274834   -1.404298   -0.652323   -0.201699   -0.591582  ...   \n",
       "4            -0.274834   -1.404298    1.532982   -0.201699   -0.591582  ...   \n",
       "5            -0.274834   -1.404298    1.532982   -0.201699    1.690382  ...   \n",
       "6            -0.274834   -1.404298    1.532982    4.957871   -0.591582  ...   \n",
       "7            -0.274834   -1.404298    1.532982   -0.201699    1.690382  ...   \n",
       "8            -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "9            -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "10           -0.274834   -1.404298   -0.652323   -0.201699    1.690382  ...   \n",
       "\n",
       "    q_comment  q_collect  q_thanks  sex  access_freq  multi_feat_a  \\\n",
       "0   -0.074245  -0.028820 -0.044241    2            4          1092   \n",
       "1   -0.074245  -0.028820 -0.044241    2            0          1092   \n",
       "2   -0.074245  -0.028820 -0.044241    0            4          1092   \n",
       "3   -0.055711  -0.028304 -0.036537    1            3          1092   \n",
       "4   -0.074245  -0.028820 -0.044241    0            4           350   \n",
       "5   -0.074245  -0.028820 -0.044241    1            0          1092   \n",
       "6   -0.074245  -0.028820 -0.044241    0            0           532   \n",
       "7   -0.074245  -0.028820 -0.044241    1            4          1486   \n",
       "8   -0.074245  -0.028820 -0.044241    2            2          1092   \n",
       "9   -0.074245  -0.028820 -0.044241    0            0          1092   \n",
       "10  -0.074245  -0.028820 -0.044241    1            4          1092   \n",
       "\n",
       "    multi_feat_b  multi_feat_c  multi_feat_d  multi_feat_e  \n",
       "0            115           187          1193             1  \n",
       "1            115           368           450             1  \n",
       "2            115           189           384             1  \n",
       "3            115           173           899             0  \n",
       "4            170           315           683             1  \n",
       "5            115           175           657             1  \n",
       "6            170           187           709             1  \n",
       "7            170           368           657             1  \n",
       "8            115           258           657             1  \n",
       "9            115           118           657             1  \n",
       "10           115           221           746             0  \n",
       "\n",
       "[11 rows x 43 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# from my_model import MyNet_v2_2\n",
    "\n",
    "net = MyNet_v2(len(good_bad_col_list + other_col_list)).to(DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    net.load_state_dict(torch.load(PKL_DIR_READ))\n",
    "else:\n",
    "    net.load_state_dict(torch.load(PKL_DIR_READ, map_location='cpu'))\n",
    "net.eval()\n",
    "\n",
    "res_list = []\n",
    "with tqdm(total=test_len) as pbar:\n",
    "    for step, (bx, by) in enumerate(data_loader['test']):\n",
    "        bx = bx.float().to(DEVICE)\n",
    "        by = by.long().to(DEVICE)\n",
    "        \n",
    "        prediction = net(bx)\n",
    "        \n",
    "        # 计算结果\n",
    "        pre = torch.softmax(prediction, dim=1)[:, 1]\n",
    "#         print(pre.cpu().detach().numpy())\n",
    "#         raise\n",
    "        res_list.extend(pre.cpu().detach().numpy())\n",
    "        pbar.update(1)\n",
    "        \n",
    "result.loc[:, 'do_answer'] = res_list\n",
    "\n",
    "result.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "invite_info_evaluate = pd.read_csv('invite_info_evaluate_1_0926.txt', \n",
    "                                   header=None, sep='\\t')\n",
    "invite_info_evaluate.columns = ['q_id1', 'u_id1', 'invite_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1141683"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_out = pd.concat([result[['q_id', 'u_id', 'do_answer']], invite_info_evaluate],\n",
    "                       axis=1)\n",
    "len(result_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_out[['q_id', 'u_id', 'invite_time', \n",
    "        'do_answer']].to_csv(RESULT_DIR_OUT, index=False, header=False, sep='\\t')  # 导出数据\n",
    "\n",
    "'ok'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
