{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Codes\\datasets\\190829_Kanshan_zjfx\n"
     ]
    }
   ],
   "source": [
    "cd ../../../datasets/190829_Kanshan_zjfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 F 中的卷是 存储\n",
      " 卷的序列号是 C14D-581B\n",
      "\n",
      " F:\\Codes\\datasets\\190829_Kanshan_zjfx 的目录\n",
      "\n",
      "2019/11/19  08:48    <DIR>          .\n",
      "2019/11/19  08:48    <DIR>          ..\n",
      "2019/09/26  19:08     5,805,965,112 answer_info_0926.txt\n",
      "2019/11/08  14:33               188 assert.py\n",
      "2019/09/26  18:10       333,836,065 invite_info_0926.txt\n",
      "2019/09/28  12:14        37,860,903 invite_info_evaluate_1_0926.txt\n",
      "2019/09/26  17:12       552,574,982 member_info_0926.txt\n",
      "2019/11/08  21:28     1,144,346,559 question_info_0926.sql\n",
      "2019/09/26  18:01     1,074,273,891 question_info_0926.txt\n",
      "2019/10/18  16:35    <DIR>          sample\n",
      "2019/08/05  17:19        15,951,125 single_word_vectors_64d.txt\n",
      "2019/08/05  17:20        69,411,196 topic_vectors_64d.txt\n",
      "2019/11/18  18:20     4,006,275,165 train.csv\n",
      "2019/11/18  17:11     3,456,569,215 train.sql\n",
      "2019/11/18  17:38       484,214,123 val.csv\n",
      "2019/08/05  17:19     1,230,810,962 word_vectors_64d.txt\n",
      "2019/11/06  09:59     9,418,974,739 zhihu2019_dataset.sql\n",
      "              14 个文件 27,631,064,225 字节\n",
      "               3 个目录 398,450,434,048 可用字节\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pymysql\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 65536\n",
    "DB_NAME = 'zhihu2019_dataset'\n",
    "DO_DATASET_BALANCE = True\n",
    "EPOCH = 3\n",
    "LR = 0.07\n",
    "TRAIN_ALL = True\n",
    "\n",
    "PKL_DIR_READ = '../../jupyter/190919_DataMiningHW/project3/storage/train_param.pkl'\n",
    "PKL_DIR_OUT = '../../jupyter/190919_DataMiningHW/project3/storage/train_param.pkl'\n",
    "RESULT_DIR_OUT = '../../jupyter/190919_DataMiningHW/project3/storage/result.txt'\n",
    "STORAGE_DIR = '../../jupyter/190919_DataMiningHW/project3/storage'\n",
    "\n",
    "DEVICE = torch.device('cuda:3') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 加载数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取训练集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with DB() as db:\n",
    "#     db.execute('select * from train')\n",
    "#     train = pd.DataFrame(db.fetchall())\n",
    "\n",
    "train = pd.read_csv('train.csv', header=0, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with DB() as db:\n",
    "#     db.execute('select * from val')\n",
    "#     test = pd.DataFrame(db.fetchall())\n",
    "\n",
    "test = pd.read_csv('val.csv', header=0, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并二集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['q_id', 'u_id', 'do_answer', 'invite_hour', 'follow_topic_hit', \n",
    "             'interest_topic_hit', 'sex', 'access_freq', 'bin_feat_a', 'bin_feat_b', \n",
    "             'bin_feat_c', 'bin_feat_d', 'bin_feat_e', 'multi_feat_a', 'multi_feat_b',\n",
    "             'multi_feat_c', 'multi_feat_d', 'multi_feat_e', 'salt', 'u_answer', \n",
    "             'u_good_answer', 'u_recommand_answer', 'u_image_answer', 'u_video_answer', \n",
    "             'u_word_avg', 'u_like_avg', 'u_unlike_avg', 'u_comment_avg', \n",
    "             'u_collect_avg', 'u_thanks_avg', 'u_report_avg','u_nohelp_avg', \n",
    "             'u_oppose_avg', 'q_answer', 'q_good_answer', 'q_recommand_answer',\n",
    "             'q_image_answer', 'q_video_answer', 'q_word_avg', 'q_like', 'q_comment', \n",
    "             'q_collect', 'q_thanks']\n",
    "# train = train[col_list]\n",
    "# test = test[col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['q_id', 'u_id', 'do_answer', 'invite_hour', 'follow_topic_hit',\n",
       "       'interest_topic_hit', 'sex', 'access_freq', 'bin_feat_a', 'bin_feat_b',\n",
       "       'bin_feat_c', 'bin_feat_d', 'bin_feat_e', 'multi_feat_a',\n",
       "       'multi_feat_b', 'multi_feat_c', 'multi_feat_d', 'multi_feat_e', 'salt',\n",
       "       'u_answer', 'u_good_answer', 'u_recommand_answer', 'u_image_answer',\n",
       "       'u_video_answer', 'u_word_avg', 'u_like_avg', 'u_unlike_avg',\n",
       "       'u_comment_avg', 'u_collect_avg', 'u_thanks_avg', 'u_report_avg',\n",
       "       'u_nohelp_avg', 'u_oppose_avg', 'q_answer', 'q_good_answer',\n",
       "       'q_recommand_answer', 'q_image_answer', 'q_video_answer', 'q_word_avg',\n",
       "       'q_like', 'q_comment', 'q_collect', 'q_thanks'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([train, test], axis=0)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "for i in ['invite_hour', 'follow_topic_hit', \n",
    "             'interest_topic_hit', 'bin_feat_a', 'bin_feat_b', \n",
    "             'bin_feat_c', 'bin_feat_d', 'bin_feat_e', 'salt', 'u_answer', \n",
    "             'u_good_answer', 'u_recommand_answer', 'u_image_answer', 'u_video_answer', \n",
    "             'u_word_avg', 'u_like_avg', 'u_unlike_avg', 'u_comment_avg', \n",
    "             'u_collect_avg', 'u_thanks_avg', 'u_report_avg','u_nohelp_avg', \n",
    "             'u_oppose_avg', 'q_answer', 'q_good_answer', 'q_recommand_answer',\n",
    "             'q_image_answer', 'q_video_answer', 'q_word_avg', 'q_like', 'q_comment', \n",
    "             'q_collect', 'q_thanks']:\n",
    "    data[i] = scale(data[i].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.5 清洗准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算数据相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invite_hour\t\t-0.0319\t-0.0310\t-0.0253\n",
      "follow_topic_hit\t\t0.0297\t0.0265\t0.0252\n",
      "interest_topic_hit\t\t0.0078\t0.0080\t0.0075\n",
      "bin_feat_a\t\t0.0147\t0.0145\t0.0141\n",
      "bin_feat_b\t\t-0.0117\t-0.0123\t-0.0120\n",
      "bin_feat_c\t\t-0.0082\t-0.0085\t-0.0082\n",
      "bin_feat_d\t\t0.0012\t0.0010\t0.0010\n",
      "bin_feat_e\t\t-0.0000\t-0.0001\t-0.0001\n",
      "salt\t\t0.0404\t0.0526\t0.0417\n",
      "u_answer\t\t0.1213\t0.1572\t0.1295\n",
      "u_good_answer\t\t0.0025\t0.0039\t0.0038\n",
      "u_recommand_answer\t\t0.0003\t0.0002\t0.0002\n",
      "u_image_answer\t\t-0.0121\t0.0209\t0.0190\n",
      "u_video_answer\t\t-0.0065\t0.0101\t0.0097\n",
      "u_word_avg\t\t-0.0024\t0.0629\t0.0509\n",
      "u_like_avg\t\t-0.0063\t-0.0116\t-0.0106\n",
      "u_unlike_avg\t\t-0.0075\t-0.0163\t-0.0156\n",
      "u_comment_avg\t\t-0.0083\t0.0073\t0.0067\n",
      "u_collect_avg\t\t-0.0028\t-0.0118\t-0.0112\n",
      "u_thanks_avg\t\t-0.0039\t-0.0196\t-0.0187\n",
      "u_report_avg\t\t-0.0005\t-0.0004\t-0.0004\n",
      "u_nohelp_avg\t\t-0.0045\t-0.0089\t-0.0086\n",
      "u_oppose_avg\t\t-0.0075\t-0.0163\t-0.0156\n",
      "q_answer\t\t0.0867\t0.3735\t0.3184\n",
      "q_good_answer\t\t0.0238\t0.0249\t0.0241\n",
      "q_recommand_answer\t\t0.0026\t0.0029\t0.0028\n",
      "q_image_answer\t\t0.0600\t0.1606\t0.1499\n",
      "q_video_answer\t\t0.0218\t0.0546\t0.0528\n",
      "q_word_avg\t\t0.1102\t0.3398\t0.2791\n",
      "q_like\t\t0.0170\t0.2100\t0.1878\n",
      "q_comment\t\t0.0268\t0.2064\t0.1853\n",
      "q_collect\t\t0.0058\t0.1424\t0.1323\n",
      "q_thanks\t\t0.0115\t0.1722\t0.1581\n"
     ]
    }
   ],
   "source": [
    "for i in ['invite_hour', 'follow_topic_hit', \n",
    "             'interest_topic_hit', 'bin_feat_a', 'bin_feat_b', \n",
    "             'bin_feat_c', 'bin_feat_d', 'bin_feat_e', 'salt', 'u_answer', \n",
    "             'u_good_answer', 'u_recommand_answer', 'u_image_answer', 'u_video_answer', \n",
    "             'u_word_avg', 'u_like_avg', 'u_unlike_avg', 'u_comment_avg', \n",
    "             'u_collect_avg', 'u_thanks_avg', 'u_report_avg','u_nohelp_avg', \n",
    "             'u_oppose_avg', 'q_answer', 'q_good_answer', 'q_recommand_answer',\n",
    "             'q_image_answer', 'q_video_answer', 'q_word_avg', 'q_like', 'q_comment', \n",
    "             'q_collect', 'q_thanks']:\n",
    "    k1 = data['do_answer'].corr(data[i], method='pearson')\n",
    "    k2 = data['do_answer'].corr(data[i], method='spearman')\n",
    "    k3 = data['do_answer'].corr(data[i], method='kendall')\n",
    "    print('%s\\t\\t%.4f\\t%.4f\\t%.4f' % (i, k1, k2, k3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 处理数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清洗数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['q_id', 'u_id', 'do_answer', 'invite_hour', 'follow_topic_hit',\n",
       "       'interest_topic_hit', 'bin_feat_a', 'bin_feat_b', 'bin_feat_c',\n",
       "       'bin_feat_d', 'bin_feat_e', 'salt', 'u_answer', 'u_good_answer',\n",
       "       'u_recommand_answer', 'u_image_answer', 'u_video_answer', 'u_word_avg',\n",
       "       'u_like_avg', 'u_unlike_avg', 'u_comment_avg', 'u_collect_avg',\n",
       "       'u_thanks_avg', 'u_report_avg', 'u_nohelp_avg', 'u_oppose_avg',\n",
       "       'q_answer', 'q_good_answer', 'q_recommand_answer', 'q_image_answer',\n",
       "       'q_video_answer', 'q_word_avg', 'q_like', 'q_comment', 'q_collect',\n",
       "       'q_thanks', 'sex', 'access_freq', 'multi_feat_a', 'multi_feat_b',\n",
       "       'multi_feat_c', 'multi_feat_d', 'multi_feat_e'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stable_col_list = ['q_id', 'u_id', 'do_answer']\n",
    "good_col_list = ['follow_topic_hit', 'interest_topic_hit', 'bin_feat_a',\n",
    "                 'salt', 'u_answer', 'u_image_answer', 'u_video_answer', \n",
    "                 'u_word_avg', 'q_answer', 'q_good_answer',\n",
    "                 'q_image_answer', 'q_video_answer', 'q_word_avg', 'q_like', 'q_comment', \n",
    "                 'q_collect', 'q_thanks']\n",
    "good_bad_col_list = ['invite_hour', 'follow_topic_hit', \n",
    "             'interest_topic_hit', 'bin_feat_a', 'bin_feat_b', \n",
    "             'bin_feat_c', 'bin_feat_d', 'bin_feat_e', 'salt', 'u_answer', \n",
    "             'u_good_answer', 'u_recommand_answer', 'u_image_answer', 'u_video_answer', \n",
    "             'u_word_avg', 'u_like_avg', 'u_unlike_avg', 'u_comment_avg', \n",
    "             'u_collect_avg', 'u_thanks_avg', 'u_report_avg','u_nohelp_avg', \n",
    "             'u_oppose_avg', 'q_answer', 'q_good_answer', 'q_recommand_answer',\n",
    "             'q_image_answer', 'q_video_answer', 'q_word_avg', 'q_like', 'q_comment', \n",
    "             'q_collect', 'q_thanks']\n",
    "other_col_list = ['sex', 'access_freq', 'multi_feat_a', 'multi_feat_b', \n",
    "                  'multi_feat_c','multi_feat_d','multi_feat_e']\n",
    "data = data[stable_col_list + good_bad_col_list + other_col_list]\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "离散特征的`LabelEncoder`编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>u_id</th>\n",
       "      <th>do_answer</th>\n",
       "      <th>invite_hour</th>\n",
       "      <th>follow_topic_hit</th>\n",
       "      <th>interest_topic_hit</th>\n",
       "      <th>bin_feat_a</th>\n",
       "      <th>bin_feat_b</th>\n",
       "      <th>bin_feat_c</th>\n",
       "      <th>bin_feat_d</th>\n",
       "      <th>...</th>\n",
       "      <th>q_comment</th>\n",
       "      <th>q_collect</th>\n",
       "      <th>q_thanks</th>\n",
       "      <th>sex</th>\n",
       "      <th>access_freq</th>\n",
       "      <th>multi_feat_a</th>\n",
       "      <th>multi_feat_b</th>\n",
       "      <th>multi_feat_c</th>\n",
       "      <th>multi_feat_d</th>\n",
       "      <th>multi_feat_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2166419046</td>\n",
       "      <td>M401693808</td>\n",
       "      <td>0</td>\n",
       "      <td>1.546644</td>\n",
       "      <td>1.313413</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>-1.404298</td>\n",
       "      <td>1.532982</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1917</td>\n",
       "      <td>170</td>\n",
       "      <td>244</td>\n",
       "      <td>799</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1550017551</td>\n",
       "      <td>M3392373099</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.389192</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070538</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>249</td>\n",
       "      <td>657</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q604029601</td>\n",
       "      <td>M2317670257</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314748</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1380</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q2350061229</td>\n",
       "      <td>M1618461867</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.389192</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>2.528689</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>1.690382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063124</td>\n",
       "      <td>-0.028304</td>\n",
       "      <td>-0.041673</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>244</td>\n",
       "      <td>799</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q2443223942</td>\n",
       "      <td>M3544409350</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.621091</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066831</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>506</td>\n",
       "      <td>204</td>\n",
       "      <td>175</td>\n",
       "      <td>705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q640765464</td>\n",
       "      <td>M2818659842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490733</td>\n",
       "      <td>1.313413</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1380</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q795459266</td>\n",
       "      <td>M2818659842</td>\n",
       "      <td>0</td>\n",
       "      <td>1.194672</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055711</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1380</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q190554387</td>\n",
       "      <td>M1581217469</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.917147</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066831</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.041673</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q1958712851</td>\n",
       "      <td>M3021021791</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018691</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>-1.404298</td>\n",
       "      <td>1.532982</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074245</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1486</td>\n",
       "      <td>170</td>\n",
       "      <td>249</td>\n",
       "      <td>657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q311993584</td>\n",
       "      <td>M1766315480</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314748</td>\n",
       "      <td>-0.438017</td>\n",
       "      <td>-0.274834</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>-0.652323</td>\n",
       "      <td>-0.201699</td>\n",
       "      <td>-0.591582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048297</td>\n",
       "      <td>-0.028304</td>\n",
       "      <td>-0.036537</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1092</td>\n",
       "      <td>115</td>\n",
       "      <td>370</td>\n",
       "      <td>1252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          q_id         u_id  do_answer  invite_hour  follow_topic_hit  \\\n",
       "0  Q2166419046   M401693808          0     1.546644          1.313413   \n",
       "1  Q1550017551  M3392373099          0    -0.389192         -0.438017   \n",
       "2   Q604029601  M2317670257          0     0.314748         -0.438017   \n",
       "3  Q2350061229  M1618461867          0    -0.389192         -0.438017   \n",
       "4  Q2443223942  M3544409350          0    -1.621091         -0.438017   \n",
       "5   Q640765464  M2818659842          0     0.490733          1.313413   \n",
       "6   Q795459266  M2818659842          0     1.194672         -0.438017   \n",
       "7   Q190554387  M1581217469          1    -0.917147         -0.438017   \n",
       "8  Q1958712851  M3021021791          0     1.018691         -0.438017   \n",
       "9   Q311993584  M1766315480          0     0.314748         -0.438017   \n",
       "\n",
       "   interest_topic_hit  bin_feat_a  bin_feat_b  bin_feat_c  bin_feat_d  ...  \\\n",
       "0           -0.274834   -1.404298    1.532982   -0.201699   -0.591582  ...   \n",
       "1           -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "2           -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "3            2.528689    0.712100   -0.652323   -0.201699    1.690382  ...   \n",
       "4           -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "5           -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "6           -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "7           -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "8           -0.274834   -1.404298    1.532982   -0.201699   -0.591582  ...   \n",
       "9           -0.274834    0.712100   -0.652323   -0.201699   -0.591582  ...   \n",
       "\n",
       "   q_comment  q_collect  q_thanks  sex  access_freq  multi_feat_a  \\\n",
       "0  -0.074245  -0.028820 -0.044241    2            4          1917   \n",
       "1  -0.070538  -0.028820 -0.044241    2            1          1092   \n",
       "2  -0.074245  -0.028820 -0.044241    2            4          1380   \n",
       "3  -0.063124  -0.028304 -0.041673    2            0          1092   \n",
       "4  -0.066831  -0.028820 -0.044241    2            1           506   \n",
       "5  -0.074245  -0.028820 -0.044241    1            0          1380   \n",
       "6  -0.055711  -0.028820 -0.044241    1            0          1380   \n",
       "7  -0.066831  -0.028820 -0.041673    2            1          1092   \n",
       "8  -0.074245  -0.028820 -0.044241    2            4          1486   \n",
       "9  -0.048297  -0.028304 -0.036537    1            0          1092   \n",
       "\n",
       "   multi_feat_b  multi_feat_c  multi_feat_d  multi_feat_e  \n",
       "0           170           244           799             1  \n",
       "1           115           249           657             0  \n",
       "2           206             0           440             1  \n",
       "3           115           244           799             1  \n",
       "4           204           175           705             1  \n",
       "5           206             0           440             1  \n",
       "6           206             0           440             1  \n",
       "7           115             0           128             1  \n",
       "8           170           249           657             1  \n",
       "9           115           370          1252             1  \n",
       "\n",
       "[10 rows x 43 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 离散值编码\n",
    "encoder = LabelEncoder()\n",
    "for i in other_col_list:\n",
    "    data[i] = encoder.fit_transform(data[i])\n",
    "    \n",
    "data.iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 包装数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# if DO_DATASET_BALANCE:\n",
    "#     temp = data[data['do_answer'] == 1]  # 用于均衡的数据\n",
    "#     print('用于均衡的数据有 %d 条.' % len(temp))\n",
    "#     train_x = data[data['do_answer']>-1].append([temp, temp, temp])\n",
    "# else:\n",
    "#     train_x = data[data['do_answer']>-1]\n",
    "# train_x, train_y = train_x[col_list[3:]].values, train_x[['do_answer']].values[:, 0]\n",
    "\n",
    "test_x = data[data['do_answer']==-1]\n",
    "test_x, test_y = test_x[good_bad_col_list + other_col_list].values, test_x['do_answer'].values\n",
    "# print('ok.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_len: 1682914\n",
      "neg_len: 7806219\n"
     ]
    }
   ],
   "source": [
    "# 正负样本df\n",
    "positive_samples = data[data['do_answer'] == 1]\n",
    "negative_samples = data[data['do_answer'] == 0]\n",
    "print('pos_len:', len(positive_samples))\n",
    "print('neg_len:', len(negative_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"每次new都会随机均衡数据集。\"\"\"\n",
    "    def __init__(self, mode='train'):\n",
    "        self.mode = mode\n",
    "        if mode == 'train':\n",
    "            train_x = pd.concat([\n",
    "                positive_samples,\n",
    "                negative_samples.sample(n=len(positive_samples), axis=0)\n",
    "            ], axis=0)\n",
    "            train_x, train_y = train_x[good_col_list + other_col_list].values, train_x['do_answer'].values\n",
    "            self.data = {\n",
    "                'x': train_x,\n",
    "                'y': train_y,\n",
    "            }\n",
    "        elif mode == 'test':\n",
    "            self.data = {\n",
    "                'x': test_x,\n",
    "                'y': test_y,\n",
    "            }\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        return self.data['x'][index], self.data['y'][index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data['x'])\n",
    "    \n",
    "    \n",
    "print('ok.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size, val_size, test_size = 0, 0, 0\n",
    "train_len, val_len, test_len = 0, 0, 0\n",
    "data_loader = {}\n",
    "\n",
    "def flush_dataloader(log=True):\n",
    "    global train_size, val_size, test_size, train_len, val_len, test_len, data_loader\n",
    "    \n",
    "    full_train_dataset = MyDataset(mode='train')\n",
    "    test_dataset = MyDataset(mode='test')\n",
    "\n",
    "    if TRAIN_ALL:\n",
    "        data_loader = {\n",
    "            'train': DataLoader(dataset=full_train_dataset, \n",
    "                                batch_size=BATCH_SIZE, \n",
    "                                num_workers=5,\n",
    "                                shuffle=True),\n",
    "            'test': DataLoader(dataset=test_dataset,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               num_workers=5,\n",
    "                               shuffle=False),\n",
    "        }\n",
    "        train_size = len(full_train_dataset)\n",
    "        test_size = len(test_dataset)\n",
    "    else:\n",
    "        train_size = int(0.8 * len(full_train_dataset))\n",
    "        val_size = len(full_train_dataset) - train_size\n",
    "        train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "        data_loader = {\n",
    "            'train': DataLoader(dataset=train_dataset, \n",
    "                                batch_size=BATCH_SIZE, \n",
    "                               num_workers=5,\n",
    "                                shuffle=True),\n",
    "            'val': DataLoader(dataset=val_dataset, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                               num_workers=5,\n",
    "                              shuffle=False),\n",
    "            'test': DataLoader(dataset=test_dataset,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               num_workers=5,\n",
    "                               shuffle=False),\n",
    "        }\n",
    "        train_size = len(train_dataset)\n",
    "        val_size = len(val_dataset)\n",
    "        test_size = len(test_dataset)\n",
    "\n",
    "    if log:\n",
    "        print('train_size:', train_size)\n",
    "        print('val_size:', val_size)\n",
    "        print('test_size:', test_size)\n",
    "\n",
    "    # 计算一轮enumerate的长度\n",
    "    train_len = math.ceil(train_size / BATCH_SIZE)\n",
    "    val_len = math.ceil(val_size / BATCH_SIZE)\n",
    "    test_len = math.ceil(test_size / BATCH_SIZE)\n",
    "\n",
    "    if log:\n",
    "        print('train_len:', train_len)\n",
    "        print('val_len:', val_len)\n",
    "        print('test_len:', test_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class MyNet_v2(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim=2, norm='dropout'):\n",
    "        super(MyNet_v2, self).__init__()\n",
    "        self.norm = norm\n",
    "\n",
    "        in_dim = in_dim+1+1+4+2+2+3\n",
    "        self.embed_sex = nn.Embedding(3, 2)\n",
    "        self.embed_access_freq = nn.Embedding(5, 2)\n",
    "        self.embed_multi_a = nn.Embedding(2561, 5)\n",
    "        self.embed_multi_b = nn.Embedding(291, 3)\n",
    "        self.embed_multi_c = nn.Embedding(428, 3)\n",
    "        self.embed_multi_d = nn.Embedding(1556, 4)\n",
    "        self.embed_multi_e = nn.Embedding(2, 1)\n",
    "        self.fc1 = nn.Linear(in_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, out_dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        if self.norm == 'batchnorm':\n",
    "            self.bn0 = nn.BatchNorm1d(in_dim)\n",
    "            self.bn1 = nn.BatchNorm1d(512)\n",
    "            self.bn2 = nn.BatchNorm1d(256)\n",
    "            self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        sex = self.embed_sex(x[:, -7].long())\n",
    "        access_freq = self.embed_access_freq(x[:, -6].long())\n",
    "        multi_a = self.embed_multi_a(x[:, -5].long())\n",
    "        multi_b = self.embed_multi_b(x[:, -4].long())\n",
    "        multi_c = self.embed_multi_c(x[:, -3].long())\n",
    "        multi_d = self.embed_multi_d(x[:, -2].long())\n",
    "        multi_e = self.embed_multi_e(x[:, -1].long())\n",
    "\n",
    "        out = x[:, :-7]\n",
    "        out = torch.cat(\n",
    "            (out, sex, access_freq, multi_a, multi_b, multi_c, multi_d, multi_e), dim=1)\n",
    "        \n",
    "        if self.norm is None:\n",
    "            out = self.fc1(out)\n",
    "            out = self.fc2(self.relu(out))\n",
    "            out = self.fc3(self.relu(out))\n",
    "            out = self.fc4(self.relu(out))\n",
    "        elif self.norm == 'dropout':\n",
    "            out = self.fc1(out)\n",
    "            out = F.dropout(out, p=0.5, training=self.training)\n",
    "            out = self.fc2(self.relu(out))\n",
    "            out = F.dropout(out, p=0.5, training=self.training)\n",
    "            out = self.fc3(self.relu(out))\n",
    "            out = F.dropout(out, p=0.5, training=self.training)\n",
    "            out = self.fc4(self.relu(out))\n",
    "        else:\n",
    "            out = self.fc1(self.bn0(out))\n",
    "            out = self.fc2(self.relu(self.bn1(out)))\n",
    "            out = self.fc3(self.relu(self.bn2(out)))\n",
    "            out = self.fc4(self.relu(self.bn3(out)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNet_v2(\n",
       "  (embed_sex): Embedding(3, 2)\n",
       "  (embed_access_freq): Embedding(5, 2)\n",
       "  (embed_multi_a): Embedding(2561, 5)\n",
       "  (embed_multi_b): Embedding(291, 3)\n",
       "  (embed_multi_c): Embedding(428, 3)\n",
       "  (embed_multi_d): Embedding(1556, 4)\n",
       "  (embed_multi_e): Embedding(2, 1)\n",
       "  (fc1): Linear(in_features=37, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from my_model import MyNet_v2_1\n",
    "\n",
    "net = MyNet_v2(len(good_col_list + other_col_list)).to(DEVICE)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 优化器、损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 3\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import optim, nn\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.75)\n",
    "\n",
    "'ok'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6026, Acc: 0.2419: 100%|██████████| 52/52 [00:16<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6021, Acc: 0.6743, Lr: 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.5999, Acc: 0.2412: 100%|██████████| 52/52 [00:15<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.6015, Acc: 0.6748, Lr: 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.6023, Acc: 0.2429: 100%|██████████| 52/52 [00:15<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.6012, Acc: 0.6749, Lr: 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    count, running_correct, running_loss = 0, 0, 0\n",
    "    flush_dataloader(log=False)\n",
    "    \n",
    "    net.train()\n",
    "    with tqdm(total=train_len) as pbar:\n",
    "        for step, (bx, by) in enumerate(data_loader['train']):\n",
    "            # 训练\n",
    "            bx = bx.float().to(DEVICE)\n",
    "            by = by.long().to(DEVICE)\n",
    "\n",
    "            prediction = net(bx)\n",
    "            loss = loss_function(prediction, by)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 统计成效\n",
    "            pre = torch.argmax(torch.softmax(prediction, dim=1), dim=1)\n",
    "            my_loss = float(loss.data.cpu().numpy())\n",
    "            my_correct = sum(pre.cpu().numpy() == by.cpu().numpy())\n",
    "            my_acc = my_correct / BATCH_SIZE\n",
    "            count += 1\n",
    "            running_loss += my_loss\n",
    "            running_correct += my_correct\n",
    "            \n",
    "            # 更新进度条\n",
    "            pbar.update(1)\n",
    "            pbar.set_description('Epoch: %d, Loss: %.4f, Acc: %.4f' % (\n",
    "                                  epoch, \n",
    "                                  my_loss, \n",
    "                                  my_acc))\n",
    "    \n",
    "    # 输出一轮结果\n",
    "    print('Epoch: %d, Loss: %.4f, Acc: %.4f, Lr: %.5f' % (\n",
    "           epoch,\n",
    "           running_loss / count,\n",
    "           running_correct / train_size,\n",
    "           optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    \n",
    "    # 保存参数\n",
    "    torch.save(net.state_dict(), PKL_DIR_OUT)\n",
    "    \n",
    "    # lr scheduler\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 存储网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), PKL_DIR_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 LightGBM分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-81ce04510f1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgood_bad_col_list\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mother_col_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\RAYIOOO\\Programmings\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2938\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2940\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2942\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\RAYIOOO\\Programmings\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take\u001b[1;34m(self, indices, axis, is_copy)\u001b[0m\n\u001b[0;32m   3357\u001b[0m         new_data = self._data.take(indices,\n\u001b[0;32m   3358\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3359\u001b[1;33m                                    verify=True)\n\u001b[0m\u001b[0;32m   3360\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\RAYIOOO\\Programmings\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[1;32m-> 1350\u001b[1;33m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\RAYIOOO\\Programmings\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   1229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m             new_blocks = self._slice_take_blocks_ax0(indexer,\n\u001b[1;32m-> 1231\u001b[1;33m                                                      fill_tuple=(fill_value,))\n\u001b[0m\u001b[0;32m   1232\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n",
      "\u001b[1;32mC:\\RAYIOOO\\Programmings\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[0;32m   1310\u001b[0m                     blocks.append(blk.take_nd(blklocs[mgr_locs.indexer],\n\u001b[0;32m   1311\u001b[0m                                               \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1312\u001b[1;33m                                               fill_tuple=None))\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\RAYIOOO\\Programmings\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[0;32m   1232\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[1;32m-> 1234\u001b[1;33m                                        allow_fill=False, fill_value=fill_value)\n\u001b[0m\u001b[0;32m   1235\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1236\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\RAYIOOO\\Programmings\\Anaconda\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[0;32m   1649\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1651\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1653\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data[good_bad_col_list + other_col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-55594436bf9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgood_bad_col_list\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mother_col_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'do_answer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\RAYIOOO\\Programmings\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2938\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2940\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2942\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\RAYIOOO\\Programmings\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take\u001b[1;34m(self, indices, axis, is_copy)\u001b[0m\n\u001b[0;32m   3357\u001b[0m         new_data = self._data.take(indices,\n\u001b[0;32m   3358\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3359\u001b[1;33m                                    verify=True)\n\u001b[0m\u001b[0;32m   3360\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\RAYIOOO\\Programmings\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[1;32m-> 1350\u001b[1;33m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\RAYIOOO\\Programmings\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   1229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m             new_blocks = self._slice_take_blocks_ax0(indexer,\n\u001b[1;32m-> 1231\u001b[1;33m                                                      fill_tuple=(fill_value,))\n\u001b[0m\u001b[0;32m   1232\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n",
      "\u001b[1;32mC:\\RAYIOOO\\Programmings\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[0;32m   1310\u001b[0m                     blocks.append(blk.take_nd(blklocs[mgr_locs.indexer],\n\u001b[0;32m   1311\u001b[0m                                               \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1312\u001b[1;33m                                               fill_tuple=None))\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\RAYIOOO\\Programmings\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[0;32m   1232\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[1;32m-> 1234\u001b[1;33m                                        allow_fill=False, fill_value=fill_value)\n\u001b[0m\u001b[0;32m   1235\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1236\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\RAYIOOO\\Programmings\\Anaconda\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[0;32m   1649\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1651\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1653\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "tmp = data[good_bad_col_list + other_col_list]\n",
    "train_x = tmp[:train.shape[0]].values\n",
    "train_y = data[:train.shape[0]]['do_answer'].values\n",
    "test_x = tmp[train.shape[0]:].values\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1,\n",
       "               importance_type='split', learning_rate=0.01, max_bin=425,\n",
       "               max_depth=-1, min_child_samples=10, min_child_weight=5,\n",
       "               min_split_gain=0, n_estimators=2000, n_jobs=-1, num_leaves=64,\n",
       "               objective='binary', random_state=None, reg_alpha=3, reg_lambda=5,\n",
       "               seed=1000, silent=True, subsample=0.8, subsample_for_bin=50000,\n",
       "               subsample_freq=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb = LGBMClassifier(boosting_type='gbdt', num_leaves=64, learning_rate=0.01, n_estimators=2000,\n",
    "                           max_bin=425, subsample_for_bin=50000, objective='binary', min_split_gain=0,\n",
    "                           min_child_weight=5, min_child_samples=10, subsample=0.8, subsample_freq=1,\n",
    "                           colsample_bytree=1, reg_alpha=3, reg_lambda=5, seed=1000, n_jobs=-1, silent=True)\n",
    "model_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain's auc: 0.798745\ttrain's binary_logloss: 0.46561\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttrain's auc: 0.799619\ttrain's binary_logloss: 0.463913\n",
      "[3]\ttrain's auc: 0.800084\ttrain's binary_logloss: 0.462259\n",
      "[4]\ttrain's auc: 0.800877\ttrain's binary_logloss: 0.460639\n",
      "[5]\ttrain's auc: 0.801082\ttrain's binary_logloss: 0.459064\n",
      "[6]\ttrain's auc: 0.801163\ttrain's binary_logloss: 0.457523\n",
      "[7]\ttrain's auc: 0.801276\ttrain's binary_logloss: 0.45602\n",
      "[8]\ttrain's auc: 0.801307\ttrain's binary_logloss: 0.454554\n",
      "[9]\ttrain's auc: 0.801458\ttrain's binary_logloss: 0.45312\n",
      "[10]\ttrain's auc: 0.801632\ttrain's binary_logloss: 0.451714\n",
      "[11]\ttrain's auc: 0.801739\ttrain's binary_logloss: 0.450344\n",
      "[12]\ttrain's auc: 0.801896\ttrain's binary_logloss: 0.449002\n",
      "[13]\ttrain's auc: 0.80217\ttrain's binary_logloss: 0.447685\n",
      "[14]\ttrain's auc: 0.802392\ttrain's binary_logloss: 0.446397\n",
      "[15]\ttrain's auc: 0.802493\ttrain's binary_logloss: 0.445139\n",
      "[16]\ttrain's auc: 0.802579\ttrain's binary_logloss: 0.443906\n",
      "[17]\ttrain's auc: 0.802632\ttrain's binary_logloss: 0.4427\n",
      "[18]\ttrain's auc: 0.802909\ttrain's binary_logloss: 0.441508\n",
      "[19]\ttrain's auc: 0.802998\ttrain's binary_logloss: 0.44035\n",
      "[20]\ttrain's auc: 0.803069\ttrain's binary_logloss: 0.439217\n",
      "[21]\ttrain's auc: 0.803276\ttrain's binary_logloss: 0.438094\n",
      "[22]\ttrain's auc: 0.803396\ttrain's binary_logloss: 0.436994\n",
      "[23]\ttrain's auc: 0.803607\ttrain's binary_logloss: 0.435911\n",
      "[24]\ttrain's auc: 0.803701\ttrain's binary_logloss: 0.434855\n",
      "[25]\ttrain's auc: 0.803778\ttrain's binary_logloss: 0.43382\n",
      "[26]\ttrain's auc: 0.803924\ttrain's binary_logloss: 0.432799\n",
      "[27]\ttrain's auc: 0.804052\ttrain's binary_logloss: 0.4318\n",
      "[28]\ttrain's auc: 0.804396\ttrain's binary_logloss: 0.430804\n",
      "[29]\ttrain's auc: 0.804647\ttrain's binary_logloss: 0.429828\n",
      "[30]\ttrain's auc: 0.804688\ttrain's binary_logloss: 0.428885\n",
      "[31]\ttrain's auc: 0.804873\ttrain's binary_logloss: 0.427944\n",
      "[32]\ttrain's auc: 0.80498\ttrain's binary_logloss: 0.42703\n",
      "[33]\ttrain's auc: 0.805275\ttrain's binary_logloss: 0.426113\n",
      "[34]\ttrain's auc: 0.805459\ttrain's binary_logloss: 0.425226\n",
      "[35]\ttrain's auc: 0.805609\ttrain's binary_logloss: 0.42435\n",
      "[36]\ttrain's auc: 0.805714\ttrain's binary_logloss: 0.423494\n",
      "[37]\ttrain's auc: 0.805795\ttrain's binary_logloss: 0.422656\n",
      "[38]\ttrain's auc: 0.80602\ttrain's binary_logloss: 0.421815\n",
      "[39]\ttrain's auc: 0.806201\ttrain's binary_logloss: 0.420991\n",
      "[40]\ttrain's auc: 0.806217\ttrain's binary_logloss: 0.420201\n",
      "[41]\ttrain's auc: 0.806407\ttrain's binary_logloss: 0.419406\n",
      "[42]\ttrain's auc: 0.806463\ttrain's binary_logloss: 0.418642\n",
      "[43]\ttrain's auc: 0.807196\ttrain's binary_logloss: 0.417873\n",
      "[44]\ttrain's auc: 0.807315\ttrain's binary_logloss: 0.417124\n",
      "[45]\ttrain's auc: 0.807354\ttrain's binary_logloss: 0.416399\n",
      "[46]\ttrain's auc: 0.807536\ttrain's binary_logloss: 0.415665\n",
      "[47]\ttrain's auc: 0.807652\ttrain's binary_logloss: 0.414947\n",
      "[48]\ttrain's auc: 0.807751\ttrain's binary_logloss: 0.414248\n",
      "[49]\ttrain's auc: 0.808147\ttrain's binary_logloss: 0.413556\n",
      "[50]\ttrain's auc: 0.80816\ttrain's binary_logloss: 0.412889\n",
      "[51]\ttrain's auc: 0.808213\ttrain's binary_logloss: 0.412228\n",
      "[52]\ttrain's auc: 0.808353\ttrain's binary_logloss: 0.411565\n",
      "[53]\ttrain's auc: 0.808465\ttrain's binary_logloss: 0.410916\n",
      "[54]\ttrain's auc: 0.808544\ttrain's binary_logloss: 0.410288\n",
      "[55]\ttrain's auc: 0.808658\ttrain's binary_logloss: 0.409656\n",
      "[56]\ttrain's auc: 0.808701\ttrain's binary_logloss: 0.409042\n",
      "[57]\ttrain's auc: 0.808806\ttrain's binary_logloss: 0.408428\n",
      "[58]\ttrain's auc: 0.808923\ttrain's binary_logloss: 0.407832\n",
      "[59]\ttrain's auc: 0.80913\ttrain's binary_logloss: 0.407242\n",
      "[60]\ttrain's auc: 0.80922\ttrain's binary_logloss: 0.406666\n",
      "[61]\ttrain's auc: 0.809289\ttrain's binary_logloss: 0.406095\n",
      "[62]\ttrain's auc: 0.809397\ttrain's binary_logloss: 0.405525\n",
      "[63]\ttrain's auc: 0.809474\ttrain's binary_logloss: 0.404974\n",
      "[64]\ttrain's auc: 0.809528\ttrain's binary_logloss: 0.404432\n",
      "[65]\ttrain's auc: 0.809601\ttrain's binary_logloss: 0.403895\n",
      "[66]\ttrain's auc: 0.809691\ttrain's binary_logloss: 0.40336\n",
      "[67]\ttrain's auc: 0.809732\ttrain's binary_logloss: 0.402844\n",
      "[68]\ttrain's auc: 0.809835\ttrain's binary_logloss: 0.40232\n",
      "[69]\ttrain's auc: 0.809926\ttrain's binary_logloss: 0.401808\n",
      "[70]\ttrain's auc: 0.809965\ttrain's binary_logloss: 0.401318\n",
      "[71]\ttrain's auc: 0.810018\ttrain's binary_logloss: 0.400828\n",
      "[72]\ttrain's auc: 0.810054\ttrain's binary_logloss: 0.400351\n",
      "[73]\ttrain's auc: 0.810063\ttrain's binary_logloss: 0.399884\n",
      "[74]\ttrain's auc: 0.81011\ttrain's binary_logloss: 0.399422\n",
      "[75]\ttrain's auc: 0.810202\ttrain's binary_logloss: 0.398947\n",
      "[76]\ttrain's auc: 0.810243\ttrain's binary_logloss: 0.398493\n",
      "[77]\ttrain's auc: 0.810299\ttrain's binary_logloss: 0.398047\n",
      "[78]\ttrain's auc: 0.810394\ttrain's binary_logloss: 0.397592\n",
      "[79]\ttrain's auc: 0.810455\ttrain's binary_logloss: 0.397156\n",
      "[80]\ttrain's auc: 0.810528\ttrain's binary_logloss: 0.39672\n",
      "[81]\ttrain's auc: 0.810636\ttrain's binary_logloss: 0.396278\n",
      "[82]\ttrain's auc: 0.810707\ttrain's binary_logloss: 0.395854\n",
      "[83]\ttrain's auc: 0.810736\ttrain's binary_logloss: 0.39545\n",
      "[84]\ttrain's auc: 0.810882\ttrain's binary_logloss: 0.395018\n",
      "[85]\ttrain's auc: 0.810921\ttrain's binary_logloss: 0.394624\n",
      "[86]\ttrain's auc: 0.811094\ttrain's binary_logloss: 0.394214\n",
      "[87]\ttrain's auc: 0.811225\ttrain's binary_logloss: 0.3938\n",
      "[88]\ttrain's auc: 0.811293\ttrain's binary_logloss: 0.393405\n",
      "[89]\ttrain's auc: 0.811378\ttrain's binary_logloss: 0.393016\n",
      "[90]\ttrain's auc: 0.8114\ttrain's binary_logloss: 0.392652\n",
      "[91]\ttrain's auc: 0.811514\ttrain's binary_logloss: 0.392264\n",
      "[92]\ttrain's auc: 0.811601\ttrain's binary_logloss: 0.391886\n",
      "[93]\ttrain's auc: 0.811679\ttrain's binary_logloss: 0.391521\n",
      "[94]\ttrain's auc: 0.811765\ttrain's binary_logloss: 0.391158\n",
      "[95]\ttrain's auc: 0.811801\ttrain's binary_logloss: 0.390816\n",
      "[96]\ttrain's auc: 0.811862\ttrain's binary_logloss: 0.390466\n",
      "[97]\ttrain's auc: 0.811923\ttrain's binary_logloss: 0.39012\n",
      "[98]\ttrain's auc: 0.812009\ttrain's binary_logloss: 0.389774\n",
      "[99]\ttrain's auc: 0.812077\ttrain's binary_logloss: 0.389442\n",
      "[100]\ttrain's auc: 0.812121\ttrain's binary_logloss: 0.389117\n",
      "[101]\ttrain's auc: 0.812214\ttrain's binary_logloss: 0.388782\n",
      "[102]\ttrain's auc: 0.812282\ttrain's binary_logloss: 0.388459\n",
      "[103]\ttrain's auc: 0.812367\ttrain's binary_logloss: 0.388138\n",
      "[104]\ttrain's auc: 0.812456\ttrain's binary_logloss: 0.387816\n",
      "[105]\ttrain's auc: 0.812511\ttrain's binary_logloss: 0.387507\n",
      "[106]\ttrain's auc: 0.812578\ttrain's binary_logloss: 0.3872\n",
      "[107]\ttrain's auc: 0.812632\ttrain's binary_logloss: 0.3869\n",
      "[108]\ttrain's auc: 0.812766\ttrain's binary_logloss: 0.386605\n",
      "[109]\ttrain's auc: 0.812803\ttrain's binary_logloss: 0.386317\n",
      "[110]\ttrain's auc: 0.812894\ttrain's binary_logloss: 0.386016\n",
      "[111]\ttrain's auc: 0.812914\ttrain's binary_logloss: 0.385743\n",
      "[112]\ttrain's auc: 0.813019\ttrain's binary_logloss: 0.385446\n",
      "[113]\ttrain's auc: 0.813081\ttrain's binary_logloss: 0.385166\n",
      "[114]\ttrain's auc: 0.813132\ttrain's binary_logloss: 0.38489\n",
      "[115]\ttrain's auc: 0.813219\ttrain's binary_logloss: 0.384609\n",
      "[116]\ttrain's auc: 0.813306\ttrain's binary_logloss: 0.384341\n",
      "[117]\ttrain's auc: 0.813338\ttrain's binary_logloss: 0.384086\n",
      "[118]\ttrain's auc: 0.813458\ttrain's binary_logloss: 0.383817\n",
      "[119]\ttrain's auc: 0.813521\ttrain's binary_logloss: 0.383557\n",
      "[120]\ttrain's auc: 0.813535\ttrain's binary_logloss: 0.383313\n",
      "[121]\ttrain's auc: 0.813608\ttrain's binary_logloss: 0.383051\n",
      "[122]\ttrain's auc: 0.813651\ttrain's binary_logloss: 0.382807\n",
      "[123]\ttrain's auc: 0.813697\ttrain's binary_logloss: 0.382565\n",
      "[124]\ttrain's auc: 0.813724\ttrain's binary_logloss: 0.38233\n",
      "[125]\ttrain's auc: 0.813855\ttrain's binary_logloss: 0.382081\n",
      "[126]\ttrain's auc: 0.813926\ttrain's binary_logloss: 0.381836\n",
      "[127]\ttrain's auc: 0.813949\ttrain's binary_logloss: 0.381613\n",
      "[128]\ttrain's auc: 0.814008\ttrain's binary_logloss: 0.381384\n",
      "[129]\ttrain's auc: 0.814068\ttrain's binary_logloss: 0.381164\n",
      "[130]\ttrain's auc: 0.81415\ttrain's binary_logloss: 0.380943\n",
      "[131]\ttrain's auc: 0.814206\ttrain's binary_logloss: 0.380716\n",
      "[132]\ttrain's auc: 0.814273\ttrain's binary_logloss: 0.380498\n",
      "[133]\ttrain's auc: 0.814307\ttrain's binary_logloss: 0.380287\n",
      "[134]\ttrain's auc: 0.814378\ttrain's binary_logloss: 0.38007\n",
      "[135]\ttrain's auc: 0.814473\ttrain's binary_logloss: 0.379851\n",
      "[136]\ttrain's auc: 0.8145\ttrain's binary_logloss: 0.37965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137]\ttrain's auc: 0.814608\ttrain's binary_logloss: 0.379427\n",
      "[138]\ttrain's auc: 0.814689\ttrain's binary_logloss: 0.379211\n",
      "[139]\ttrain's auc: 0.814792\ttrain's binary_logloss: 0.378992\n",
      "[140]\ttrain's auc: 0.814848\ttrain's binary_logloss: 0.37879\n",
      "[141]\ttrain's auc: 0.814919\ttrain's binary_logloss: 0.378581\n",
      "[142]\ttrain's auc: 0.815013\ttrain's binary_logloss: 0.378369\n",
      "[143]\ttrain's auc: 0.815071\ttrain's binary_logloss: 0.378175\n",
      "[144]\ttrain's auc: 0.815127\ttrain's binary_logloss: 0.37798\n",
      "[145]\ttrain's auc: 0.815297\ttrain's binary_logloss: 0.377752\n",
      "[146]\ttrain's auc: 0.815398\ttrain's binary_logloss: 0.377545\n",
      "[147]\ttrain's auc: 0.815468\ttrain's binary_logloss: 0.377356\n",
      "[148]\ttrain's auc: 0.815525\ttrain's binary_logloss: 0.377172\n",
      "[149]\ttrain's auc: 0.815586\ttrain's binary_logloss: 0.376985\n",
      "[150]\ttrain's auc: 0.815651\ttrain's binary_logloss: 0.376799\n",
      "[151]\ttrain's auc: 0.815735\ttrain's binary_logloss: 0.37661\n",
      "[152]\ttrain's auc: 0.815789\ttrain's binary_logloss: 0.376434\n",
      "[153]\ttrain's auc: 0.815887\ttrain's binary_logloss: 0.376243\n",
      "[154]\ttrain's auc: 0.815948\ttrain's binary_logloss: 0.37607\n",
      "[155]\ttrain's auc: 0.816035\ttrain's binary_logloss: 0.375886\n",
      "[156]\ttrain's auc: 0.816089\ttrain's binary_logloss: 0.375714\n",
      "[157]\ttrain's auc: 0.816128\ttrain's binary_logloss: 0.375554\n",
      "[158]\ttrain's auc: 0.816182\ttrain's binary_logloss: 0.375384\n",
      "[159]\ttrain's auc: 0.816246\ttrain's binary_logloss: 0.375216\n",
      "[160]\ttrain's auc: 0.816312\ttrain's binary_logloss: 0.375051\n",
      "[161]\ttrain's auc: 0.816328\ttrain's binary_logloss: 0.374904\n",
      "[162]\ttrain's auc: 0.816363\ttrain's binary_logloss: 0.374753\n",
      "[163]\ttrain's auc: 0.816415\ttrain's binary_logloss: 0.374597\n",
      "[164]\ttrain's auc: 0.816513\ttrain's binary_logloss: 0.374421\n",
      "[165]\ttrain's auc: 0.816565\ttrain's binary_logloss: 0.374266\n",
      "[166]\ttrain's auc: 0.816615\ttrain's binary_logloss: 0.374117\n",
      "[167]\ttrain's auc: 0.81675\ttrain's binary_logloss: 0.373931\n",
      "[168]\ttrain's auc: 0.816776\ttrain's binary_logloss: 0.373792\n",
      "[169]\ttrain's auc: 0.816843\ttrain's binary_logloss: 0.37364\n",
      "[170]\ttrain's auc: 0.816934\ttrain's binary_logloss: 0.373474\n",
      "[171]\ttrain's auc: 0.817004\ttrain's binary_logloss: 0.373325\n",
      "[172]\ttrain's auc: 0.817052\ttrain's binary_logloss: 0.373184\n",
      "[173]\ttrain's auc: 0.817177\ttrain's binary_logloss: 0.373018\n",
      "[174]\ttrain's auc: 0.81726\ttrain's binary_logloss: 0.372865\n",
      "[175]\ttrain's auc: 0.817407\ttrain's binary_logloss: 0.372687\n",
      "[176]\ttrain's auc: 0.817529\ttrain's binary_logloss: 0.372518\n",
      "[177]\ttrain's auc: 0.817611\ttrain's binary_logloss: 0.37237\n",
      "[178]\ttrain's auc: 0.817626\ttrain's binary_logloss: 0.372252\n",
      "[179]\ttrain's auc: 0.817711\ttrain's binary_logloss: 0.372108\n",
      "[180]\ttrain's auc: 0.817748\ttrain's binary_logloss: 0.371984\n",
      "[181]\ttrain's auc: 0.817825\ttrain's binary_logloss: 0.371841\n",
      "[182]\ttrain's auc: 0.817878\ttrain's binary_logloss: 0.371709\n",
      "[183]\ttrain's auc: 0.81796\ttrain's binary_logloss: 0.371566\n",
      "[184]\ttrain's auc: 0.818009\ttrain's binary_logloss: 0.371439\n",
      "[185]\ttrain's auc: 0.818051\ttrain's binary_logloss: 0.371317\n",
      "[186]\ttrain's auc: 0.818115\ttrain's binary_logloss: 0.371186\n",
      "[187]\ttrain's auc: 0.81824\ttrain's binary_logloss: 0.371032\n",
      "[188]\ttrain's auc: 0.818336\ttrain's binary_logloss: 0.370893\n",
      "[189]\ttrain's auc: 0.818364\ttrain's binary_logloss: 0.370782\n",
      "[190]\ttrain's auc: 0.818455\ttrain's binary_logloss: 0.370645\n",
      "[191]\ttrain's auc: 0.818496\ttrain's binary_logloss: 0.370529\n",
      "[192]\ttrain's auc: 0.818529\ttrain's binary_logloss: 0.370419\n",
      "[193]\ttrain's auc: 0.818601\ttrain's binary_logloss: 0.370291\n",
      "[194]\ttrain's auc: 0.818714\ttrain's binary_logloss: 0.370146\n",
      "[195]\ttrain's auc: 0.818775\ttrain's binary_logloss: 0.370029\n",
      "[196]\ttrain's auc: 0.818813\ttrain's binary_logloss: 0.369924\n",
      "[197]\ttrain's auc: 0.818898\ttrain's binary_logloss: 0.369792\n",
      "[198]\ttrain's auc: 0.818982\ttrain's binary_logloss: 0.369665\n",
      "[199]\ttrain's auc: 0.819034\ttrain's binary_logloss: 0.369557\n",
      "[200]\ttrain's auc: 0.819093\ttrain's binary_logloss: 0.369444\n",
      "[201]\ttrain's auc: 0.819151\ttrain's binary_logloss: 0.369331\n",
      "[202]\ttrain's auc: 0.819243\ttrain's binary_logloss: 0.369204\n",
      "[203]\ttrain's auc: 0.819362\ttrain's binary_logloss: 0.36906\n",
      "[204]\ttrain's auc: 0.819481\ttrain's binary_logloss: 0.368927\n",
      "[205]\ttrain's auc: 0.819549\ttrain's binary_logloss: 0.368813\n",
      "[206]\ttrain's auc: 0.819593\ttrain's binary_logloss: 0.368714\n",
      "[207]\ttrain's auc: 0.819651\ttrain's binary_logloss: 0.368606\n",
      "[208]\ttrain's auc: 0.819692\ttrain's binary_logloss: 0.36851\n",
      "[209]\ttrain's auc: 0.81974\ttrain's binary_logloss: 0.368409\n",
      "[210]\ttrain's auc: 0.819802\ttrain's binary_logloss: 0.368303\n",
      "[211]\ttrain's auc: 0.819889\ttrain's binary_logloss: 0.368183\n",
      "[212]\ttrain's auc: 0.81993\ttrain's binary_logloss: 0.368091\n",
      "[213]\ttrain's auc: 0.819979\ttrain's binary_logloss: 0.367994\n",
      "[214]\ttrain's auc: 0.820035\ttrain's binary_logloss: 0.367901\n",
      "[215]\ttrain's auc: 0.820077\ttrain's binary_logloss: 0.36781\n",
      "[216]\ttrain's auc: 0.820133\ttrain's binary_logloss: 0.367712\n",
      "[217]\ttrain's auc: 0.820241\ttrain's binary_logloss: 0.367591\n",
      "[218]\ttrain's auc: 0.820268\ttrain's binary_logloss: 0.36751\n",
      "[219]\ttrain's auc: 0.820315\ttrain's binary_logloss: 0.367424\n",
      "[220]\ttrain's auc: 0.820348\ttrain's binary_logloss: 0.367337\n",
      "[221]\ttrain's auc: 0.820374\ttrain's binary_logloss: 0.367257\n",
      "[222]\ttrain's auc: 0.820396\ttrain's binary_logloss: 0.36718\n",
      "[223]\ttrain's auc: 0.820443\ttrain's binary_logloss: 0.367091\n",
      "[224]\ttrain's auc: 0.820496\ttrain's binary_logloss: 0.366997\n",
      "[225]\ttrain's auc: 0.820551\ttrain's binary_logloss: 0.366905\n",
      "[226]\ttrain's auc: 0.820597\ttrain's binary_logloss: 0.366816\n",
      "[227]\ttrain's auc: 0.820611\ttrain's binary_logloss: 0.366748\n",
      "[228]\ttrain's auc: 0.820644\ttrain's binary_logloss: 0.366669\n",
      "[229]\ttrain's auc: 0.820679\ttrain's binary_logloss: 0.366593\n",
      "[230]\ttrain's auc: 0.820747\ttrain's binary_logloss: 0.366499\n",
      "[231]\ttrain's auc: 0.820806\ttrain's binary_logloss: 0.366413\n",
      "[232]\ttrain's auc: 0.820845\ttrain's binary_logloss: 0.366333\n",
      "[233]\ttrain's auc: 0.820958\ttrain's binary_logloss: 0.366221\n",
      "[234]\ttrain's auc: 0.820997\ttrain's binary_logloss: 0.366143\n",
      "[235]\ttrain's auc: 0.821052\ttrain's binary_logloss: 0.366058\n",
      "[236]\ttrain's auc: 0.821097\ttrain's binary_logloss: 0.365977\n",
      "[237]\ttrain's auc: 0.821147\ttrain's binary_logloss: 0.365893\n",
      "[238]\ttrain's auc: 0.821188\ttrain's binary_logloss: 0.365821\n",
      "[239]\ttrain's auc: 0.821226\ttrain's binary_logloss: 0.365746\n",
      "[240]\ttrain's auc: 0.821261\ttrain's binary_logloss: 0.365677\n",
      "[241]\ttrain's auc: 0.821329\ttrain's binary_logloss: 0.365586\n",
      "[242]\ttrain's auc: 0.821364\ttrain's binary_logloss: 0.365513\n",
      "[243]\ttrain's auc: 0.821448\ttrain's binary_logloss: 0.365423\n",
      "[244]\ttrain's auc: 0.821517\ttrain's binary_logloss: 0.365337\n",
      "[245]\ttrain's auc: 0.821555\ttrain's binary_logloss: 0.365266\n",
      "[246]\ttrain's auc: 0.821609\ttrain's binary_logloss: 0.365185\n",
      "[247]\ttrain's auc: 0.821682\ttrain's binary_logloss: 0.365102\n",
      "[248]\ttrain's auc: 0.821699\ttrain's binary_logloss: 0.365045\n",
      "[249]\ttrain's auc: 0.821774\ttrain's binary_logloss: 0.364959\n",
      "[250]\ttrain's auc: 0.821844\ttrain's binary_logloss: 0.364877\n",
      "[251]\ttrain's auc: 0.821915\ttrain's binary_logloss: 0.364795\n",
      "[252]\ttrain's auc: 0.821953\ttrain's binary_logloss: 0.364729\n",
      "[253]\ttrain's auc: 0.821993\ttrain's binary_logloss: 0.364659\n",
      "[254]\ttrain's auc: 0.822059\ttrain's binary_logloss: 0.364582\n",
      "[255]\ttrain's auc: 0.822118\ttrain's binary_logloss: 0.364508\n",
      "[256]\ttrain's auc: 0.822139\ttrain's binary_logloss: 0.364452\n",
      "[257]\ttrain's auc: 0.822202\ttrain's binary_logloss: 0.364377\n",
      "[258]\ttrain's auc: 0.822262\ttrain's binary_logloss: 0.364303\n",
      "[259]\ttrain's auc: 0.822298\ttrain's binary_logloss: 0.364252\n",
      "[260]\ttrain's auc: 0.82237\ttrain's binary_logloss: 0.364176\n",
      "[261]\ttrain's auc: 0.822428\ttrain's binary_logloss: 0.364123\n",
      "[262]\ttrain's auc: 0.822477\ttrain's binary_logloss: 0.364054\n",
      "[263]\ttrain's auc: 0.822499\ttrain's binary_logloss: 0.364002\n",
      "[264]\ttrain's auc: 0.822544\ttrain's binary_logloss: 0.363934\n",
      "[265]\ttrain's auc: 0.822598\ttrain's binary_logloss: 0.363864\n",
      "[266]\ttrain's auc: 0.822653\ttrain's binary_logloss: 0.363796\n",
      "[267]\ttrain's auc: 0.822711\ttrain's binary_logloss: 0.363728\n",
      "[268]\ttrain's auc: 0.822755\ttrain's binary_logloss: 0.363664\n",
      "[269]\ttrain's auc: 0.82277\ttrain's binary_logloss: 0.363616\n",
      "[270]\ttrain's auc: 0.8228\ttrain's binary_logloss: 0.363561\n",
      "[271]\ttrain's auc: 0.822853\ttrain's binary_logloss: 0.363495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[272]\ttrain's auc: 0.822873\ttrain's binary_logloss: 0.363447\n",
      "[273]\ttrain's auc: 0.822884\ttrain's binary_logloss: 0.363402\n",
      "[274]\ttrain's auc: 0.822948\ttrain's binary_logloss: 0.363333\n",
      "[275]\ttrain's auc: 0.822989\ttrain's binary_logloss: 0.363275\n",
      "[276]\ttrain's auc: 0.823027\ttrain's binary_logloss: 0.363216\n",
      "[277]\ttrain's auc: 0.823065\ttrain's binary_logloss: 0.363158\n",
      "[278]\ttrain's auc: 0.82308\ttrain's binary_logloss: 0.363114\n",
      "[279]\ttrain's auc: 0.823096\ttrain's binary_logloss: 0.36307\n",
      "[280]\ttrain's auc: 0.823136\ttrain's binary_logloss: 0.363011\n",
      "[281]\ttrain's auc: 0.823209\ttrain's binary_logloss: 0.362937\n",
      "[282]\ttrain's auc: 0.823246\ttrain's binary_logloss: 0.362883\n",
      "[283]\ttrain's auc: 0.823304\ttrain's binary_logloss: 0.362819\n",
      "[284]\ttrain's auc: 0.823319\ttrain's binary_logloss: 0.362778\n",
      "[285]\ttrain's auc: 0.823337\ttrain's binary_logloss: 0.362736\n",
      "[286]\ttrain's auc: 0.82338\ttrain's binary_logloss: 0.362679\n",
      "[287]\ttrain's auc: 0.823402\ttrain's binary_logloss: 0.362637\n",
      "[288]\ttrain's auc: 0.823432\ttrain's binary_logloss: 0.362588\n",
      "[289]\ttrain's auc: 0.823477\ttrain's binary_logloss: 0.362531\n",
      "[290]\ttrain's auc: 0.823518\ttrain's binary_logloss: 0.362476\n",
      "[291]\ttrain's auc: 0.82357\ttrain's binary_logloss: 0.362423\n",
      "[292]\ttrain's auc: 0.823616\ttrain's binary_logloss: 0.362368\n",
      "[293]\ttrain's auc: 0.823645\ttrain's binary_logloss: 0.362318\n",
      "[294]\ttrain's auc: 0.823655\ttrain's binary_logloss: 0.362282\n",
      "[295]\ttrain's auc: 0.823676\ttrain's binary_logloss: 0.362239\n",
      "[296]\ttrain's auc: 0.823704\ttrain's binary_logloss: 0.362194\n",
      "[297]\ttrain's auc: 0.823741\ttrain's binary_logloss: 0.362142\n",
      "[298]\ttrain's auc: 0.823766\ttrain's binary_logloss: 0.362099\n",
      "[299]\ttrain's auc: 0.823798\ttrain's binary_logloss: 0.362055\n",
      "[300]\ttrain's auc: 0.823828\ttrain's binary_logloss: 0.36201\n",
      "[301]\ttrain's auc: 0.823871\ttrain's binary_logloss: 0.361959\n",
      "[302]\ttrain's auc: 0.823897\ttrain's binary_logloss: 0.361915\n",
      "[303]\ttrain's auc: 0.823939\ttrain's binary_logloss: 0.361864\n",
      "[304]\ttrain's auc: 0.823958\ttrain's binary_logloss: 0.361828\n",
      "[305]\ttrain's auc: 0.823984\ttrain's binary_logloss: 0.361785\n",
      "[306]\ttrain's auc: 0.823999\ttrain's binary_logloss: 0.361752\n",
      "[307]\ttrain's auc: 0.824019\ttrain's binary_logloss: 0.361714\n",
      "[308]\ttrain's auc: 0.82404\ttrain's binary_logloss: 0.361675\n",
      "[309]\ttrain's auc: 0.824059\ttrain's binary_logloss: 0.361638\n",
      "[310]\ttrain's auc: 0.824109\ttrain's binary_logloss: 0.361587\n",
      "[311]\ttrain's auc: 0.82413\ttrain's binary_logloss: 0.361549\n",
      "[312]\ttrain's auc: 0.824156\ttrain's binary_logloss: 0.361509\n",
      "[313]\ttrain's auc: 0.824184\ttrain's binary_logloss: 0.361468\n",
      "[314]\ttrain's auc: 0.824196\ttrain's binary_logloss: 0.361436\n",
      "[315]\ttrain's auc: 0.824209\ttrain's binary_logloss: 0.361406\n",
      "[316]\ttrain's auc: 0.824229\ttrain's binary_logloss: 0.36137\n",
      "[317]\ttrain's auc: 0.824248\ttrain's binary_logloss: 0.361335\n",
      "[318]\ttrain's auc: 0.824266\ttrain's binary_logloss: 0.3613\n",
      "[319]\ttrain's auc: 0.824286\ttrain's binary_logloss: 0.361265\n",
      "[320]\ttrain's auc: 0.824303\ttrain's binary_logloss: 0.361232\n",
      "[321]\ttrain's auc: 0.824319\ttrain's binary_logloss: 0.361199\n",
      "[322]\ttrain's auc: 0.824343\ttrain's binary_logloss: 0.361163\n",
      "[323]\ttrain's auc: 0.824361\ttrain's binary_logloss: 0.36113\n",
      "[324]\ttrain's auc: 0.824383\ttrain's binary_logloss: 0.361095\n",
      "[325]\ttrain's auc: 0.824393\ttrain's binary_logloss: 0.361068\n",
      "[326]\ttrain's auc: 0.824407\ttrain's binary_logloss: 0.361038\n",
      "[327]\ttrain's auc: 0.824432\ttrain's binary_logloss: 0.361003\n",
      "[328]\ttrain's auc: 0.82445\ttrain's binary_logloss: 0.360973\n",
      "[329]\ttrain's auc: 0.824469\ttrain's binary_logloss: 0.360941\n",
      "[330]\ttrain's auc: 0.82448\ttrain's binary_logloss: 0.360914\n",
      "[331]\ttrain's auc: 0.824496\ttrain's binary_logloss: 0.360883\n",
      "[332]\ttrain's auc: 0.824519\ttrain's binary_logloss: 0.36085\n",
      "[333]\ttrain's auc: 0.824542\ttrain's binary_logloss: 0.360817\n",
      "[334]\ttrain's auc: 0.824565\ttrain's binary_logloss: 0.360784\n",
      "[335]\ttrain's auc: 0.824583\ttrain's binary_logloss: 0.360754\n",
      "[336]\ttrain's auc: 0.824604\ttrain's binary_logloss: 0.360721\n",
      "[337]\ttrain's auc: 0.824622\ttrain's binary_logloss: 0.360693\n",
      "[338]\ttrain's auc: 0.824638\ttrain's binary_logloss: 0.360665\n",
      "[339]\ttrain's auc: 0.824651\ttrain's binary_logloss: 0.360638\n",
      "[340]\ttrain's auc: 0.824683\ttrain's binary_logloss: 0.360601\n",
      "[341]\ttrain's auc: 0.824696\ttrain's binary_logloss: 0.360575\n",
      "[342]\ttrain's auc: 0.824712\ttrain's binary_logloss: 0.360548\n",
      "[343]\ttrain's auc: 0.824722\ttrain's binary_logloss: 0.360524\n",
      "[344]\ttrain's auc: 0.824737\ttrain's binary_logloss: 0.360497\n",
      "[345]\ttrain's auc: 0.824756\ttrain's binary_logloss: 0.36047\n",
      "[346]\ttrain's auc: 0.824771\ttrain's binary_logloss: 0.360446\n",
      "[347]\ttrain's auc: 0.824782\ttrain's binary_logloss: 0.360423\n",
      "[348]\ttrain's auc: 0.824803\ttrain's binary_logloss: 0.360394\n",
      "[349]\ttrain's auc: 0.824817\ttrain's binary_logloss: 0.360369\n",
      "[350]\ttrain's auc: 0.824827\ttrain's binary_logloss: 0.360346\n",
      "[351]\ttrain's auc: 0.824846\ttrain's binary_logloss: 0.360318\n",
      "[352]\ttrain's auc: 0.824858\ttrain's binary_logloss: 0.360296\n",
      "[353]\ttrain's auc: 0.824875\ttrain's binary_logloss: 0.36027\n",
      "[354]\ttrain's auc: 0.82489\ttrain's binary_logloss: 0.360246\n",
      "[355]\ttrain's auc: 0.824914\ttrain's binary_logloss: 0.360215\n",
      "[356]\ttrain's auc: 0.824926\ttrain's binary_logloss: 0.360192\n",
      "[357]\ttrain's auc: 0.824945\ttrain's binary_logloss: 0.360167\n",
      "[358]\ttrain's auc: 0.824962\ttrain's binary_logloss: 0.360141\n",
      "[359]\ttrain's auc: 0.824994\ttrain's binary_logloss: 0.360105\n",
      "[360]\ttrain's auc: 0.825004\ttrain's binary_logloss: 0.360083\n",
      "[361]\ttrain's auc: 0.825023\ttrain's binary_logloss: 0.360057\n",
      "[362]\ttrain's auc: 0.825048\ttrain's binary_logloss: 0.360028\n",
      "[363]\ttrain's auc: 0.825062\ttrain's binary_logloss: 0.360006\n",
      "[364]\ttrain's auc: 0.825075\ttrain's binary_logloss: 0.359984\n",
      "[365]\ttrain's auc: 0.825091\ttrain's binary_logloss: 0.359962\n",
      "[366]\ttrain's auc: 0.825099\ttrain's binary_logloss: 0.359943\n",
      "[367]\ttrain's auc: 0.825114\ttrain's binary_logloss: 0.35992\n",
      "[368]\ttrain's auc: 0.825127\ttrain's binary_logloss: 0.359898\n",
      "[369]\ttrain's auc: 0.825142\ttrain's binary_logloss: 0.359874\n",
      "[370]\ttrain's auc: 0.825154\ttrain's binary_logloss: 0.359852\n",
      "[371]\ttrain's auc: 0.825186\ttrain's binary_logloss: 0.359818\n",
      "[372]\ttrain's auc: 0.825203\ttrain's binary_logloss: 0.359794\n",
      "[373]\ttrain's auc: 0.825223\ttrain's binary_logloss: 0.359767\n",
      "[374]\ttrain's auc: 0.825234\ttrain's binary_logloss: 0.359748\n",
      "[375]\ttrain's auc: 0.825272\ttrain's binary_logloss: 0.359711\n",
      "[376]\ttrain's auc: 0.825299\ttrain's binary_logloss: 0.359683\n",
      "[377]\ttrain's auc: 0.825321\ttrain's binary_logloss: 0.359658\n",
      "[378]\ttrain's auc: 0.825342\ttrain's binary_logloss: 0.359632\n",
      "[379]\ttrain's auc: 0.825357\ttrain's binary_logloss: 0.35961\n",
      "[380]\ttrain's auc: 0.825383\ttrain's binary_logloss: 0.35958\n",
      "[381]\ttrain's auc: 0.825408\ttrain's binary_logloss: 0.359552\n",
      "[382]\ttrain's auc: 0.825418\ttrain's binary_logloss: 0.359534\n",
      "[383]\ttrain's auc: 0.825436\ttrain's binary_logloss: 0.359512\n",
      "[384]\ttrain's auc: 0.825445\ttrain's binary_logloss: 0.359493\n",
      "[385]\ttrain's auc: 0.825473\ttrain's binary_logloss: 0.359463\n",
      "[386]\ttrain's auc: 0.825498\ttrain's binary_logloss: 0.359434\n",
      "[387]\ttrain's auc: 0.825524\ttrain's binary_logloss: 0.359404\n",
      "[388]\ttrain's auc: 0.825541\ttrain's binary_logloss: 0.359383\n",
      "[389]\ttrain's auc: 0.82555\ttrain's binary_logloss: 0.359367\n",
      "[390]\ttrain's auc: 0.82557\ttrain's binary_logloss: 0.359346\n",
      "[391]\ttrain's auc: 0.825584\ttrain's binary_logloss: 0.359326\n",
      "[392]\ttrain's auc: 0.825613\ttrain's binary_logloss: 0.359295\n",
      "[393]\ttrain's auc: 0.825643\ttrain's binary_logloss: 0.359263\n",
      "[394]\ttrain's auc: 0.825668\ttrain's binary_logloss: 0.359234\n",
      "[395]\ttrain's auc: 0.825701\ttrain's binary_logloss: 0.359201\n",
      "[396]\ttrain's auc: 0.825716\ttrain's binary_logloss: 0.359183\n",
      "[397]\ttrain's auc: 0.825741\ttrain's binary_logloss: 0.359155\n",
      "[398]\ttrain's auc: 0.82576\ttrain's binary_logloss: 0.359134\n",
      "[399]\ttrain's auc: 0.825783\ttrain's binary_logloss: 0.359106\n",
      "[400]\ttrain's auc: 0.825795\ttrain's binary_logloss: 0.359089\n",
      "[401]\ttrain's auc: 0.825821\ttrain's binary_logloss: 0.35906\n",
      "[402]\ttrain's auc: 0.825831\ttrain's binary_logloss: 0.359044\n",
      "[403]\ttrain's auc: 0.825852\ttrain's binary_logloss: 0.359023\n",
      "[404]\ttrain's auc: 0.825871\ttrain's binary_logloss: 0.359003\n",
      "[405]\ttrain's auc: 0.82589\ttrain's binary_logloss: 0.358983\n",
      "[406]\ttrain's auc: 0.825916\ttrain's binary_logloss: 0.358959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[407]\ttrain's auc: 0.825928\ttrain's binary_logloss: 0.358941\n",
      "[408]\ttrain's auc: 0.825951\ttrain's binary_logloss: 0.358915\n",
      "[409]\ttrain's auc: 0.825968\ttrain's binary_logloss: 0.358897\n",
      "[410]\ttrain's auc: 0.825983\ttrain's binary_logloss: 0.358879\n",
      "[411]\ttrain's auc: 0.826023\ttrain's binary_logloss: 0.358844\n",
      "[412]\ttrain's auc: 0.826053\ttrain's binary_logloss: 0.358815\n",
      "[413]\ttrain's auc: 0.826079\ttrain's binary_logloss: 0.358788\n",
      "[414]\ttrain's auc: 0.826104\ttrain's binary_logloss: 0.358761\n",
      "[415]\ttrain's auc: 0.826128\ttrain's binary_logloss: 0.358735\n",
      "[416]\ttrain's auc: 0.826147\ttrain's binary_logloss: 0.358713\n",
      "[417]\ttrain's auc: 0.826167\ttrain's binary_logloss: 0.358693\n",
      "[418]\ttrain's auc: 0.826176\ttrain's binary_logloss: 0.358678\n",
      "[419]\ttrain's auc: 0.826201\ttrain's binary_logloss: 0.358653\n",
      "[420]\ttrain's auc: 0.826215\ttrain's binary_logloss: 0.358637\n",
      "[421]\ttrain's auc: 0.826251\ttrain's binary_logloss: 0.358605\n",
      "[422]\ttrain's auc: 0.826278\ttrain's binary_logloss: 0.358579\n",
      "[423]\ttrain's auc: 0.826288\ttrain's binary_logloss: 0.358565\n",
      "[424]\ttrain's auc: 0.826323\ttrain's binary_logloss: 0.358536\n",
      "[425]\ttrain's auc: 0.826338\ttrain's binary_logloss: 0.35852\n",
      "[426]\ttrain's auc: 0.826359\ttrain's binary_logloss: 0.358498\n",
      "[427]\ttrain's auc: 0.826373\ttrain's binary_logloss: 0.358481\n",
      "[428]\ttrain's auc: 0.826382\ttrain's binary_logloss: 0.358468\n",
      "[429]\ttrain's auc: 0.8264\ttrain's binary_logloss: 0.358449\n",
      "[430]\ttrain's auc: 0.826413\ttrain's binary_logloss: 0.358434\n",
      "[431]\ttrain's auc: 0.826427\ttrain's binary_logloss: 0.358417\n",
      "[432]\ttrain's auc: 0.826438\ttrain's binary_logloss: 0.358402\n",
      "[433]\ttrain's auc: 0.826462\ttrain's binary_logloss: 0.358378\n",
      "[434]\ttrain's auc: 0.826474\ttrain's binary_logloss: 0.358364\n",
      "[435]\ttrain's auc: 0.826498\ttrain's binary_logloss: 0.35834\n",
      "[436]\ttrain's auc: 0.826526\ttrain's binary_logloss: 0.358315\n",
      "[437]\ttrain's auc: 0.826549\ttrain's binary_logloss: 0.358293\n",
      "[438]\ttrain's auc: 0.826567\ttrain's binary_logloss: 0.358275\n",
      "[439]\ttrain's auc: 0.82658\ttrain's binary_logloss: 0.35826\n",
      "[440]\ttrain's auc: 0.826607\ttrain's binary_logloss: 0.358234\n",
      "[441]\ttrain's auc: 0.826631\ttrain's binary_logloss: 0.358211\n",
      "[442]\ttrain's auc: 0.826664\ttrain's binary_logloss: 0.358182\n",
      "[443]\ttrain's auc: 0.826689\ttrain's binary_logloss: 0.358157\n",
      "[444]\ttrain's auc: 0.826705\ttrain's binary_logloss: 0.358139\n",
      "[445]\ttrain's auc: 0.826722\ttrain's binary_logloss: 0.358121\n",
      "[446]\ttrain's auc: 0.826737\ttrain's binary_logloss: 0.358104\n",
      "[447]\ttrain's auc: 0.826755\ttrain's binary_logloss: 0.358086\n",
      "[448]\ttrain's auc: 0.82677\ttrain's binary_logloss: 0.358069\n",
      "[449]\ttrain's auc: 0.826786\ttrain's binary_logloss: 0.358053\n",
      "[450]\ttrain's auc: 0.826803\ttrain's binary_logloss: 0.358035\n",
      "[451]\ttrain's auc: 0.82684\ttrain's binary_logloss: 0.358005\n",
      "[452]\ttrain's auc: 0.826868\ttrain's binary_logloss: 0.35798\n",
      "[453]\ttrain's auc: 0.826883\ttrain's binary_logloss: 0.357964\n",
      "[454]\ttrain's auc: 0.826909\ttrain's binary_logloss: 0.357941\n",
      "[455]\ttrain's auc: 0.826943\ttrain's binary_logloss: 0.357912\n",
      "[456]\ttrain's auc: 0.826956\ttrain's binary_logloss: 0.357897\n",
      "[457]\ttrain's auc: 0.826967\ttrain's binary_logloss: 0.357883\n",
      "[458]\ttrain's auc: 0.826987\ttrain's binary_logloss: 0.357862\n",
      "[459]\ttrain's auc: 0.827007\ttrain's binary_logloss: 0.357841\n",
      "[460]\ttrain's auc: 0.827024\ttrain's binary_logloss: 0.357824\n",
      "[461]\ttrain's auc: 0.827049\ttrain's binary_logloss: 0.357804\n",
      "[462]\ttrain's auc: 0.827058\ttrain's binary_logloss: 0.357792\n",
      "[463]\ttrain's auc: 0.827079\ttrain's binary_logloss: 0.357771\n",
      "[464]\ttrain's auc: 0.82709\ttrain's binary_logloss: 0.357759\n",
      "[465]\ttrain's auc: 0.827108\ttrain's binary_logloss: 0.357741\n",
      "[466]\ttrain's auc: 0.827137\ttrain's binary_logloss: 0.357718\n",
      "[467]\ttrain's auc: 0.827158\ttrain's binary_logloss: 0.357698\n",
      "[468]\ttrain's auc: 0.827171\ttrain's binary_logloss: 0.357682\n",
      "[469]\ttrain's auc: 0.827181\ttrain's binary_logloss: 0.35767\n",
      "[470]\ttrain's auc: 0.827197\ttrain's binary_logloss: 0.357654\n",
      "[471]\ttrain's auc: 0.827217\ttrain's binary_logloss: 0.357636\n",
      "[472]\ttrain's auc: 0.827228\ttrain's binary_logloss: 0.357623\n",
      "[473]\ttrain's auc: 0.827242\ttrain's binary_logloss: 0.357608\n",
      "[474]\ttrain's auc: 0.827263\ttrain's binary_logloss: 0.357588\n",
      "[475]\ttrain's auc: 0.827277\ttrain's binary_logloss: 0.357572\n",
      "[476]\ttrain's auc: 0.82729\ttrain's binary_logloss: 0.357559\n",
      "[477]\ttrain's auc: 0.827308\ttrain's binary_logloss: 0.357542\n",
      "[478]\ttrain's auc: 0.82732\ttrain's binary_logloss: 0.35753\n",
      "[479]\ttrain's auc: 0.827329\ttrain's binary_logloss: 0.357519\n",
      "[480]\ttrain's auc: 0.827353\ttrain's binary_logloss: 0.357499\n",
      "[481]\ttrain's auc: 0.827375\ttrain's binary_logloss: 0.357478\n",
      "[482]\ttrain's auc: 0.827393\ttrain's binary_logloss: 0.357462\n",
      "[483]\ttrain's auc: 0.827411\ttrain's binary_logloss: 0.357446\n",
      "[484]\ttrain's auc: 0.82743\ttrain's binary_logloss: 0.357429\n",
      "[485]\ttrain's auc: 0.827451\ttrain's binary_logloss: 0.357411\n",
      "[486]\ttrain's auc: 0.827462\ttrain's binary_logloss: 0.357398\n",
      "[487]\ttrain's auc: 0.827474\ttrain's binary_logloss: 0.357385\n",
      "[488]\ttrain's auc: 0.82749\ttrain's binary_logloss: 0.357369\n",
      "[489]\ttrain's auc: 0.827504\ttrain's binary_logloss: 0.357356\n",
      "[490]\ttrain's auc: 0.82752\ttrain's binary_logloss: 0.35734\n",
      "[491]\ttrain's auc: 0.827536\ttrain's binary_logloss: 0.357325\n",
      "[492]\ttrain's auc: 0.827543\ttrain's binary_logloss: 0.357315\n",
      "[493]\ttrain's auc: 0.827556\ttrain's binary_logloss: 0.357301\n",
      "[494]\ttrain's auc: 0.827571\ttrain's binary_logloss: 0.357284\n",
      "[495]\ttrain's auc: 0.827592\ttrain's binary_logloss: 0.357267\n",
      "[496]\ttrain's auc: 0.827607\ttrain's binary_logloss: 0.357252\n",
      "[497]\ttrain's auc: 0.827625\ttrain's binary_logloss: 0.357234\n",
      "[498]\ttrain's auc: 0.827637\ttrain's binary_logloss: 0.357222\n",
      "[499]\ttrain's auc: 0.827652\ttrain's binary_logloss: 0.357207\n",
      "[500]\ttrain's auc: 0.827669\ttrain's binary_logloss: 0.357193\n",
      "[501]\ttrain's auc: 0.827678\ttrain's binary_logloss: 0.357183\n",
      "[502]\ttrain's auc: 0.827693\ttrain's binary_logloss: 0.357169\n",
      "[503]\ttrain's auc: 0.827709\ttrain's binary_logloss: 0.357153\n",
      "[504]\ttrain's auc: 0.827731\ttrain's binary_logloss: 0.357133\n",
      "[505]\ttrain's auc: 0.827744\ttrain's binary_logloss: 0.357118\n",
      "[506]\ttrain's auc: 0.827763\ttrain's binary_logloss: 0.357099\n",
      "[507]\ttrain's auc: 0.827779\ttrain's binary_logloss: 0.357084\n",
      "[508]\ttrain's auc: 0.827795\ttrain's binary_logloss: 0.357067\n",
      "[509]\ttrain's auc: 0.827807\ttrain's binary_logloss: 0.357054\n",
      "[510]\ttrain's auc: 0.827822\ttrain's binary_logloss: 0.357038\n",
      "[511]\ttrain's auc: 0.82784\ttrain's binary_logloss: 0.357022\n",
      "[512]\ttrain's auc: 0.827854\ttrain's binary_logloss: 0.357007\n",
      "[513]\ttrain's auc: 0.827866\ttrain's binary_logloss: 0.356994\n",
      "[514]\ttrain's auc: 0.827876\ttrain's binary_logloss: 0.356984\n",
      "[515]\ttrain's auc: 0.827892\ttrain's binary_logloss: 0.356969\n",
      "[516]\ttrain's auc: 0.827904\ttrain's binary_logloss: 0.356957\n",
      "[517]\ttrain's auc: 0.827917\ttrain's binary_logloss: 0.356945\n",
      "[518]\ttrain's auc: 0.827933\ttrain's binary_logloss: 0.356931\n",
      "[519]\ttrain's auc: 0.827953\ttrain's binary_logloss: 0.356912\n",
      "[520]\ttrain's auc: 0.82797\ttrain's binary_logloss: 0.356898\n",
      "[521]\ttrain's auc: 0.827989\ttrain's binary_logloss: 0.356882\n",
      "[522]\ttrain's auc: 0.828003\ttrain's binary_logloss: 0.356869\n",
      "[523]\ttrain's auc: 0.828009\ttrain's binary_logloss: 0.35686\n",
      "[524]\ttrain's auc: 0.828033\ttrain's binary_logloss: 0.356841\n",
      "[525]\ttrain's auc: 0.828053\ttrain's binary_logloss: 0.356823\n",
      "[526]\ttrain's auc: 0.828064\ttrain's binary_logloss: 0.356812\n",
      "[527]\ttrain's auc: 0.828083\ttrain's binary_logloss: 0.356794\n",
      "[528]\ttrain's auc: 0.828092\ttrain's binary_logloss: 0.356783\n",
      "[529]\ttrain's auc: 0.828106\ttrain's binary_logloss: 0.356771\n",
      "[530]\ttrain's auc: 0.828118\ttrain's binary_logloss: 0.35676\n",
      "[531]\ttrain's auc: 0.828137\ttrain's binary_logloss: 0.356742\n",
      "[532]\ttrain's auc: 0.828156\ttrain's binary_logloss: 0.356725\n",
      "[533]\ttrain's auc: 0.828176\ttrain's binary_logloss: 0.356709\n",
      "[534]\ttrain's auc: 0.828188\ttrain's binary_logloss: 0.356696\n",
      "[535]\ttrain's auc: 0.828207\ttrain's binary_logloss: 0.356679\n",
      "[536]\ttrain's auc: 0.828218\ttrain's binary_logloss: 0.356669\n",
      "[537]\ttrain's auc: 0.82824\ttrain's binary_logloss: 0.356651\n",
      "[538]\ttrain's auc: 0.828258\ttrain's binary_logloss: 0.356634\n",
      "[539]\ttrain's auc: 0.828275\ttrain's binary_logloss: 0.356618\n",
      "[540]\ttrain's auc: 0.828289\ttrain's binary_logloss: 0.356605\n",
      "[541]\ttrain's auc: 0.828302\ttrain's binary_logloss: 0.356593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[542]\ttrain's auc: 0.828311\ttrain's binary_logloss: 0.356583\n",
      "[543]\ttrain's auc: 0.828331\ttrain's binary_logloss: 0.356567\n",
      "[544]\ttrain's auc: 0.828345\ttrain's binary_logloss: 0.356552\n",
      "[545]\ttrain's auc: 0.828353\ttrain's binary_logloss: 0.356544\n",
      "[546]\ttrain's auc: 0.828369\ttrain's binary_logloss: 0.356528\n",
      "[547]\ttrain's auc: 0.828381\ttrain's binary_logloss: 0.356516\n",
      "[548]\ttrain's auc: 0.828391\ttrain's binary_logloss: 0.356505\n",
      "[549]\ttrain's auc: 0.828401\ttrain's binary_logloss: 0.356494\n",
      "[550]\ttrain's auc: 0.828415\ttrain's binary_logloss: 0.356481\n",
      "[551]\ttrain's auc: 0.828421\ttrain's binary_logloss: 0.356473\n",
      "[552]\ttrain's auc: 0.828431\ttrain's binary_logloss: 0.356462\n",
      "[553]\ttrain's auc: 0.828441\ttrain's binary_logloss: 0.356453\n",
      "[554]\ttrain's auc: 0.828453\ttrain's binary_logloss: 0.356442\n",
      "[555]\ttrain's auc: 0.828464\ttrain's binary_logloss: 0.356431\n",
      "[556]\ttrain's auc: 0.828474\ttrain's binary_logloss: 0.356421\n",
      "[557]\ttrain's auc: 0.828493\ttrain's binary_logloss: 0.356404\n",
      "[558]\ttrain's auc: 0.82851\ttrain's binary_logloss: 0.35639\n",
      "[559]\ttrain's auc: 0.828523\ttrain's binary_logloss: 0.356377\n",
      "[560]\ttrain's auc: 0.828539\ttrain's binary_logloss: 0.356364\n",
      "[561]\ttrain's auc: 0.828548\ttrain's binary_logloss: 0.356354\n",
      "[562]\ttrain's auc: 0.82856\ttrain's binary_logloss: 0.356344\n",
      "[563]\ttrain's auc: 0.828568\ttrain's binary_logloss: 0.356334\n",
      "[564]\ttrain's auc: 0.82858\ttrain's binary_logloss: 0.356324\n",
      "[565]\ttrain's auc: 0.828597\ttrain's binary_logloss: 0.356308\n",
      "[566]\ttrain's auc: 0.828607\ttrain's binary_logloss: 0.356298\n",
      "[567]\ttrain's auc: 0.828619\ttrain's binary_logloss: 0.356286\n",
      "[568]\ttrain's auc: 0.828635\ttrain's binary_logloss: 0.356271\n",
      "[569]\ttrain's auc: 0.828652\ttrain's binary_logloss: 0.356256\n",
      "[570]\ttrain's auc: 0.828669\ttrain's binary_logloss: 0.356242\n",
      "[571]\ttrain's auc: 0.828685\ttrain's binary_logloss: 0.356228\n",
      "[572]\ttrain's auc: 0.828701\ttrain's binary_logloss: 0.356214\n",
      "[573]\ttrain's auc: 0.828725\ttrain's binary_logloss: 0.356194\n",
      "[574]\ttrain's auc: 0.828743\ttrain's binary_logloss: 0.356179\n",
      "[575]\ttrain's auc: 0.828751\ttrain's binary_logloss: 0.356169\n",
      "[576]\ttrain's auc: 0.828759\ttrain's binary_logloss: 0.35616\n",
      "[577]\ttrain's auc: 0.828771\ttrain's binary_logloss: 0.356149\n",
      "[578]\ttrain's auc: 0.828782\ttrain's binary_logloss: 0.356139\n",
      "[579]\ttrain's auc: 0.828799\ttrain's binary_logloss: 0.356125\n",
      "[580]\ttrain's auc: 0.828807\ttrain's binary_logloss: 0.356117\n",
      "[581]\ttrain's auc: 0.828814\ttrain's binary_logloss: 0.356108\n",
      "[582]\ttrain's auc: 0.828824\ttrain's binary_logloss: 0.356099\n",
      "[583]\ttrain's auc: 0.828833\ttrain's binary_logloss: 0.356089\n",
      "[584]\ttrain's auc: 0.828841\ttrain's binary_logloss: 0.35608\n",
      "[585]\ttrain's auc: 0.828847\ttrain's binary_logloss: 0.356073\n",
      "[586]\ttrain's auc: 0.828856\ttrain's binary_logloss: 0.356064\n",
      "[587]\ttrain's auc: 0.828864\ttrain's binary_logloss: 0.356055\n",
      "[588]\ttrain's auc: 0.828871\ttrain's binary_logloss: 0.356047\n",
      "[589]\ttrain's auc: 0.828881\ttrain's binary_logloss: 0.356037\n",
      "[590]\ttrain's auc: 0.828895\ttrain's binary_logloss: 0.356025\n",
      "[591]\ttrain's auc: 0.828904\ttrain's binary_logloss: 0.356015\n",
      "[592]\ttrain's auc: 0.828913\ttrain's binary_logloss: 0.356006\n",
      "[593]\ttrain's auc: 0.828924\ttrain's binary_logloss: 0.355995\n",
      "[594]\ttrain's auc: 0.828936\ttrain's binary_logloss: 0.355984\n",
      "[595]\ttrain's auc: 0.828952\ttrain's binary_logloss: 0.355972\n",
      "[596]\ttrain's auc: 0.828967\ttrain's binary_logloss: 0.355958\n",
      "[597]\ttrain's auc: 0.828974\ttrain's binary_logloss: 0.35595\n",
      "[598]\ttrain's auc: 0.828992\ttrain's binary_logloss: 0.355934\n",
      "[599]\ttrain's auc: 0.829\ttrain's binary_logloss: 0.355926\n",
      "[600]\ttrain's auc: 0.829009\ttrain's binary_logloss: 0.355918\n",
      "[601]\ttrain's auc: 0.82902\ttrain's binary_logloss: 0.355908\n",
      "[602]\ttrain's auc: 0.829026\ttrain's binary_logloss: 0.355901\n",
      "[603]\ttrain's auc: 0.829042\ttrain's binary_logloss: 0.355888\n",
      "[604]\ttrain's auc: 0.829057\ttrain's binary_logloss: 0.355875\n",
      "[605]\ttrain's auc: 0.829066\ttrain's binary_logloss: 0.355865\n",
      "[606]\ttrain's auc: 0.829072\ttrain's binary_logloss: 0.355858\n",
      "[607]\ttrain's auc: 0.829084\ttrain's binary_logloss: 0.355847\n",
      "[608]\ttrain's auc: 0.829095\ttrain's binary_logloss: 0.355836\n",
      "[609]\ttrain's auc: 0.829106\ttrain's binary_logloss: 0.355825\n",
      "[610]\ttrain's auc: 0.829114\ttrain's binary_logloss: 0.355818\n",
      "[611]\ttrain's auc: 0.829125\ttrain's binary_logloss: 0.355808\n",
      "[612]\ttrain's auc: 0.829132\ttrain's binary_logloss: 0.355801\n",
      "[613]\ttrain's auc: 0.82914\ttrain's binary_logloss: 0.355793\n",
      "[614]\ttrain's auc: 0.829146\ttrain's binary_logloss: 0.355785\n",
      "[615]\ttrain's auc: 0.829153\ttrain's binary_logloss: 0.355778\n",
      "[616]\ttrain's auc: 0.829161\ttrain's binary_logloss: 0.35577\n",
      "[617]\ttrain's auc: 0.829173\ttrain's binary_logloss: 0.35576\n",
      "[618]\ttrain's auc: 0.829183\ttrain's binary_logloss: 0.355751\n",
      "[619]\ttrain's auc: 0.829193\ttrain's binary_logloss: 0.355741\n",
      "[620]\ttrain's auc: 0.8292\ttrain's binary_logloss: 0.355733\n",
      "[621]\ttrain's auc: 0.829218\ttrain's binary_logloss: 0.355718\n",
      "[622]\ttrain's auc: 0.829232\ttrain's binary_logloss: 0.355705\n",
      "[623]\ttrain's auc: 0.829243\ttrain's binary_logloss: 0.355695\n",
      "[624]\ttrain's auc: 0.82925\ttrain's binary_logloss: 0.355688\n",
      "[625]\ttrain's auc: 0.829255\ttrain's binary_logloss: 0.355682\n",
      "[626]\ttrain's auc: 0.829261\ttrain's binary_logloss: 0.355676\n",
      "[627]\ttrain's auc: 0.829281\ttrain's binary_logloss: 0.355659\n",
      "[628]\ttrain's auc: 0.829289\ttrain's binary_logloss: 0.355651\n",
      "[629]\ttrain's auc: 0.829297\ttrain's binary_logloss: 0.355643\n",
      "[630]\ttrain's auc: 0.82931\ttrain's binary_logloss: 0.355631\n",
      "[631]\ttrain's auc: 0.829324\ttrain's binary_logloss: 0.355618\n",
      "[632]\ttrain's auc: 0.829331\ttrain's binary_logloss: 0.355611\n",
      "[633]\ttrain's auc: 0.82936\ttrain's binary_logloss: 0.355587\n",
      "[634]\ttrain's auc: 0.82937\ttrain's binary_logloss: 0.355578\n",
      "[635]\ttrain's auc: 0.829377\ttrain's binary_logloss: 0.35557\n",
      "[636]\ttrain's auc: 0.829388\ttrain's binary_logloss: 0.355561\n",
      "[637]\ttrain's auc: 0.829396\ttrain's binary_logloss: 0.355553\n",
      "[638]\ttrain's auc: 0.829424\ttrain's binary_logloss: 0.35553\n",
      "[639]\ttrain's auc: 0.829428\ttrain's binary_logloss: 0.355525\n",
      "[640]\ttrain's auc: 0.829438\ttrain's binary_logloss: 0.355516\n",
      "[641]\ttrain's auc: 0.829446\ttrain's binary_logloss: 0.355509\n",
      "[642]\ttrain's auc: 0.829451\ttrain's binary_logloss: 0.355502\n",
      "[643]\ttrain's auc: 0.829466\ttrain's binary_logloss: 0.355489\n",
      "[644]\ttrain's auc: 0.82947\ttrain's binary_logloss: 0.355483\n",
      "[645]\ttrain's auc: 0.829479\ttrain's binary_logloss: 0.355475\n",
      "[646]\ttrain's auc: 0.829494\ttrain's binary_logloss: 0.355463\n",
      "[647]\ttrain's auc: 0.829504\ttrain's binary_logloss: 0.355454\n",
      "[648]\ttrain's auc: 0.829517\ttrain's binary_logloss: 0.355442\n",
      "[649]\ttrain's auc: 0.82955\ttrain's binary_logloss: 0.355417\n",
      "[650]\ttrain's auc: 0.829557\ttrain's binary_logloss: 0.355409\n",
      "[651]\ttrain's auc: 0.829567\ttrain's binary_logloss: 0.355401\n",
      "[652]\ttrain's auc: 0.829576\ttrain's binary_logloss: 0.355393\n",
      "[653]\ttrain's auc: 0.829586\ttrain's binary_logloss: 0.355384\n",
      "[654]\ttrain's auc: 0.829596\ttrain's binary_logloss: 0.355374\n",
      "[655]\ttrain's auc: 0.829608\ttrain's binary_logloss: 0.355363\n",
      "[656]\ttrain's auc: 0.829616\ttrain's binary_logloss: 0.355356\n",
      "[657]\ttrain's auc: 0.829624\ttrain's binary_logloss: 0.355348\n",
      "[658]\ttrain's auc: 0.829634\ttrain's binary_logloss: 0.35534\n",
      "[659]\ttrain's auc: 0.829639\ttrain's binary_logloss: 0.355334\n",
      "[660]\ttrain's auc: 0.829644\ttrain's binary_logloss: 0.355328\n",
      "[661]\ttrain's auc: 0.829651\ttrain's binary_logloss: 0.355322\n",
      "[662]\ttrain's auc: 0.829659\ttrain's binary_logloss: 0.355314\n",
      "[663]\ttrain's auc: 0.829674\ttrain's binary_logloss: 0.355301\n",
      "[664]\ttrain's auc: 0.829681\ttrain's binary_logloss: 0.355294\n",
      "[665]\ttrain's auc: 0.829693\ttrain's binary_logloss: 0.355283\n",
      "[666]\ttrain's auc: 0.829714\ttrain's binary_logloss: 0.355265\n",
      "[667]\ttrain's auc: 0.82972\ttrain's binary_logloss: 0.355259\n",
      "[668]\ttrain's auc: 0.829731\ttrain's binary_logloss: 0.35525\n",
      "[669]\ttrain's auc: 0.829746\ttrain's binary_logloss: 0.355236\n",
      "[670]\ttrain's auc: 0.829753\ttrain's binary_logloss: 0.35523\n",
      "[671]\ttrain's auc: 0.82976\ttrain's binary_logloss: 0.355223\n",
      "[672]\ttrain's auc: 0.829767\ttrain's binary_logloss: 0.355216\n",
      "[673]\ttrain's auc: 0.829773\ttrain's binary_logloss: 0.35521\n",
      "[674]\ttrain's auc: 0.829779\ttrain's binary_logloss: 0.355204\n",
      "[675]\ttrain's auc: 0.829788\ttrain's binary_logloss: 0.355196\n",
      "[676]\ttrain's auc: 0.829796\ttrain's binary_logloss: 0.355188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[677]\ttrain's auc: 0.829803\ttrain's binary_logloss: 0.355181\n",
      "[678]\ttrain's auc: 0.829808\ttrain's binary_logloss: 0.355175\n",
      "[679]\ttrain's auc: 0.829814\ttrain's binary_logloss: 0.355168\n",
      "[680]\ttrain's auc: 0.829822\ttrain's binary_logloss: 0.355161\n",
      "[681]\ttrain's auc: 0.829836\ttrain's binary_logloss: 0.355149\n",
      "[682]\ttrain's auc: 0.829854\ttrain's binary_logloss: 0.355133\n",
      "[683]\ttrain's auc: 0.829881\ttrain's binary_logloss: 0.355113\n",
      "[684]\ttrain's auc: 0.829894\ttrain's binary_logloss: 0.355101\n",
      "[685]\ttrain's auc: 0.829919\ttrain's binary_logloss: 0.355081\n",
      "[686]\ttrain's auc: 0.829927\ttrain's binary_logloss: 0.355073\n",
      "[687]\ttrain's auc: 0.829948\ttrain's binary_logloss: 0.355059\n",
      "[688]\ttrain's auc: 0.829953\ttrain's binary_logloss: 0.355053\n",
      "[689]\ttrain's auc: 0.82996\ttrain's binary_logloss: 0.355046\n",
      "[690]\ttrain's auc: 0.829966\ttrain's binary_logloss: 0.35504\n",
      "[691]\ttrain's auc: 0.829973\ttrain's binary_logloss: 0.355033\n",
      "[692]\ttrain's auc: 0.829982\ttrain's binary_logloss: 0.355024\n",
      "[693]\ttrain's auc: 0.829999\ttrain's binary_logloss: 0.35501\n",
      "[694]\ttrain's auc: 0.830005\ttrain's binary_logloss: 0.355005\n",
      "[695]\ttrain's auc: 0.830023\ttrain's binary_logloss: 0.35499\n",
      "[696]\ttrain's auc: 0.830029\ttrain's binary_logloss: 0.354984\n",
      "[697]\ttrain's auc: 0.830038\ttrain's binary_logloss: 0.354975\n",
      "[698]\ttrain's auc: 0.830044\ttrain's binary_logloss: 0.354969\n",
      "[699]\ttrain's auc: 0.830053\ttrain's binary_logloss: 0.35496\n",
      "[700]\ttrain's auc: 0.830064\ttrain's binary_logloss: 0.35495\n",
      "[701]\ttrain's auc: 0.830076\ttrain's binary_logloss: 0.35494\n",
      "[702]\ttrain's auc: 0.83008\ttrain's binary_logloss: 0.354935\n",
      "[703]\ttrain's auc: 0.830084\ttrain's binary_logloss: 0.35493\n",
      "[704]\ttrain's auc: 0.830091\ttrain's binary_logloss: 0.354923\n",
      "[705]\ttrain's auc: 0.830101\ttrain's binary_logloss: 0.354915\n",
      "[706]\ttrain's auc: 0.830109\ttrain's binary_logloss: 0.354908\n",
      "[707]\ttrain's auc: 0.830118\ttrain's binary_logloss: 0.3549\n",
      "[708]\ttrain's auc: 0.830125\ttrain's binary_logloss: 0.354894\n",
      "[709]\ttrain's auc: 0.830134\ttrain's binary_logloss: 0.354886\n",
      "[710]\ttrain's auc: 0.830145\ttrain's binary_logloss: 0.354877\n",
      "[711]\ttrain's auc: 0.830162\ttrain's binary_logloss: 0.354863\n",
      "[712]\ttrain's auc: 0.830169\ttrain's binary_logloss: 0.354856\n",
      "[713]\ttrain's auc: 0.830175\ttrain's binary_logloss: 0.354851\n",
      "[714]\ttrain's auc: 0.830183\ttrain's binary_logloss: 0.354843\n",
      "[715]\ttrain's auc: 0.830193\ttrain's binary_logloss: 0.354834\n",
      "[716]\ttrain's auc: 0.830204\ttrain's binary_logloss: 0.354825\n",
      "[717]\ttrain's auc: 0.830209\ttrain's binary_logloss: 0.35482\n",
      "[718]\ttrain's auc: 0.830217\ttrain's binary_logloss: 0.354812\n",
      "[719]\ttrain's auc: 0.830223\ttrain's binary_logloss: 0.354807\n",
      "[720]\ttrain's auc: 0.830228\ttrain's binary_logloss: 0.354801\n",
      "[721]\ttrain's auc: 0.830233\ttrain's binary_logloss: 0.354795\n",
      "[722]\ttrain's auc: 0.830241\ttrain's binary_logloss: 0.354788\n",
      "[723]\ttrain's auc: 0.83025\ttrain's binary_logloss: 0.354781\n",
      "[724]\ttrain's auc: 0.830261\ttrain's binary_logloss: 0.354771\n",
      "[725]\ttrain's auc: 0.830266\ttrain's binary_logloss: 0.354766\n",
      "[726]\ttrain's auc: 0.830275\ttrain's binary_logloss: 0.354758\n",
      "[727]\ttrain's auc: 0.830293\ttrain's binary_logloss: 0.354743\n",
      "[728]\ttrain's auc: 0.830298\ttrain's binary_logloss: 0.354738\n",
      "[729]\ttrain's auc: 0.830306\ttrain's binary_logloss: 0.354732\n",
      "[730]\ttrain's auc: 0.830317\ttrain's binary_logloss: 0.354722\n",
      "[731]\ttrain's auc: 0.830337\ttrain's binary_logloss: 0.354705\n",
      "[732]\ttrain's auc: 0.830342\ttrain's binary_logloss: 0.354701\n",
      "[733]\ttrain's auc: 0.830349\ttrain's binary_logloss: 0.354694\n",
      "[734]\ttrain's auc: 0.830355\ttrain's binary_logloss: 0.354689\n",
      "[735]\ttrain's auc: 0.83036\ttrain's binary_logloss: 0.354684\n",
      "[736]\ttrain's auc: 0.830372\ttrain's binary_logloss: 0.354675\n",
      "[737]\ttrain's auc: 0.830379\ttrain's binary_logloss: 0.354669\n",
      "[738]\ttrain's auc: 0.830386\ttrain's binary_logloss: 0.354663\n",
      "[739]\ttrain's auc: 0.830397\ttrain's binary_logloss: 0.354653\n",
      "[740]\ttrain's auc: 0.830408\ttrain's binary_logloss: 0.354643\n",
      "[741]\ttrain's auc: 0.830418\ttrain's binary_logloss: 0.354635\n",
      "[742]\ttrain's auc: 0.830429\ttrain's binary_logloss: 0.354625\n",
      "[743]\ttrain's auc: 0.83044\ttrain's binary_logloss: 0.354615\n",
      "[744]\ttrain's auc: 0.830463\ttrain's binary_logloss: 0.354597\n",
      "[745]\ttrain's auc: 0.830492\ttrain's binary_logloss: 0.354576\n",
      "[746]\ttrain's auc: 0.830499\ttrain's binary_logloss: 0.354569\n",
      "[747]\ttrain's auc: 0.830507\ttrain's binary_logloss: 0.354562\n",
      "[748]\ttrain's auc: 0.83052\ttrain's binary_logloss: 0.35455\n",
      "[749]\ttrain's auc: 0.830532\ttrain's binary_logloss: 0.35454\n",
      "[750]\ttrain's auc: 0.830548\ttrain's binary_logloss: 0.354527\n",
      "[751]\ttrain's auc: 0.83056\ttrain's binary_logloss: 0.354517\n",
      "[752]\ttrain's auc: 0.830574\ttrain's binary_logloss: 0.354505\n",
      "[753]\ttrain's auc: 0.830582\ttrain's binary_logloss: 0.354498\n",
      "[754]\ttrain's auc: 0.830588\ttrain's binary_logloss: 0.354491\n",
      "[755]\ttrain's auc: 0.830592\ttrain's binary_logloss: 0.354487\n",
      "[756]\ttrain's auc: 0.830607\ttrain's binary_logloss: 0.354475\n",
      "[757]\ttrain's auc: 0.830621\ttrain's binary_logloss: 0.354463\n",
      "[758]\ttrain's auc: 0.830629\ttrain's binary_logloss: 0.354456\n",
      "[759]\ttrain's auc: 0.830638\ttrain's binary_logloss: 0.354448\n",
      "[760]\ttrain's auc: 0.830643\ttrain's binary_logloss: 0.354443\n",
      "[761]\ttrain's auc: 0.83065\ttrain's binary_logloss: 0.354437\n",
      "[762]\ttrain's auc: 0.830654\ttrain's binary_logloss: 0.354432\n",
      "[763]\ttrain's auc: 0.830659\ttrain's binary_logloss: 0.354426\n",
      "[764]\ttrain's auc: 0.830663\ttrain's binary_logloss: 0.354422\n",
      "[765]\ttrain's auc: 0.830673\ttrain's binary_logloss: 0.354414\n",
      "[766]\ttrain's auc: 0.83068\ttrain's binary_logloss: 0.354407\n",
      "[767]\ttrain's auc: 0.830686\ttrain's binary_logloss: 0.354402\n",
      "[768]\ttrain's auc: 0.83069\ttrain's binary_logloss: 0.354397\n",
      "[769]\ttrain's auc: 0.830695\ttrain's binary_logloss: 0.354392\n",
      "[770]\ttrain's auc: 0.8307\ttrain's binary_logloss: 0.354388\n",
      "[771]\ttrain's auc: 0.830709\ttrain's binary_logloss: 0.35438\n",
      "[772]\ttrain's auc: 0.830713\ttrain's binary_logloss: 0.354376\n",
      "[773]\ttrain's auc: 0.830726\ttrain's binary_logloss: 0.354365\n",
      "[774]\ttrain's auc: 0.830733\ttrain's binary_logloss: 0.354359\n",
      "[775]\ttrain's auc: 0.830736\ttrain's binary_logloss: 0.354355\n",
      "[776]\ttrain's auc: 0.830744\ttrain's binary_logloss: 0.354348\n",
      "[777]\ttrain's auc: 0.830752\ttrain's binary_logloss: 0.354341\n",
      "[778]\ttrain's auc: 0.830758\ttrain's binary_logloss: 0.354337\n",
      "[779]\ttrain's auc: 0.830762\ttrain's binary_logloss: 0.354332\n",
      "[780]\ttrain's auc: 0.83077\ttrain's binary_logloss: 0.354325\n",
      "[781]\ttrain's auc: 0.830777\ttrain's binary_logloss: 0.354319\n",
      "[782]\ttrain's auc: 0.830801\ttrain's binary_logloss: 0.354301\n",
      "[783]\ttrain's auc: 0.830805\ttrain's binary_logloss: 0.354297\n",
      "[784]\ttrain's auc: 0.83081\ttrain's binary_logloss: 0.354291\n",
      "[785]\ttrain's auc: 0.830817\ttrain's binary_logloss: 0.354285\n",
      "[786]\ttrain's auc: 0.830829\ttrain's binary_logloss: 0.354275\n",
      "[787]\ttrain's auc: 0.830836\ttrain's binary_logloss: 0.354269\n",
      "[788]\ttrain's auc: 0.83084\ttrain's binary_logloss: 0.354265\n",
      "[789]\ttrain's auc: 0.830844\ttrain's binary_logloss: 0.354261\n",
      "[790]\ttrain's auc: 0.83085\ttrain's binary_logloss: 0.354255\n",
      "[791]\ttrain's auc: 0.830854\ttrain's binary_logloss: 0.354251\n",
      "[792]\ttrain's auc: 0.830859\ttrain's binary_logloss: 0.354246\n",
      "[793]\ttrain's auc: 0.830868\ttrain's binary_logloss: 0.354239\n",
      "[794]\ttrain's auc: 0.830876\ttrain's binary_logloss: 0.354231\n",
      "[795]\ttrain's auc: 0.830882\ttrain's binary_logloss: 0.354225\n",
      "[796]\ttrain's auc: 0.830886\ttrain's binary_logloss: 0.354222\n",
      "[797]\ttrain's auc: 0.830892\ttrain's binary_logloss: 0.354216\n",
      "[798]\ttrain's auc: 0.830897\ttrain's binary_logloss: 0.354211\n",
      "[799]\ttrain's auc: 0.830909\ttrain's binary_logloss: 0.354202\n",
      "[800]\ttrain's auc: 0.830931\ttrain's binary_logloss: 0.354185\n",
      "[801]\ttrain's auc: 0.83094\ttrain's binary_logloss: 0.354178\n",
      "[802]\ttrain's auc: 0.830953\ttrain's binary_logloss: 0.354167\n",
      "[803]\ttrain's auc: 0.830959\ttrain's binary_logloss: 0.354161\n",
      "[804]\ttrain's auc: 0.830966\ttrain's binary_logloss: 0.354154\n",
      "[805]\ttrain's auc: 0.83098\ttrain's binary_logloss: 0.354142\n",
      "[806]\ttrain's auc: 0.830984\ttrain's binary_logloss: 0.354138\n",
      "[807]\ttrain's auc: 0.830989\ttrain's binary_logloss: 0.354132\n",
      "[808]\ttrain's auc: 0.830994\ttrain's binary_logloss: 0.354128\n",
      "[809]\ttrain's auc: 0.831014\ttrain's binary_logloss: 0.354113\n",
      "[810]\ttrain's auc: 0.831026\ttrain's binary_logloss: 0.354103\n",
      "[811]\ttrain's auc: 0.831029\ttrain's binary_logloss: 0.354099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[812]\ttrain's auc: 0.831038\ttrain's binary_logloss: 0.354092\n",
      "[813]\ttrain's auc: 0.831043\ttrain's binary_logloss: 0.354087\n",
      "[814]\ttrain's auc: 0.831051\ttrain's binary_logloss: 0.354081\n",
      "[815]\ttrain's auc: 0.831055\ttrain's binary_logloss: 0.354076\n",
      "[816]\ttrain's auc: 0.831061\ttrain's binary_logloss: 0.35407\n",
      "[817]\ttrain's auc: 0.831065\ttrain's binary_logloss: 0.354066\n",
      "[818]\ttrain's auc: 0.831079\ttrain's binary_logloss: 0.354054\n",
      "[819]\ttrain's auc: 0.831084\ttrain's binary_logloss: 0.354049\n",
      "[820]\ttrain's auc: 0.831097\ttrain's binary_logloss: 0.354039\n",
      "[821]\ttrain's auc: 0.831102\ttrain's binary_logloss: 0.354035\n",
      "[822]\ttrain's auc: 0.831106\ttrain's binary_logloss: 0.354032\n",
      "[823]\ttrain's auc: 0.831111\ttrain's binary_logloss: 0.354027\n",
      "[824]\ttrain's auc: 0.831118\ttrain's binary_logloss: 0.354021\n",
      "[825]\ttrain's auc: 0.831122\ttrain's binary_logloss: 0.354016\n",
      "[826]\ttrain's auc: 0.831132\ttrain's binary_logloss: 0.354009\n",
      "[827]\ttrain's auc: 0.831145\ttrain's binary_logloss: 0.353998\n",
      "[828]\ttrain's auc: 0.831152\ttrain's binary_logloss: 0.353992\n",
      "[829]\ttrain's auc: 0.831159\ttrain's binary_logloss: 0.353986\n",
      "[830]\ttrain's auc: 0.831164\ttrain's binary_logloss: 0.353981\n",
      "[831]\ttrain's auc: 0.831173\ttrain's binary_logloss: 0.353972\n",
      "[832]\ttrain's auc: 0.831178\ttrain's binary_logloss: 0.353968\n",
      "[833]\ttrain's auc: 0.831185\ttrain's binary_logloss: 0.353962\n",
      "[834]\ttrain's auc: 0.831188\ttrain's binary_logloss: 0.353958\n",
      "[835]\ttrain's auc: 0.831201\ttrain's binary_logloss: 0.353947\n",
      "[836]\ttrain's auc: 0.831204\ttrain's binary_logloss: 0.353944\n",
      "[837]\ttrain's auc: 0.831219\ttrain's binary_logloss: 0.353932\n",
      "[838]\ttrain's auc: 0.831228\ttrain's binary_logloss: 0.353924\n",
      "[839]\ttrain's auc: 0.831239\ttrain's binary_logloss: 0.353915\n",
      "[840]\ttrain's auc: 0.83125\ttrain's binary_logloss: 0.353906\n",
      "[841]\ttrain's auc: 0.831256\ttrain's binary_logloss: 0.353902\n",
      "[842]\ttrain's auc: 0.831262\ttrain's binary_logloss: 0.353896\n",
      "[843]\ttrain's auc: 0.831267\ttrain's binary_logloss: 0.353892\n",
      "[844]\ttrain's auc: 0.831271\ttrain's binary_logloss: 0.353887\n",
      "[845]\ttrain's auc: 0.831274\ttrain's binary_logloss: 0.353884\n",
      "[846]\ttrain's auc: 0.831279\ttrain's binary_logloss: 0.353881\n",
      "[847]\ttrain's auc: 0.831285\ttrain's binary_logloss: 0.353875\n",
      "[848]\ttrain's auc: 0.831296\ttrain's binary_logloss: 0.353867\n",
      "[849]\ttrain's auc: 0.8313\ttrain's binary_logloss: 0.353863\n",
      "[850]\ttrain's auc: 0.831307\ttrain's binary_logloss: 0.353857\n",
      "[851]\ttrain's auc: 0.831312\ttrain's binary_logloss: 0.353852\n",
      "[852]\ttrain's auc: 0.831316\ttrain's binary_logloss: 0.353848\n",
      "[853]\ttrain's auc: 0.831321\ttrain's binary_logloss: 0.353844\n",
      "[854]\ttrain's auc: 0.831332\ttrain's binary_logloss: 0.353834\n",
      "[855]\ttrain's auc: 0.831336\ttrain's binary_logloss: 0.353831\n",
      "[856]\ttrain's auc: 0.831342\ttrain's binary_logloss: 0.353826\n",
      "[857]\ttrain's auc: 0.831348\ttrain's binary_logloss: 0.35382\n",
      "[858]\ttrain's auc: 0.831352\ttrain's binary_logloss: 0.353817\n",
      "[859]\ttrain's auc: 0.831359\ttrain's binary_logloss: 0.353811\n",
      "[860]\ttrain's auc: 0.831374\ttrain's binary_logloss: 0.3538\n",
      "[861]\ttrain's auc: 0.83138\ttrain's binary_logloss: 0.353795\n",
      "[862]\ttrain's auc: 0.83139\ttrain's binary_logloss: 0.353786\n",
      "[863]\ttrain's auc: 0.831402\ttrain's binary_logloss: 0.353777\n",
      "[864]\ttrain's auc: 0.831405\ttrain's binary_logloss: 0.353773\n",
      "[865]\ttrain's auc: 0.83141\ttrain's binary_logloss: 0.353768\n",
      "[866]\ttrain's auc: 0.831419\ttrain's binary_logloss: 0.353761\n",
      "[867]\ttrain's auc: 0.831424\ttrain's binary_logloss: 0.353756\n",
      "[868]\ttrain's auc: 0.831431\ttrain's binary_logloss: 0.35375\n",
      "[869]\ttrain's auc: 0.831435\ttrain's binary_logloss: 0.353746\n",
      "[870]\ttrain's auc: 0.83144\ttrain's binary_logloss: 0.353741\n",
      "[871]\ttrain's auc: 0.831444\ttrain's binary_logloss: 0.353738\n",
      "[872]\ttrain's auc: 0.831448\ttrain's binary_logloss: 0.353734\n",
      "[873]\ttrain's auc: 0.831452\ttrain's binary_logloss: 0.35373\n",
      "[874]\ttrain's auc: 0.83146\ttrain's binary_logloss: 0.353723\n",
      "[875]\ttrain's auc: 0.831465\ttrain's binary_logloss: 0.353718\n",
      "[876]\ttrain's auc: 0.831469\ttrain's binary_logloss: 0.353714\n",
      "[877]\ttrain's auc: 0.831473\ttrain's binary_logloss: 0.35371\n",
      "[878]\ttrain's auc: 0.831482\ttrain's binary_logloss: 0.353702\n",
      "[879]\ttrain's auc: 0.831488\ttrain's binary_logloss: 0.353697\n",
      "[880]\ttrain's auc: 0.831497\ttrain's binary_logloss: 0.353689\n",
      "[881]\ttrain's auc: 0.831505\ttrain's binary_logloss: 0.353682\n",
      "[882]\ttrain's auc: 0.831519\ttrain's binary_logloss: 0.35367\n",
      "[883]\ttrain's auc: 0.831527\ttrain's binary_logloss: 0.353663\n",
      "[884]\ttrain's auc: 0.831533\ttrain's binary_logloss: 0.353657\n",
      "[885]\ttrain's auc: 0.831539\ttrain's binary_logloss: 0.353651\n",
      "[886]\ttrain's auc: 0.831544\ttrain's binary_logloss: 0.353648\n",
      "[887]\ttrain's auc: 0.831546\ttrain's binary_logloss: 0.353645\n",
      "[888]\ttrain's auc: 0.831552\ttrain's binary_logloss: 0.35364\n",
      "[889]\ttrain's auc: 0.831555\ttrain's binary_logloss: 0.353636\n",
      "[890]\ttrain's auc: 0.831562\ttrain's binary_logloss: 0.35363\n",
      "[891]\ttrain's auc: 0.831572\ttrain's binary_logloss: 0.353622\n",
      "[892]\ttrain's auc: 0.831574\ttrain's binary_logloss: 0.353619\n",
      "[893]\ttrain's auc: 0.831582\ttrain's binary_logloss: 0.353612\n",
      "[894]\ttrain's auc: 0.831585\ttrain's binary_logloss: 0.353609\n",
      "[895]\ttrain's auc: 0.831589\ttrain's binary_logloss: 0.353606\n",
      "[896]\ttrain's auc: 0.831593\ttrain's binary_logloss: 0.353602\n",
      "[897]\ttrain's auc: 0.831597\ttrain's binary_logloss: 0.3536\n",
      "[898]\ttrain's auc: 0.8316\ttrain's binary_logloss: 0.353596\n",
      "[899]\ttrain's auc: 0.831603\ttrain's binary_logloss: 0.353593\n",
      "[900]\ttrain's auc: 0.831615\ttrain's binary_logloss: 0.353583\n",
      "[901]\ttrain's auc: 0.831618\ttrain's binary_logloss: 0.35358\n",
      "[902]\ttrain's auc: 0.831622\ttrain's binary_logloss: 0.353576\n",
      "[903]\ttrain's auc: 0.831625\ttrain's binary_logloss: 0.353573\n",
      "[904]\ttrain's auc: 0.831632\ttrain's binary_logloss: 0.353567\n",
      "[905]\ttrain's auc: 0.831637\ttrain's binary_logloss: 0.353563\n",
      "[906]\ttrain's auc: 0.831647\ttrain's binary_logloss: 0.353554\n",
      "[907]\ttrain's auc: 0.831651\ttrain's binary_logloss: 0.35355\n",
      "[908]\ttrain's auc: 0.831655\ttrain's binary_logloss: 0.353547\n",
      "[909]\ttrain's auc: 0.83166\ttrain's binary_logloss: 0.353541\n",
      "[910]\ttrain's auc: 0.831666\ttrain's binary_logloss: 0.353536\n",
      "[911]\ttrain's auc: 0.831674\ttrain's binary_logloss: 0.353529\n",
      "[912]\ttrain's auc: 0.831679\ttrain's binary_logloss: 0.353524\n",
      "[913]\ttrain's auc: 0.831685\ttrain's binary_logloss: 0.353519\n",
      "[914]\ttrain's auc: 0.831692\ttrain's binary_logloss: 0.353513\n",
      "[915]\ttrain's auc: 0.831712\ttrain's binary_logloss: 0.353498\n",
      "[916]\ttrain's auc: 0.831717\ttrain's binary_logloss: 0.353493\n",
      "[917]\ttrain's auc: 0.831723\ttrain's binary_logloss: 0.353488\n",
      "[918]\ttrain's auc: 0.831728\ttrain's binary_logloss: 0.353485\n",
      "[919]\ttrain's auc: 0.831731\ttrain's binary_logloss: 0.353481\n",
      "[920]\ttrain's auc: 0.831737\ttrain's binary_logloss: 0.353477\n",
      "[921]\ttrain's auc: 0.831746\ttrain's binary_logloss: 0.353469\n",
      "[922]\ttrain's auc: 0.831755\ttrain's binary_logloss: 0.353461\n",
      "[923]\ttrain's auc: 0.831761\ttrain's binary_logloss: 0.353456\n",
      "[924]\ttrain's auc: 0.831766\ttrain's binary_logloss: 0.353452\n",
      "[925]\ttrain's auc: 0.83177\ttrain's binary_logloss: 0.353448\n",
      "[926]\ttrain's auc: 0.831776\ttrain's binary_logloss: 0.353442\n",
      "[927]\ttrain's auc: 0.83178\ttrain's binary_logloss: 0.353439\n",
      "[928]\ttrain's auc: 0.831784\ttrain's binary_logloss: 0.353435\n",
      "[929]\ttrain's auc: 0.831792\ttrain's binary_logloss: 0.35343\n",
      "[930]\ttrain's auc: 0.8318\ttrain's binary_logloss: 0.353422\n",
      "[931]\ttrain's auc: 0.831808\ttrain's binary_logloss: 0.353417\n",
      "[932]\ttrain's auc: 0.831811\ttrain's binary_logloss: 0.353413\n",
      "[933]\ttrain's auc: 0.831815\ttrain's binary_logloss: 0.353409\n",
      "[934]\ttrain's auc: 0.831818\ttrain's binary_logloss: 0.353406\n",
      "[935]\ttrain's auc: 0.83182\ttrain's binary_logloss: 0.353403\n",
      "[936]\ttrain's auc: 0.831823\ttrain's binary_logloss: 0.3534\n",
      "[937]\ttrain's auc: 0.83183\ttrain's binary_logloss: 0.353394\n",
      "[938]\ttrain's auc: 0.831833\ttrain's binary_logloss: 0.353391\n",
      "[939]\ttrain's auc: 0.831838\ttrain's binary_logloss: 0.353386\n",
      "[940]\ttrain's auc: 0.831843\ttrain's binary_logloss: 0.353382\n",
      "[941]\ttrain's auc: 0.831846\ttrain's binary_logloss: 0.353379\n",
      "[942]\ttrain's auc: 0.831849\ttrain's binary_logloss: 0.353376\n",
      "[943]\ttrain's auc: 0.831854\ttrain's binary_logloss: 0.353372\n",
      "[944]\ttrain's auc: 0.831857\ttrain's binary_logloss: 0.353368\n",
      "[945]\ttrain's auc: 0.831864\ttrain's binary_logloss: 0.353362\n",
      "[946]\ttrain's auc: 0.831868\ttrain's binary_logloss: 0.353359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[947]\ttrain's auc: 0.831876\ttrain's binary_logloss: 0.353352\n",
      "[948]\ttrain's auc: 0.83188\ttrain's binary_logloss: 0.353349\n",
      "[949]\ttrain's auc: 0.831892\ttrain's binary_logloss: 0.353338\n",
      "[950]\ttrain's auc: 0.831896\ttrain's binary_logloss: 0.353335\n",
      "[951]\ttrain's auc: 0.831898\ttrain's binary_logloss: 0.353331\n",
      "[952]\ttrain's auc: 0.831902\ttrain's binary_logloss: 0.353327\n",
      "[953]\ttrain's auc: 0.831905\ttrain's binary_logloss: 0.353324\n",
      "[954]\ttrain's auc: 0.83191\ttrain's binary_logloss: 0.35332\n",
      "[955]\ttrain's auc: 0.831913\ttrain's binary_logloss: 0.353316\n",
      "[956]\ttrain's auc: 0.831915\ttrain's binary_logloss: 0.353314\n",
      "[957]\ttrain's auc: 0.83192\ttrain's binary_logloss: 0.35331\n",
      "[958]\ttrain's auc: 0.831929\ttrain's binary_logloss: 0.353303\n",
      "[959]\ttrain's auc: 0.831933\ttrain's binary_logloss: 0.353298\n",
      "[960]\ttrain's auc: 0.831938\ttrain's binary_logloss: 0.353294\n",
      "[961]\ttrain's auc: 0.831942\ttrain's binary_logloss: 0.35329\n",
      "[962]\ttrain's auc: 0.831945\ttrain's binary_logloss: 0.353287\n",
      "[963]\ttrain's auc: 0.831949\ttrain's binary_logloss: 0.353284\n",
      "[964]\ttrain's auc: 0.83196\ttrain's binary_logloss: 0.353275\n",
      "[965]\ttrain's auc: 0.831969\ttrain's binary_logloss: 0.353267\n",
      "[966]\ttrain's auc: 0.831974\ttrain's binary_logloss: 0.353263\n",
      "[967]\ttrain's auc: 0.831977\ttrain's binary_logloss: 0.35326\n",
      "[968]\ttrain's auc: 0.83198\ttrain's binary_logloss: 0.353258\n",
      "[969]\ttrain's auc: 0.831986\ttrain's binary_logloss: 0.353251\n",
      "[970]\ttrain's auc: 0.832004\ttrain's binary_logloss: 0.353237\n",
      "[971]\ttrain's auc: 0.83201\ttrain's binary_logloss: 0.353231\n",
      "[972]\ttrain's auc: 0.832022\ttrain's binary_logloss: 0.353221\n",
      "[973]\ttrain's auc: 0.832029\ttrain's binary_logloss: 0.353215\n",
      "[974]\ttrain's auc: 0.832033\ttrain's binary_logloss: 0.353212\n",
      "[975]\ttrain's auc: 0.832037\ttrain's binary_logloss: 0.353209\n",
      "[976]\ttrain's auc: 0.832041\ttrain's binary_logloss: 0.353205\n",
      "[977]\ttrain's auc: 0.832057\ttrain's binary_logloss: 0.353192\n",
      "[978]\ttrain's auc: 0.83206\ttrain's binary_logloss: 0.353189\n",
      "[979]\ttrain's auc: 0.832065\ttrain's binary_logloss: 0.353185\n",
      "[980]\ttrain's auc: 0.832069\ttrain's binary_logloss: 0.353182\n",
      "[981]\ttrain's auc: 0.832078\ttrain's binary_logloss: 0.353174\n",
      "[982]\ttrain's auc: 0.832084\ttrain's binary_logloss: 0.353169\n",
      "[983]\ttrain's auc: 0.832087\ttrain's binary_logloss: 0.353165\n",
      "[984]\ttrain's auc: 0.832091\ttrain's binary_logloss: 0.353162\n",
      "[985]\ttrain's auc: 0.832095\ttrain's binary_logloss: 0.353159\n",
      "[986]\ttrain's auc: 0.832101\ttrain's binary_logloss: 0.353153\n",
      "[987]\ttrain's auc: 0.832116\ttrain's binary_logloss: 0.35314\n",
      "[988]\ttrain's auc: 0.832121\ttrain's binary_logloss: 0.353135\n",
      "[989]\ttrain's auc: 0.832122\ttrain's binary_logloss: 0.353133\n",
      "[990]\ttrain's auc: 0.832127\ttrain's binary_logloss: 0.353129\n",
      "[991]\ttrain's auc: 0.832131\ttrain's binary_logloss: 0.353125\n",
      "[992]\ttrain's auc: 0.832142\ttrain's binary_logloss: 0.353117\n",
      "[993]\ttrain's auc: 0.832152\ttrain's binary_logloss: 0.353108\n",
      "[994]\ttrain's auc: 0.832155\ttrain's binary_logloss: 0.353105\n",
      "[995]\ttrain's auc: 0.832163\ttrain's binary_logloss: 0.353098\n",
      "[996]\ttrain's auc: 0.832168\ttrain's binary_logloss: 0.353094\n",
      "[997]\ttrain's auc: 0.832172\ttrain's binary_logloss: 0.35309\n",
      "[998]\ttrain's auc: 0.832179\ttrain's binary_logloss: 0.353083\n",
      "[999]\ttrain's auc: 0.832182\ttrain's binary_logloss: 0.35308\n",
      "[1000]\ttrain's auc: 0.832187\ttrain's binary_logloss: 0.353076\n",
      "[1001]\ttrain's auc: 0.83219\ttrain's binary_logloss: 0.353073\n",
      "[1002]\ttrain's auc: 0.832194\ttrain's binary_logloss: 0.353071\n",
      "[1003]\ttrain's auc: 0.832202\ttrain's binary_logloss: 0.353063\n",
      "[1004]\ttrain's auc: 0.832205\ttrain's binary_logloss: 0.353061\n",
      "[1005]\ttrain's auc: 0.83221\ttrain's binary_logloss: 0.353056\n",
      "[1006]\ttrain's auc: 0.832213\ttrain's binary_logloss: 0.353053\n",
      "[1007]\ttrain's auc: 0.832216\ttrain's binary_logloss: 0.35305\n",
      "[1008]\ttrain's auc: 0.832218\ttrain's binary_logloss: 0.353047\n",
      "[1009]\ttrain's auc: 0.832223\ttrain's binary_logloss: 0.353043\n",
      "[1010]\ttrain's auc: 0.832227\ttrain's binary_logloss: 0.35304\n",
      "[1011]\ttrain's auc: 0.83223\ttrain's binary_logloss: 0.353037\n",
      "[1012]\ttrain's auc: 0.832238\ttrain's binary_logloss: 0.353031\n",
      "[1013]\ttrain's auc: 0.83224\ttrain's binary_logloss: 0.353029\n",
      "[1014]\ttrain's auc: 0.832244\ttrain's binary_logloss: 0.353025\n",
      "[1015]\ttrain's auc: 0.832247\ttrain's binary_logloss: 0.353022\n",
      "[1016]\ttrain's auc: 0.83225\ttrain's binary_logloss: 0.35302\n",
      "[1017]\ttrain's auc: 0.832254\ttrain's binary_logloss: 0.353016\n",
      "[1018]\ttrain's auc: 0.832257\ttrain's binary_logloss: 0.353013\n",
      "[1019]\ttrain's auc: 0.83226\ttrain's binary_logloss: 0.35301\n",
      "[1020]\ttrain's auc: 0.832264\ttrain's binary_logloss: 0.353007\n",
      "[1021]\ttrain's auc: 0.83227\ttrain's binary_logloss: 0.353002\n",
      "[1022]\ttrain's auc: 0.832274\ttrain's binary_logloss: 0.352999\n",
      "[1023]\ttrain's auc: 0.832278\ttrain's binary_logloss: 0.352995\n",
      "[1024]\ttrain's auc: 0.832282\ttrain's binary_logloss: 0.352992\n",
      "[1025]\ttrain's auc: 0.832284\ttrain's binary_logloss: 0.35299\n",
      "[1026]\ttrain's auc: 0.83229\ttrain's binary_logloss: 0.352985\n",
      "[1027]\ttrain's auc: 0.832296\ttrain's binary_logloss: 0.352979\n",
      "[1028]\ttrain's auc: 0.832299\ttrain's binary_logloss: 0.352977\n",
      "[1029]\ttrain's auc: 0.832301\ttrain's binary_logloss: 0.352974\n",
      "[1030]\ttrain's auc: 0.832305\ttrain's binary_logloss: 0.352971\n",
      "[1031]\ttrain's auc: 0.832309\ttrain's binary_logloss: 0.352967\n",
      "[1032]\ttrain's auc: 0.832313\ttrain's binary_logloss: 0.352964\n",
      "[1033]\ttrain's auc: 0.832321\ttrain's binary_logloss: 0.352957\n",
      "[1034]\ttrain's auc: 0.832325\ttrain's binary_logloss: 0.352954\n",
      "[1035]\ttrain's auc: 0.832328\ttrain's binary_logloss: 0.352952\n",
      "[1036]\ttrain's auc: 0.832333\ttrain's binary_logloss: 0.352946\n",
      "[1037]\ttrain's auc: 0.832335\ttrain's binary_logloss: 0.352944\n",
      "[1038]\ttrain's auc: 0.83235\ttrain's binary_logloss: 0.352932\n",
      "[1039]\ttrain's auc: 0.832368\ttrain's binary_logloss: 0.352918\n",
      "[1040]\ttrain's auc: 0.832373\ttrain's binary_logloss: 0.352913\n",
      "[1041]\ttrain's auc: 0.832376\ttrain's binary_logloss: 0.352911\n",
      "[1042]\ttrain's auc: 0.832378\ttrain's binary_logloss: 0.352908\n",
      "[1043]\ttrain's auc: 0.832381\ttrain's binary_logloss: 0.352904\n",
      "[1044]\ttrain's auc: 0.832384\ttrain's binary_logloss: 0.352902\n",
      "[1045]\ttrain's auc: 0.832386\ttrain's binary_logloss: 0.3529\n",
      "[1046]\ttrain's auc: 0.832391\ttrain's binary_logloss: 0.352896\n",
      "[1047]\ttrain's auc: 0.832406\ttrain's binary_logloss: 0.352884\n",
      "[1048]\ttrain's auc: 0.832411\ttrain's binary_logloss: 0.352879\n",
      "[1049]\ttrain's auc: 0.832414\ttrain's binary_logloss: 0.352876\n",
      "[1050]\ttrain's auc: 0.832417\ttrain's binary_logloss: 0.352874\n",
      "[1051]\ttrain's auc: 0.832421\ttrain's binary_logloss: 0.35287\n",
      "[1052]\ttrain's auc: 0.832425\ttrain's binary_logloss: 0.352867\n",
      "[1053]\ttrain's auc: 0.832428\ttrain's binary_logloss: 0.352864\n",
      "[1054]\ttrain's auc: 0.832433\ttrain's binary_logloss: 0.352859\n",
      "[1055]\ttrain's auc: 0.83244\ttrain's binary_logloss: 0.352854\n",
      "[1056]\ttrain's auc: 0.832445\ttrain's binary_logloss: 0.352849\n",
      "[1057]\ttrain's auc: 0.832448\ttrain's binary_logloss: 0.352846\n",
      "[1058]\ttrain's auc: 0.83245\ttrain's binary_logloss: 0.352843\n",
      "[1059]\ttrain's auc: 0.832452\ttrain's binary_logloss: 0.352841\n",
      "[1060]\ttrain's auc: 0.832458\ttrain's binary_logloss: 0.352836\n",
      "[1061]\ttrain's auc: 0.832461\ttrain's binary_logloss: 0.352833\n",
      "[1062]\ttrain's auc: 0.832464\ttrain's binary_logloss: 0.35283\n",
      "[1063]\ttrain's auc: 0.832467\ttrain's binary_logloss: 0.352828\n",
      "[1064]\ttrain's auc: 0.832473\ttrain's binary_logloss: 0.352822\n",
      "[1065]\ttrain's auc: 0.832475\ttrain's binary_logloss: 0.352819\n",
      "[1066]\ttrain's auc: 0.832479\ttrain's binary_logloss: 0.352817\n",
      "[1067]\ttrain's auc: 0.832481\ttrain's binary_logloss: 0.352814\n",
      "[1068]\ttrain's auc: 0.832487\ttrain's binary_logloss: 0.352808\n",
      "[1069]\ttrain's auc: 0.83249\ttrain's binary_logloss: 0.352805\n",
      "[1070]\ttrain's auc: 0.832493\ttrain's binary_logloss: 0.352803\n",
      "[1071]\ttrain's auc: 0.8325\ttrain's binary_logloss: 0.352797\n",
      "[1072]\ttrain's auc: 0.832504\ttrain's binary_logloss: 0.352794\n",
      "[1073]\ttrain's auc: 0.832507\ttrain's binary_logloss: 0.352791\n",
      "[1074]\ttrain's auc: 0.83251\ttrain's binary_logloss: 0.352789\n",
      "[1075]\ttrain's auc: 0.832512\ttrain's binary_logloss: 0.352786\n",
      "[1076]\ttrain's auc: 0.832515\ttrain's binary_logloss: 0.352783\n",
      "[1077]\ttrain's auc: 0.832518\ttrain's binary_logloss: 0.35278\n",
      "[1078]\ttrain's auc: 0.83252\ttrain's binary_logloss: 0.352778\n",
      "[1079]\ttrain's auc: 0.832524\ttrain's binary_logloss: 0.352775\n",
      "[1080]\ttrain's auc: 0.832528\ttrain's binary_logloss: 0.352771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1081]\ttrain's auc: 0.832532\ttrain's binary_logloss: 0.352768\n",
      "[1082]\ttrain's auc: 0.832535\ttrain's binary_logloss: 0.352765\n",
      "[1083]\ttrain's auc: 0.832539\ttrain's binary_logloss: 0.352761\n",
      "[1084]\ttrain's auc: 0.832546\ttrain's binary_logloss: 0.352755\n",
      "[1085]\ttrain's auc: 0.832551\ttrain's binary_logloss: 0.352751\n",
      "[1086]\ttrain's auc: 0.832556\ttrain's binary_logloss: 0.352747\n",
      "[1087]\ttrain's auc: 0.83256\ttrain's binary_logloss: 0.352743\n",
      "[1088]\ttrain's auc: 0.83257\ttrain's binary_logloss: 0.352735\n",
      "[1089]\ttrain's auc: 0.832573\ttrain's binary_logloss: 0.352731\n",
      "[1090]\ttrain's auc: 0.832576\ttrain's binary_logloss: 0.352728\n",
      "[1091]\ttrain's auc: 0.83258\ttrain's binary_logloss: 0.352724\n",
      "[1092]\ttrain's auc: 0.832583\ttrain's binary_logloss: 0.352721\n",
      "[1093]\ttrain's auc: 0.832591\ttrain's binary_logloss: 0.352714\n",
      "[1094]\ttrain's auc: 0.832594\ttrain's binary_logloss: 0.352711\n",
      "[1095]\ttrain's auc: 0.832598\ttrain's binary_logloss: 0.352708\n",
      "[1096]\ttrain's auc: 0.832604\ttrain's binary_logloss: 0.352703\n",
      "[1097]\ttrain's auc: 0.832607\ttrain's binary_logloss: 0.3527\n",
      "[1098]\ttrain's auc: 0.832612\ttrain's binary_logloss: 0.352695\n",
      "[1099]\ttrain's auc: 0.832616\ttrain's binary_logloss: 0.352692\n",
      "[1100]\ttrain's auc: 0.832618\ttrain's binary_logloss: 0.352689\n",
      "[1101]\ttrain's auc: 0.83262\ttrain's binary_logloss: 0.352687\n",
      "[1102]\ttrain's auc: 0.832623\ttrain's binary_logloss: 0.352685\n",
      "[1103]\ttrain's auc: 0.832625\ttrain's binary_logloss: 0.352682\n",
      "[1104]\ttrain's auc: 0.832629\ttrain's binary_logloss: 0.352679\n",
      "[1105]\ttrain's auc: 0.832637\ttrain's binary_logloss: 0.352672\n",
      "[1106]\ttrain's auc: 0.832639\ttrain's binary_logloss: 0.35267\n",
      "[1107]\ttrain's auc: 0.832643\ttrain's binary_logloss: 0.352668\n",
      "[1108]\ttrain's auc: 0.832659\ttrain's binary_logloss: 0.352655\n",
      "[1109]\ttrain's auc: 0.832661\ttrain's binary_logloss: 0.352653\n",
      "[1110]\ttrain's auc: 0.832664\ttrain's binary_logloss: 0.35265\n",
      "[1111]\ttrain's auc: 0.832667\ttrain's binary_logloss: 0.352648\n",
      "[1112]\ttrain's auc: 0.83267\ttrain's binary_logloss: 0.352645\n",
      "[1113]\ttrain's auc: 0.832673\ttrain's binary_logloss: 0.352643\n",
      "[1114]\ttrain's auc: 0.832676\ttrain's binary_logloss: 0.35264\n",
      "[1115]\ttrain's auc: 0.832679\ttrain's binary_logloss: 0.352638\n",
      "[1116]\ttrain's auc: 0.832684\ttrain's binary_logloss: 0.352633\n",
      "[1117]\ttrain's auc: 0.832687\ttrain's binary_logloss: 0.352631\n",
      "[1118]\ttrain's auc: 0.832689\ttrain's binary_logloss: 0.352629\n",
      "[1119]\ttrain's auc: 0.832693\ttrain's binary_logloss: 0.352625\n",
      "[1120]\ttrain's auc: 0.832698\ttrain's binary_logloss: 0.352621\n",
      "[1121]\ttrain's auc: 0.8327\ttrain's binary_logloss: 0.352619\n",
      "[1122]\ttrain's auc: 0.832706\ttrain's binary_logloss: 0.352613\n",
      "[1123]\ttrain's auc: 0.832709\ttrain's binary_logloss: 0.352611\n",
      "[1124]\ttrain's auc: 0.832712\ttrain's binary_logloss: 0.352608\n",
      "[1125]\ttrain's auc: 0.832714\ttrain's binary_logloss: 0.352605\n",
      "[1126]\ttrain's auc: 0.832717\ttrain's binary_logloss: 0.352602\n",
      "[1127]\ttrain's auc: 0.832724\ttrain's binary_logloss: 0.352596\n",
      "[1128]\ttrain's auc: 0.832728\ttrain's binary_logloss: 0.352593\n",
      "[1129]\ttrain's auc: 0.832731\ttrain's binary_logloss: 0.352589\n",
      "[1130]\ttrain's auc: 0.832736\ttrain's binary_logloss: 0.352585\n",
      "[1131]\ttrain's auc: 0.832739\ttrain's binary_logloss: 0.352583\n",
      "[1132]\ttrain's auc: 0.832743\ttrain's binary_logloss: 0.352579\n",
      "[1133]\ttrain's auc: 0.832746\ttrain's binary_logloss: 0.352576\n",
      "[1134]\ttrain's auc: 0.832752\ttrain's binary_logloss: 0.352571\n",
      "[1135]\ttrain's auc: 0.832757\ttrain's binary_logloss: 0.352567\n",
      "[1136]\ttrain's auc: 0.83276\ttrain's binary_logloss: 0.352565\n",
      "[1137]\ttrain's auc: 0.832763\ttrain's binary_logloss: 0.352562\n",
      "[1138]\ttrain's auc: 0.832771\ttrain's binary_logloss: 0.352555\n",
      "[1139]\ttrain's auc: 0.832773\ttrain's binary_logloss: 0.352552\n",
      "[1140]\ttrain's auc: 0.832776\ttrain's binary_logloss: 0.35255\n",
      "[1141]\ttrain's auc: 0.832778\ttrain's binary_logloss: 0.352547\n",
      "[1142]\ttrain's auc: 0.832781\ttrain's binary_logloss: 0.352545\n",
      "[1143]\ttrain's auc: 0.832784\ttrain's binary_logloss: 0.352542\n",
      "[1144]\ttrain's auc: 0.832787\ttrain's binary_logloss: 0.35254\n",
      "[1145]\ttrain's auc: 0.832795\ttrain's binary_logloss: 0.352533\n",
      "[1146]\ttrain's auc: 0.832797\ttrain's binary_logloss: 0.35253\n",
      "[1147]\ttrain's auc: 0.832802\ttrain's binary_logloss: 0.352525\n",
      "[1148]\ttrain's auc: 0.832808\ttrain's binary_logloss: 0.352521\n",
      "[1149]\ttrain's auc: 0.83281\ttrain's binary_logloss: 0.352518\n",
      "[1150]\ttrain's auc: 0.832813\ttrain's binary_logloss: 0.352515\n",
      "[1151]\ttrain's auc: 0.832818\ttrain's binary_logloss: 0.352512\n",
      "[1152]\ttrain's auc: 0.832821\ttrain's binary_logloss: 0.352509\n",
      "[1153]\ttrain's auc: 0.832823\ttrain's binary_logloss: 0.352506\n",
      "[1154]\ttrain's auc: 0.832825\ttrain's binary_logloss: 0.352504\n",
      "[1155]\ttrain's auc: 0.832832\ttrain's binary_logloss: 0.352499\n",
      "[1156]\ttrain's auc: 0.832834\ttrain's binary_logloss: 0.352496\n",
      "[1157]\ttrain's auc: 0.832843\ttrain's binary_logloss: 0.352489\n",
      "[1158]\ttrain's auc: 0.832846\ttrain's binary_logloss: 0.352487\n",
      "[1159]\ttrain's auc: 0.832859\ttrain's binary_logloss: 0.352476\n",
      "[1160]\ttrain's auc: 0.832862\ttrain's binary_logloss: 0.352473\n",
      "[1161]\ttrain's auc: 0.832868\ttrain's binary_logloss: 0.352467\n",
      "[1162]\ttrain's auc: 0.832872\ttrain's binary_logloss: 0.352464\n",
      "[1163]\ttrain's auc: 0.832875\ttrain's binary_logloss: 0.352462\n",
      "[1164]\ttrain's auc: 0.832877\ttrain's binary_logloss: 0.35246\n",
      "[1165]\ttrain's auc: 0.832879\ttrain's binary_logloss: 0.352458\n",
      "[1166]\ttrain's auc: 0.832882\ttrain's binary_logloss: 0.352455\n",
      "[1167]\ttrain's auc: 0.832886\ttrain's binary_logloss: 0.352452\n",
      "[1168]\ttrain's auc: 0.832897\ttrain's binary_logloss: 0.352442\n",
      "[1169]\ttrain's auc: 0.832901\ttrain's binary_logloss: 0.352439\n",
      "[1170]\ttrain's auc: 0.832915\ttrain's binary_logloss: 0.352428\n",
      "[1171]\ttrain's auc: 0.832918\ttrain's binary_logloss: 0.352425\n",
      "[1172]\ttrain's auc: 0.83292\ttrain's binary_logloss: 0.352422\n",
      "[1173]\ttrain's auc: 0.832931\ttrain's binary_logloss: 0.352413\n",
      "[1174]\ttrain's auc: 0.832941\ttrain's binary_logloss: 0.352405\n",
      "[1175]\ttrain's auc: 0.832944\ttrain's binary_logloss: 0.352402\n",
      "[1176]\ttrain's auc: 0.83295\ttrain's binary_logloss: 0.352397\n",
      "[1177]\ttrain's auc: 0.832953\ttrain's binary_logloss: 0.352394\n",
      "[1178]\ttrain's auc: 0.832956\ttrain's binary_logloss: 0.352392\n",
      "[1179]\ttrain's auc: 0.832958\ttrain's binary_logloss: 0.352389\n",
      "[1180]\ttrain's auc: 0.832961\ttrain's binary_logloss: 0.352386\n",
      "[1181]\ttrain's auc: 0.832963\ttrain's binary_logloss: 0.352384\n",
      "[1182]\ttrain's auc: 0.832967\ttrain's binary_logloss: 0.352381\n",
      "[1183]\ttrain's auc: 0.832968\ttrain's binary_logloss: 0.352379\n",
      "[1184]\ttrain's auc: 0.832971\ttrain's binary_logloss: 0.352376\n",
      "[1185]\ttrain's auc: 0.832973\ttrain's binary_logloss: 0.352374\n",
      "[1186]\ttrain's auc: 0.832978\ttrain's binary_logloss: 0.352369\n",
      "[1187]\ttrain's auc: 0.832981\ttrain's binary_logloss: 0.352367\n",
      "[1188]\ttrain's auc: 0.832986\ttrain's binary_logloss: 0.352361\n",
      "[1189]\ttrain's auc: 0.832989\ttrain's binary_logloss: 0.352359\n",
      "[1190]\ttrain's auc: 0.832991\ttrain's binary_logloss: 0.352357\n",
      "[1191]\ttrain's auc: 0.832994\ttrain's binary_logloss: 0.352355\n",
      "[1192]\ttrain's auc: 0.832998\ttrain's binary_logloss: 0.35235\n",
      "[1193]\ttrain's auc: 0.833003\ttrain's binary_logloss: 0.352345\n",
      "[1194]\ttrain's auc: 0.833006\ttrain's binary_logloss: 0.352343\n",
      "[1195]\ttrain's auc: 0.833007\ttrain's binary_logloss: 0.352342\n",
      "[1196]\ttrain's auc: 0.833024\ttrain's binary_logloss: 0.352328\n",
      "[1197]\ttrain's auc: 0.833027\ttrain's binary_logloss: 0.352326\n",
      "[1198]\ttrain's auc: 0.833033\ttrain's binary_logloss: 0.352322\n",
      "[1199]\ttrain's auc: 0.833035\ttrain's binary_logloss: 0.352319\n",
      "[1200]\ttrain's auc: 0.833038\ttrain's binary_logloss: 0.352317\n",
      "[1201]\ttrain's auc: 0.833041\ttrain's binary_logloss: 0.352314\n",
      "[1202]\ttrain's auc: 0.833042\ttrain's binary_logloss: 0.352313\n",
      "[1203]\ttrain's auc: 0.833049\ttrain's binary_logloss: 0.352307\n",
      "[1204]\ttrain's auc: 0.833051\ttrain's binary_logloss: 0.352305\n",
      "[1205]\ttrain's auc: 0.833055\ttrain's binary_logloss: 0.352302\n",
      "[1206]\ttrain's auc: 0.83306\ttrain's binary_logloss: 0.352297\n",
      "[1207]\ttrain's auc: 0.833062\ttrain's binary_logloss: 0.352294\n",
      "[1208]\ttrain's auc: 0.833066\ttrain's binary_logloss: 0.352291\n",
      "[1209]\ttrain's auc: 0.833068\ttrain's binary_logloss: 0.352289\n",
      "[1210]\ttrain's auc: 0.833074\ttrain's binary_logloss: 0.352284\n",
      "[1211]\ttrain's auc: 0.833077\ttrain's binary_logloss: 0.352281\n",
      "[1212]\ttrain's auc: 0.83308\ttrain's binary_logloss: 0.352279\n",
      "[1213]\ttrain's auc: 0.833084\ttrain's binary_logloss: 0.352275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1214]\ttrain's auc: 0.833087\ttrain's binary_logloss: 0.352273\n",
      "[1215]\ttrain's auc: 0.833091\ttrain's binary_logloss: 0.352269\n",
      "[1216]\ttrain's auc: 0.833093\ttrain's binary_logloss: 0.352267\n",
      "[1217]\ttrain's auc: 0.833095\ttrain's binary_logloss: 0.352265\n",
      "[1218]\ttrain's auc: 0.833098\ttrain's binary_logloss: 0.352263\n",
      "[1219]\ttrain's auc: 0.833101\ttrain's binary_logloss: 0.352259\n",
      "[1220]\ttrain's auc: 0.833104\ttrain's binary_logloss: 0.352257\n",
      "[1221]\ttrain's auc: 0.833106\ttrain's binary_logloss: 0.352255\n",
      "[1222]\ttrain's auc: 0.83311\ttrain's binary_logloss: 0.352252\n",
      "[1223]\ttrain's auc: 0.833112\ttrain's binary_logloss: 0.35225\n",
      "[1224]\ttrain's auc: 0.833114\ttrain's binary_logloss: 0.352248\n",
      "[1225]\ttrain's auc: 0.833118\ttrain's binary_logloss: 0.352244\n",
      "[1226]\ttrain's auc: 0.83312\ttrain's binary_logloss: 0.352242\n",
      "[1227]\ttrain's auc: 0.833122\ttrain's binary_logloss: 0.35224\n",
      "[1228]\ttrain's auc: 0.833125\ttrain's binary_logloss: 0.352238\n",
      "[1229]\ttrain's auc: 0.833127\ttrain's binary_logloss: 0.352236\n",
      "[1230]\ttrain's auc: 0.833131\ttrain's binary_logloss: 0.352233\n",
      "[1231]\ttrain's auc: 0.833133\ttrain's binary_logloss: 0.352231\n",
      "[1232]\ttrain's auc: 0.833136\ttrain's binary_logloss: 0.352229\n",
      "[1233]\ttrain's auc: 0.833138\ttrain's binary_logloss: 0.352227\n",
      "[1234]\ttrain's auc: 0.83314\ttrain's binary_logloss: 0.352225\n",
      "[1235]\ttrain's auc: 0.833145\ttrain's binary_logloss: 0.352221\n",
      "[1236]\ttrain's auc: 0.833152\ttrain's binary_logloss: 0.352215\n",
      "[1237]\ttrain's auc: 0.833156\ttrain's binary_logloss: 0.352212\n",
      "[1238]\ttrain's auc: 0.83316\ttrain's binary_logloss: 0.352209\n",
      "[1239]\ttrain's auc: 0.833162\ttrain's binary_logloss: 0.352207\n",
      "[1240]\ttrain's auc: 0.833169\ttrain's binary_logloss: 0.352201\n",
      "[1241]\ttrain's auc: 0.833171\ttrain's binary_logloss: 0.352199\n",
      "[1242]\ttrain's auc: 0.833174\ttrain's binary_logloss: 0.352197\n",
      "[1243]\ttrain's auc: 0.833177\ttrain's binary_logloss: 0.352195\n",
      "[1244]\ttrain's auc: 0.833179\ttrain's binary_logloss: 0.352192\n",
      "[1245]\ttrain's auc: 0.833182\ttrain's binary_logloss: 0.35219\n",
      "[1246]\ttrain's auc: 0.833184\ttrain's binary_logloss: 0.352188\n",
      "[1247]\ttrain's auc: 0.833187\ttrain's binary_logloss: 0.352186\n",
      "[1248]\ttrain's auc: 0.833189\ttrain's binary_logloss: 0.352184\n",
      "[1249]\ttrain's auc: 0.833192\ttrain's binary_logloss: 0.352181\n",
      "[1250]\ttrain's auc: 0.833195\ttrain's binary_logloss: 0.352178\n",
      "[1251]\ttrain's auc: 0.833203\ttrain's binary_logloss: 0.352172\n",
      "[1252]\ttrain's auc: 0.833206\ttrain's binary_logloss: 0.352169\n",
      "[1253]\ttrain's auc: 0.83321\ttrain's binary_logloss: 0.352166\n",
      "[1254]\ttrain's auc: 0.833212\ttrain's binary_logloss: 0.352163\n",
      "[1255]\ttrain's auc: 0.833215\ttrain's binary_logloss: 0.352161\n",
      "[1256]\ttrain's auc: 0.833224\ttrain's binary_logloss: 0.352153\n",
      "[1257]\ttrain's auc: 0.833228\ttrain's binary_logloss: 0.35215\n",
      "[1258]\ttrain's auc: 0.833234\ttrain's binary_logloss: 0.352144\n",
      "[1259]\ttrain's auc: 0.833238\ttrain's binary_logloss: 0.352141\n",
      "[1260]\ttrain's auc: 0.833241\ttrain's binary_logloss: 0.352139\n",
      "[1261]\ttrain's auc: 0.833244\ttrain's binary_logloss: 0.352137\n",
      "[1262]\ttrain's auc: 0.833246\ttrain's binary_logloss: 0.352135\n",
      "[1263]\ttrain's auc: 0.833248\ttrain's binary_logloss: 0.352133\n",
      "[1264]\ttrain's auc: 0.833252\ttrain's binary_logloss: 0.352129\n",
      "[1265]\ttrain's auc: 0.833254\ttrain's binary_logloss: 0.352127\n",
      "[1266]\ttrain's auc: 0.833261\ttrain's binary_logloss: 0.352121\n",
      "[1267]\ttrain's auc: 0.833263\ttrain's binary_logloss: 0.352119\n",
      "[1268]\ttrain's auc: 0.833267\ttrain's binary_logloss: 0.352116\n",
      "[1269]\ttrain's auc: 0.833268\ttrain's binary_logloss: 0.352114\n",
      "[1270]\ttrain's auc: 0.833272\ttrain's binary_logloss: 0.352111\n",
      "[1271]\ttrain's auc: 0.833274\ttrain's binary_logloss: 0.352109\n",
      "[1272]\ttrain's auc: 0.833276\ttrain's binary_logloss: 0.352107\n",
      "[1273]\ttrain's auc: 0.833278\ttrain's binary_logloss: 0.352105\n",
      "[1274]\ttrain's auc: 0.833284\ttrain's binary_logloss: 0.3521\n",
      "[1275]\ttrain's auc: 0.833287\ttrain's binary_logloss: 0.352097\n",
      "[1276]\ttrain's auc: 0.833289\ttrain's binary_logloss: 0.352095\n",
      "[1277]\ttrain's auc: 0.833293\ttrain's binary_logloss: 0.352091\n",
      "[1278]\ttrain's auc: 0.833295\ttrain's binary_logloss: 0.352089\n",
      "[1279]\ttrain's auc: 0.833299\ttrain's binary_logloss: 0.352086\n",
      "[1280]\ttrain's auc: 0.833302\ttrain's binary_logloss: 0.352084\n",
      "[1281]\ttrain's auc: 0.833304\ttrain's binary_logloss: 0.352082\n",
      "[1282]\ttrain's auc: 0.833307\ttrain's binary_logloss: 0.35208\n",
      "[1283]\ttrain's auc: 0.83331\ttrain's binary_logloss: 0.352077\n",
      "[1284]\ttrain's auc: 0.833317\ttrain's binary_logloss: 0.352071\n",
      "[1285]\ttrain's auc: 0.833319\ttrain's binary_logloss: 0.352068\n",
      "[1286]\ttrain's auc: 0.833321\ttrain's binary_logloss: 0.352067\n",
      "[1287]\ttrain's auc: 0.833323\ttrain's binary_logloss: 0.352065\n",
      "[1288]\ttrain's auc: 0.833329\ttrain's binary_logloss: 0.35206\n",
      "[1289]\ttrain's auc: 0.833331\ttrain's binary_logloss: 0.352058\n",
      "[1290]\ttrain's auc: 0.833336\ttrain's binary_logloss: 0.352053\n",
      "[1291]\ttrain's auc: 0.833338\ttrain's binary_logloss: 0.352052\n",
      "[1292]\ttrain's auc: 0.833354\ttrain's binary_logloss: 0.35204\n",
      "[1293]\ttrain's auc: 0.833357\ttrain's binary_logloss: 0.352038\n",
      "[1294]\ttrain's auc: 0.833365\ttrain's binary_logloss: 0.352031\n",
      "[1295]\ttrain's auc: 0.833369\ttrain's binary_logloss: 0.352027\n",
      "[1296]\ttrain's auc: 0.833371\ttrain's binary_logloss: 0.352025\n",
      "[1297]\ttrain's auc: 0.833372\ttrain's binary_logloss: 0.352023\n",
      "[1298]\ttrain's auc: 0.833374\ttrain's binary_logloss: 0.352021\n",
      "[1299]\ttrain's auc: 0.833379\ttrain's binary_logloss: 0.352017\n",
      "[1300]\ttrain's auc: 0.833382\ttrain's binary_logloss: 0.352014\n",
      "[1301]\ttrain's auc: 0.833384\ttrain's binary_logloss: 0.352012\n",
      "[1302]\ttrain's auc: 0.833386\ttrain's binary_logloss: 0.352011\n",
      "[1303]\ttrain's auc: 0.833387\ttrain's binary_logloss: 0.35201\n",
      "[1304]\ttrain's auc: 0.83339\ttrain's binary_logloss: 0.352007\n",
      "[1305]\ttrain's auc: 0.833392\ttrain's binary_logloss: 0.352005\n",
      "[1306]\ttrain's auc: 0.833395\ttrain's binary_logloss: 0.352003\n",
      "[1307]\ttrain's auc: 0.833397\ttrain's binary_logloss: 0.352\n",
      "[1308]\ttrain's auc: 0.8334\ttrain's binary_logloss: 0.351997\n",
      "[1309]\ttrain's auc: 0.833402\ttrain's binary_logloss: 0.351995\n",
      "[1310]\ttrain's auc: 0.833404\ttrain's binary_logloss: 0.351993\n",
      "[1311]\ttrain's auc: 0.833416\ttrain's binary_logloss: 0.351983\n",
      "[1312]\ttrain's auc: 0.833419\ttrain's binary_logloss: 0.351981\n",
      "[1313]\ttrain's auc: 0.833422\ttrain's binary_logloss: 0.351979\n",
      "[1314]\ttrain's auc: 0.833425\ttrain's binary_logloss: 0.351977\n",
      "[1315]\ttrain's auc: 0.833427\ttrain's binary_logloss: 0.351975\n",
      "[1316]\ttrain's auc: 0.83343\ttrain's binary_logloss: 0.351973\n",
      "[1317]\ttrain's auc: 0.833431\ttrain's binary_logloss: 0.351971\n",
      "[1318]\ttrain's auc: 0.833435\ttrain's binary_logloss: 0.351967\n",
      "[1319]\ttrain's auc: 0.833438\ttrain's binary_logloss: 0.351965\n",
      "[1320]\ttrain's auc: 0.833441\ttrain's binary_logloss: 0.351962\n",
      "[1321]\ttrain's auc: 0.833442\ttrain's binary_logloss: 0.351961\n",
      "[1322]\ttrain's auc: 0.833444\ttrain's binary_logloss: 0.351958\n",
      "[1323]\ttrain's auc: 0.833446\ttrain's binary_logloss: 0.351956\n",
      "[1324]\ttrain's auc: 0.83345\ttrain's binary_logloss: 0.351953\n",
      "[1325]\ttrain's auc: 0.833454\ttrain's binary_logloss: 0.35195\n",
      "[1326]\ttrain's auc: 0.833456\ttrain's binary_logloss: 0.351949\n",
      "[1327]\ttrain's auc: 0.833458\ttrain's binary_logloss: 0.351947\n",
      "[1328]\ttrain's auc: 0.83346\ttrain's binary_logloss: 0.351945\n",
      "[1329]\ttrain's auc: 0.833463\ttrain's binary_logloss: 0.351943\n",
      "[1330]\ttrain's auc: 0.833465\ttrain's binary_logloss: 0.351941\n",
      "[1331]\ttrain's auc: 0.833467\ttrain's binary_logloss: 0.351939\n",
      "[1332]\ttrain's auc: 0.83347\ttrain's binary_logloss: 0.351937\n",
      "[1333]\ttrain's auc: 0.833472\ttrain's binary_logloss: 0.351934\n",
      "[1334]\ttrain's auc: 0.833475\ttrain's binary_logloss: 0.351932\n",
      "[1335]\ttrain's auc: 0.833477\ttrain's binary_logloss: 0.35193\n",
      "[1336]\ttrain's auc: 0.83348\ttrain's binary_logloss: 0.351928\n",
      "[1337]\ttrain's auc: 0.833482\ttrain's binary_logloss: 0.351925\n",
      "[1338]\ttrain's auc: 0.833484\ttrain's binary_logloss: 0.351924\n",
      "[1339]\ttrain's auc: 0.833486\ttrain's binary_logloss: 0.351922\n",
      "[1340]\ttrain's auc: 0.833492\ttrain's binary_logloss: 0.351917\n",
      "[1341]\ttrain's auc: 0.833494\ttrain's binary_logloss: 0.351915\n",
      "[1342]\ttrain's auc: 0.833497\ttrain's binary_logloss: 0.351912\n",
      "[1343]\ttrain's auc: 0.833499\ttrain's binary_logloss: 0.35191\n",
      "[1344]\ttrain's auc: 0.833502\ttrain's binary_logloss: 0.351908\n",
      "[1345]\ttrain's auc: 0.833512\ttrain's binary_logloss: 0.351899\n",
      "[1346]\ttrain's auc: 0.833514\ttrain's binary_logloss: 0.351898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1347]\ttrain's auc: 0.833517\ttrain's binary_logloss: 0.351895\n",
      "[1348]\ttrain's auc: 0.833518\ttrain's binary_logloss: 0.351893\n",
      "[1349]\ttrain's auc: 0.83352\ttrain's binary_logloss: 0.351892\n",
      "[1350]\ttrain's auc: 0.833522\ttrain's binary_logloss: 0.35189\n",
      "[1351]\ttrain's auc: 0.833524\ttrain's binary_logloss: 0.351888\n",
      "[1352]\ttrain's auc: 0.833526\ttrain's binary_logloss: 0.351886\n",
      "[1353]\ttrain's auc: 0.833528\ttrain's binary_logloss: 0.351884\n",
      "[1354]\ttrain's auc: 0.83353\ttrain's binary_logloss: 0.351882\n",
      "[1355]\ttrain's auc: 0.833532\ttrain's binary_logloss: 0.35188\n",
      "[1356]\ttrain's auc: 0.833538\ttrain's binary_logloss: 0.351875\n",
      "[1357]\ttrain's auc: 0.83354\ttrain's binary_logloss: 0.351874\n",
      "[1358]\ttrain's auc: 0.833545\ttrain's binary_logloss: 0.351869\n",
      "[1359]\ttrain's auc: 0.833549\ttrain's binary_logloss: 0.351866\n",
      "[1360]\ttrain's auc: 0.833551\ttrain's binary_logloss: 0.351864\n",
      "[1361]\ttrain's auc: 0.833554\ttrain's binary_logloss: 0.351861\n",
      "[1362]\ttrain's auc: 0.833555\ttrain's binary_logloss: 0.35186\n",
      "[1363]\ttrain's auc: 0.833557\ttrain's binary_logloss: 0.351859\n",
      "[1364]\ttrain's auc: 0.83356\ttrain's binary_logloss: 0.351856\n",
      "[1365]\ttrain's auc: 0.833562\ttrain's binary_logloss: 0.351854\n",
      "[1366]\ttrain's auc: 0.833565\ttrain's binary_logloss: 0.351851\n",
      "[1367]\ttrain's auc: 0.833571\ttrain's binary_logloss: 0.351846\n",
      "[1368]\ttrain's auc: 0.833573\ttrain's binary_logloss: 0.351844\n",
      "[1369]\ttrain's auc: 0.833576\ttrain's binary_logloss: 0.351842\n",
      "[1370]\ttrain's auc: 0.833579\ttrain's binary_logloss: 0.35184\n",
      "[1371]\ttrain's auc: 0.833581\ttrain's binary_logloss: 0.351838\n",
      "[1372]\ttrain's auc: 0.833584\ttrain's binary_logloss: 0.351835\n",
      "[1373]\ttrain's auc: 0.833587\ttrain's binary_logloss: 0.351833\n",
      "[1374]\ttrain's auc: 0.833592\ttrain's binary_logloss: 0.351828\n",
      "[1375]\ttrain's auc: 0.833595\ttrain's binary_logloss: 0.351826\n",
      "[1376]\ttrain's auc: 0.833597\ttrain's binary_logloss: 0.351825\n",
      "[1377]\ttrain's auc: 0.833599\ttrain's binary_logloss: 0.351823\n",
      "[1378]\ttrain's auc: 0.833602\ttrain's binary_logloss: 0.351821\n",
      "[1379]\ttrain's auc: 0.833604\ttrain's binary_logloss: 0.351819\n",
      "[1380]\ttrain's auc: 0.833608\ttrain's binary_logloss: 0.351815\n",
      "[1381]\ttrain's auc: 0.833613\ttrain's binary_logloss: 0.351811\n",
      "[1382]\ttrain's auc: 0.833615\ttrain's binary_logloss: 0.351809\n",
      "[1383]\ttrain's auc: 0.833617\ttrain's binary_logloss: 0.351807\n",
      "[1384]\ttrain's auc: 0.833624\ttrain's binary_logloss: 0.351801\n",
      "[1385]\ttrain's auc: 0.833626\ttrain's binary_logloss: 0.351798\n",
      "[1386]\ttrain's auc: 0.833628\ttrain's binary_logloss: 0.351797\n",
      "[1387]\ttrain's auc: 0.833629\ttrain's binary_logloss: 0.351795\n",
      "[1388]\ttrain's auc: 0.833632\ttrain's binary_logloss: 0.351793\n",
      "[1389]\ttrain's auc: 0.833635\ttrain's binary_logloss: 0.35179\n",
      "[1390]\ttrain's auc: 0.833637\ttrain's binary_logloss: 0.351789\n",
      "[1391]\ttrain's auc: 0.833639\ttrain's binary_logloss: 0.351787\n",
      "[1392]\ttrain's auc: 0.833641\ttrain's binary_logloss: 0.351785\n",
      "[1393]\ttrain's auc: 0.833643\ttrain's binary_logloss: 0.351783\n",
      "[1394]\ttrain's auc: 0.833651\ttrain's binary_logloss: 0.351776\n",
      "[1395]\ttrain's auc: 0.833654\ttrain's binary_logloss: 0.351773\n",
      "[1396]\ttrain's auc: 0.833655\ttrain's binary_logloss: 0.351772\n",
      "[1397]\ttrain's auc: 0.833658\ttrain's binary_logloss: 0.351769\n",
      "[1398]\ttrain's auc: 0.833661\ttrain's binary_logloss: 0.351767\n",
      "[1399]\ttrain's auc: 0.833664\ttrain's binary_logloss: 0.351764\n",
      "[1400]\ttrain's auc: 0.833665\ttrain's binary_logloss: 0.351763\n",
      "[1401]\ttrain's auc: 0.833668\ttrain's binary_logloss: 0.35176\n",
      "[1402]\ttrain's auc: 0.833682\ttrain's binary_logloss: 0.351748\n",
      "[1403]\ttrain's auc: 0.833684\ttrain's binary_logloss: 0.351747\n",
      "[1404]\ttrain's auc: 0.833687\ttrain's binary_logloss: 0.351745\n",
      "[1405]\ttrain's auc: 0.833688\ttrain's binary_logloss: 0.351742\n",
      "[1406]\ttrain's auc: 0.833691\ttrain's binary_logloss: 0.35174\n",
      "[1407]\ttrain's auc: 0.833692\ttrain's binary_logloss: 0.351739\n",
      "[1408]\ttrain's auc: 0.833694\ttrain's binary_logloss: 0.351737\n",
      "[1409]\ttrain's auc: 0.833696\ttrain's binary_logloss: 0.351735\n",
      "[1410]\ttrain's auc: 0.833698\ttrain's binary_logloss: 0.351733\n",
      "[1411]\ttrain's auc: 0.833701\ttrain's binary_logloss: 0.351731\n",
      "[1412]\ttrain's auc: 0.833704\ttrain's binary_logloss: 0.351728\n",
      "[1413]\ttrain's auc: 0.833706\ttrain's binary_logloss: 0.351726\n",
      "[1414]\ttrain's auc: 0.833708\ttrain's binary_logloss: 0.351724\n",
      "[1415]\ttrain's auc: 0.83371\ttrain's binary_logloss: 0.351722\n",
      "[1416]\ttrain's auc: 0.833713\ttrain's binary_logloss: 0.35172\n",
      "[1417]\ttrain's auc: 0.833715\ttrain's binary_logloss: 0.351718\n",
      "[1418]\ttrain's auc: 0.833718\ttrain's binary_logloss: 0.351716\n",
      "[1419]\ttrain's auc: 0.83372\ttrain's binary_logloss: 0.351713\n",
      "[1420]\ttrain's auc: 0.833721\ttrain's binary_logloss: 0.351712\n",
      "[1421]\ttrain's auc: 0.833729\ttrain's binary_logloss: 0.351705\n",
      "[1422]\ttrain's auc: 0.833732\ttrain's binary_logloss: 0.351703\n",
      "[1423]\ttrain's auc: 0.833734\ttrain's binary_logloss: 0.351701\n",
      "[1424]\ttrain's auc: 0.833736\ttrain's binary_logloss: 0.351699\n",
      "[1425]\ttrain's auc: 0.833738\ttrain's binary_logloss: 0.351697\n",
      "[1426]\ttrain's auc: 0.833742\ttrain's binary_logloss: 0.351693\n",
      "[1427]\ttrain's auc: 0.833747\ttrain's binary_logloss: 0.351689\n",
      "[1428]\ttrain's auc: 0.833749\ttrain's binary_logloss: 0.351686\n",
      "[1429]\ttrain's auc: 0.833752\ttrain's binary_logloss: 0.351684\n",
      "[1430]\ttrain's auc: 0.833753\ttrain's binary_logloss: 0.351683\n",
      "[1431]\ttrain's auc: 0.833759\ttrain's binary_logloss: 0.351678\n",
      "[1432]\ttrain's auc: 0.833765\ttrain's binary_logloss: 0.351674\n",
      "[1433]\ttrain's auc: 0.833768\ttrain's binary_logloss: 0.351671\n",
      "[1434]\ttrain's auc: 0.833769\ttrain's binary_logloss: 0.35167\n",
      "[1435]\ttrain's auc: 0.833772\ttrain's binary_logloss: 0.351668\n",
      "[1436]\ttrain's auc: 0.833774\ttrain's binary_logloss: 0.351666\n",
      "[1437]\ttrain's auc: 0.833778\ttrain's binary_logloss: 0.351662\n",
      "[1438]\ttrain's auc: 0.83378\ttrain's binary_logloss: 0.351661\n",
      "[1439]\ttrain's auc: 0.833796\ttrain's binary_logloss: 0.351649\n",
      "[1440]\ttrain's auc: 0.833799\ttrain's binary_logloss: 0.351647\n",
      "[1441]\ttrain's auc: 0.833801\ttrain's binary_logloss: 0.351645\n",
      "[1442]\ttrain's auc: 0.833803\ttrain's binary_logloss: 0.351643\n",
      "[1443]\ttrain's auc: 0.833804\ttrain's binary_logloss: 0.351641\n",
      "[1444]\ttrain's auc: 0.833806\ttrain's binary_logloss: 0.35164\n",
      "[1445]\ttrain's auc: 0.833811\ttrain's binary_logloss: 0.351635\n",
      "[1446]\ttrain's auc: 0.833813\ttrain's binary_logloss: 0.351633\n",
      "[1447]\ttrain's auc: 0.833815\ttrain's binary_logloss: 0.351632\n",
      "[1448]\ttrain's auc: 0.833817\ttrain's binary_logloss: 0.351629\n",
      "[1449]\ttrain's auc: 0.83382\ttrain's binary_logloss: 0.351627\n",
      "[1450]\ttrain's auc: 0.833823\ttrain's binary_logloss: 0.351625\n",
      "[1451]\ttrain's auc: 0.833824\ttrain's binary_logloss: 0.351624\n",
      "[1452]\ttrain's auc: 0.833826\ttrain's binary_logloss: 0.351622\n",
      "[1453]\ttrain's auc: 0.833828\ttrain's binary_logloss: 0.35162\n",
      "[1454]\ttrain's auc: 0.83383\ttrain's binary_logloss: 0.351619\n",
      "[1455]\ttrain's auc: 0.833832\ttrain's binary_logloss: 0.351617\n",
      "[1456]\ttrain's auc: 0.833834\ttrain's binary_logloss: 0.351615\n",
      "[1457]\ttrain's auc: 0.833835\ttrain's binary_logloss: 0.351613\n",
      "[1458]\ttrain's auc: 0.833837\ttrain's binary_logloss: 0.351611\n",
      "[1459]\ttrain's auc: 0.83384\ttrain's binary_logloss: 0.351609\n",
      "[1460]\ttrain's auc: 0.833842\ttrain's binary_logloss: 0.351607\n",
      "[1461]\ttrain's auc: 0.833844\ttrain's binary_logloss: 0.351606\n",
      "[1462]\ttrain's auc: 0.833846\ttrain's binary_logloss: 0.351604\n",
      "[1463]\ttrain's auc: 0.833851\ttrain's binary_logloss: 0.351599\n",
      "[1464]\ttrain's auc: 0.833854\ttrain's binary_logloss: 0.351597\n",
      "[1465]\ttrain's auc: 0.833855\ttrain's binary_logloss: 0.351595\n",
      "[1466]\ttrain's auc: 0.833857\ttrain's binary_logloss: 0.351593\n",
      "[1467]\ttrain's auc: 0.833859\ttrain's binary_logloss: 0.351592\n",
      "[1468]\ttrain's auc: 0.833861\ttrain's binary_logloss: 0.35159\n",
      "[1469]\ttrain's auc: 0.833862\ttrain's binary_logloss: 0.351589\n",
      "[1470]\ttrain's auc: 0.833866\ttrain's binary_logloss: 0.351585\n",
      "[1471]\ttrain's auc: 0.833869\ttrain's binary_logloss: 0.351583\n",
      "[1472]\ttrain's auc: 0.833873\ttrain's binary_logloss: 0.35158\n",
      "[1473]\ttrain's auc: 0.833876\ttrain's binary_logloss: 0.351577\n",
      "[1474]\ttrain's auc: 0.833878\ttrain's binary_logloss: 0.351575\n",
      "[1475]\ttrain's auc: 0.833881\ttrain's binary_logloss: 0.351573\n",
      "[1476]\ttrain's auc: 0.833883\ttrain's binary_logloss: 0.351571\n",
      "[1477]\ttrain's auc: 0.833884\ttrain's binary_logloss: 0.35157\n",
      "[1478]\ttrain's auc: 0.833887\ttrain's binary_logloss: 0.351568\n",
      "[1479]\ttrain's auc: 0.833888\ttrain's binary_logloss: 0.351567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1480]\ttrain's auc: 0.83389\ttrain's binary_logloss: 0.351565\n",
      "[1481]\ttrain's auc: 0.833891\ttrain's binary_logloss: 0.351564\n",
      "[1482]\ttrain's auc: 0.833903\ttrain's binary_logloss: 0.351555\n",
      "[1483]\ttrain's auc: 0.833904\ttrain's binary_logloss: 0.351553\n",
      "[1484]\ttrain's auc: 0.833911\ttrain's binary_logloss: 0.351548\n",
      "[1485]\ttrain's auc: 0.833913\ttrain's binary_logloss: 0.351546\n",
      "[1486]\ttrain's auc: 0.833915\ttrain's binary_logloss: 0.351544\n",
      "[1487]\ttrain's auc: 0.833917\ttrain's binary_logloss: 0.351543\n",
      "[1488]\ttrain's auc: 0.833919\ttrain's binary_logloss: 0.351541\n",
      "[1489]\ttrain's auc: 0.833921\ttrain's binary_logloss: 0.351539\n",
      "[1490]\ttrain's auc: 0.833922\ttrain's binary_logloss: 0.351537\n",
      "[1491]\ttrain's auc: 0.833925\ttrain's binary_logloss: 0.351535\n",
      "[1492]\ttrain's auc: 0.833927\ttrain's binary_logloss: 0.351533\n",
      "[1493]\ttrain's auc: 0.83393\ttrain's binary_logloss: 0.35153\n",
      "[1494]\ttrain's auc: 0.833932\ttrain's binary_logloss: 0.351528\n",
      "[1495]\ttrain's auc: 0.833935\ttrain's binary_logloss: 0.351526\n",
      "[1496]\ttrain's auc: 0.833936\ttrain's binary_logloss: 0.351525\n",
      "[1497]\ttrain's auc: 0.833938\ttrain's binary_logloss: 0.351523\n",
      "[1498]\ttrain's auc: 0.833943\ttrain's binary_logloss: 0.351519\n",
      "[1499]\ttrain's auc: 0.833945\ttrain's binary_logloss: 0.351517\n",
      "[1500]\ttrain's auc: 0.833947\ttrain's binary_logloss: 0.351515\n",
      "[1501]\ttrain's auc: 0.833949\ttrain's binary_logloss: 0.351514\n",
      "[1502]\ttrain's auc: 0.833951\ttrain's binary_logloss: 0.351512\n",
      "[1503]\ttrain's auc: 0.833952\ttrain's binary_logloss: 0.35151\n",
      "[1504]\ttrain's auc: 0.833954\ttrain's binary_logloss: 0.351508\n",
      "[1505]\ttrain's auc: 0.833955\ttrain's binary_logloss: 0.351507\n",
      "[1506]\ttrain's auc: 0.833956\ttrain's binary_logloss: 0.351506\n",
      "[1507]\ttrain's auc: 0.833959\ttrain's binary_logloss: 0.351503\n",
      "[1508]\ttrain's auc: 0.83396\ttrain's binary_logloss: 0.351502\n",
      "[1509]\ttrain's auc: 0.833962\ttrain's binary_logloss: 0.3515\n",
      "[1510]\ttrain's auc: 0.833964\ttrain's binary_logloss: 0.351498\n",
      "[1511]\ttrain's auc: 0.833967\ttrain's binary_logloss: 0.351495\n",
      "[1512]\ttrain's auc: 0.833969\ttrain's binary_logloss: 0.351494\n",
      "[1513]\ttrain's auc: 0.833971\ttrain's binary_logloss: 0.351492\n",
      "[1514]\ttrain's auc: 0.833973\ttrain's binary_logloss: 0.351491\n",
      "[1515]\ttrain's auc: 0.833974\ttrain's binary_logloss: 0.35149\n",
      "[1516]\ttrain's auc: 0.833976\ttrain's binary_logloss: 0.351487\n",
      "[1517]\ttrain's auc: 0.833979\ttrain's binary_logloss: 0.351485\n",
      "[1518]\ttrain's auc: 0.833983\ttrain's binary_logloss: 0.351481\n",
      "[1519]\ttrain's auc: 0.833984\ttrain's binary_logloss: 0.35148\n",
      "[1520]\ttrain's auc: 0.833987\ttrain's binary_logloss: 0.351478\n",
      "[1521]\ttrain's auc: 0.833989\ttrain's binary_logloss: 0.351476\n",
      "[1522]\ttrain's auc: 0.833991\ttrain's binary_logloss: 0.351474\n",
      "[1523]\ttrain's auc: 0.833996\ttrain's binary_logloss: 0.35147\n",
      "[1524]\ttrain's auc: 0.833998\ttrain's binary_logloss: 0.351468\n",
      "[1525]\ttrain's auc: 0.834\ttrain's binary_logloss: 0.351467\n",
      "[1526]\ttrain's auc: 0.834003\ttrain's binary_logloss: 0.351464\n",
      "[1527]\ttrain's auc: 0.834005\ttrain's binary_logloss: 0.351463\n",
      "[1528]\ttrain's auc: 0.834007\ttrain's binary_logloss: 0.351461\n",
      "[1529]\ttrain's auc: 0.83401\ttrain's binary_logloss: 0.351459\n",
      "[1530]\ttrain's auc: 0.834012\ttrain's binary_logloss: 0.351458\n",
      "[1531]\ttrain's auc: 0.834016\ttrain's binary_logloss: 0.351454\n",
      "[1532]\ttrain's auc: 0.834018\ttrain's binary_logloss: 0.351452\n",
      "[1533]\ttrain's auc: 0.834022\ttrain's binary_logloss: 0.351449\n",
      "[1534]\ttrain's auc: 0.834024\ttrain's binary_logloss: 0.351447\n",
      "[1535]\ttrain's auc: 0.834026\ttrain's binary_logloss: 0.351446\n",
      "[1536]\ttrain's auc: 0.834027\ttrain's binary_logloss: 0.351444\n",
      "[1537]\ttrain's auc: 0.834031\ttrain's binary_logloss: 0.35144\n",
      "[1538]\ttrain's auc: 0.834033\ttrain's binary_logloss: 0.351438\n",
      "[1539]\ttrain's auc: 0.834035\ttrain's binary_logloss: 0.351437\n",
      "[1540]\ttrain's auc: 0.834037\ttrain's binary_logloss: 0.351435\n",
      "[1541]\ttrain's auc: 0.834049\ttrain's binary_logloss: 0.351425\n",
      "[1542]\ttrain's auc: 0.834051\ttrain's binary_logloss: 0.351423\n",
      "[1543]\ttrain's auc: 0.834054\ttrain's binary_logloss: 0.351421\n",
      "[1544]\ttrain's auc: 0.834056\ttrain's binary_logloss: 0.351419\n",
      "[1545]\ttrain's auc: 0.834057\ttrain's binary_logloss: 0.351418\n",
      "[1546]\ttrain's auc: 0.834059\ttrain's binary_logloss: 0.351416\n",
      "[1547]\ttrain's auc: 0.83406\ttrain's binary_logloss: 0.351415\n",
      "[1548]\ttrain's auc: 0.834062\ttrain's binary_logloss: 0.351413\n",
      "[1549]\ttrain's auc: 0.834068\ttrain's binary_logloss: 0.351408\n",
      "[1550]\ttrain's auc: 0.83407\ttrain's binary_logloss: 0.351407\n",
      "[1551]\ttrain's auc: 0.834072\ttrain's binary_logloss: 0.351405\n",
      "[1552]\ttrain's auc: 0.834073\ttrain's binary_logloss: 0.351404\n",
      "[1553]\ttrain's auc: 0.834077\ttrain's binary_logloss: 0.351401\n",
      "[1554]\ttrain's auc: 0.834085\ttrain's binary_logloss: 0.351393\n",
      "[1555]\ttrain's auc: 0.83409\ttrain's binary_logloss: 0.351389\n",
      "[1556]\ttrain's auc: 0.834093\ttrain's binary_logloss: 0.351387\n",
      "[1557]\ttrain's auc: 0.834095\ttrain's binary_logloss: 0.351385\n",
      "[1558]\ttrain's auc: 0.834097\ttrain's binary_logloss: 0.351383\n",
      "[1559]\ttrain's auc: 0.834099\ttrain's binary_logloss: 0.351381\n",
      "[1560]\ttrain's auc: 0.834101\ttrain's binary_logloss: 0.351379\n",
      "[1561]\ttrain's auc: 0.834107\ttrain's binary_logloss: 0.351375\n",
      "[1562]\ttrain's auc: 0.834109\ttrain's binary_logloss: 0.351373\n",
      "[1563]\ttrain's auc: 0.834111\ttrain's binary_logloss: 0.351372\n",
      "[1564]\ttrain's auc: 0.834112\ttrain's binary_logloss: 0.35137\n",
      "[1565]\ttrain's auc: 0.834115\ttrain's binary_logloss: 0.351368\n",
      "[1566]\ttrain's auc: 0.834116\ttrain's binary_logloss: 0.351367\n",
      "[1567]\ttrain's auc: 0.834119\ttrain's binary_logloss: 0.351365\n",
      "[1568]\ttrain's auc: 0.834121\ttrain's binary_logloss: 0.351364\n",
      "[1569]\ttrain's auc: 0.834122\ttrain's binary_logloss: 0.351363\n",
      "[1570]\ttrain's auc: 0.834124\ttrain's binary_logloss: 0.351361\n",
      "[1571]\ttrain's auc: 0.834126\ttrain's binary_logloss: 0.35136\n",
      "[1572]\ttrain's auc: 0.834128\ttrain's binary_logloss: 0.351358\n",
      "[1573]\ttrain's auc: 0.83413\ttrain's binary_logloss: 0.351355\n",
      "[1574]\ttrain's auc: 0.834132\ttrain's binary_logloss: 0.351354\n",
      "[1575]\ttrain's auc: 0.834133\ttrain's binary_logloss: 0.351353\n",
      "[1576]\ttrain's auc: 0.834135\ttrain's binary_logloss: 0.351351\n",
      "[1577]\ttrain's auc: 0.834136\ttrain's binary_logloss: 0.351349\n",
      "[1578]\ttrain's auc: 0.834138\ttrain's binary_logloss: 0.351347\n",
      "[1579]\ttrain's auc: 0.83414\ttrain's binary_logloss: 0.351345\n",
      "[1580]\ttrain's auc: 0.834157\ttrain's binary_logloss: 0.351332\n",
      "[1581]\ttrain's auc: 0.834158\ttrain's binary_logloss: 0.351331\n",
      "[1582]\ttrain's auc: 0.83416\ttrain's binary_logloss: 0.351329\n",
      "[1583]\ttrain's auc: 0.834162\ttrain's binary_logloss: 0.351327\n",
      "[1584]\ttrain's auc: 0.834164\ttrain's binary_logloss: 0.351326\n",
      "[1585]\ttrain's auc: 0.834168\ttrain's binary_logloss: 0.351323\n",
      "[1586]\ttrain's auc: 0.83417\ttrain's binary_logloss: 0.35132\n",
      "[1587]\ttrain's auc: 0.834172\ttrain's binary_logloss: 0.351319\n",
      "[1588]\ttrain's auc: 0.834174\ttrain's binary_logloss: 0.351317\n",
      "[1589]\ttrain's auc: 0.834175\ttrain's binary_logloss: 0.351316\n",
      "[1590]\ttrain's auc: 0.834178\ttrain's binary_logloss: 0.351314\n",
      "[1591]\ttrain's auc: 0.83418\ttrain's binary_logloss: 0.351312\n",
      "[1592]\ttrain's auc: 0.834182\ttrain's binary_logloss: 0.351311\n",
      "[1593]\ttrain's auc: 0.834183\ttrain's binary_logloss: 0.351309\n",
      "[1594]\ttrain's auc: 0.834185\ttrain's binary_logloss: 0.351307\n",
      "[1595]\ttrain's auc: 0.834187\ttrain's binary_logloss: 0.351305\n",
      "[1596]\ttrain's auc: 0.834189\ttrain's binary_logloss: 0.351303\n",
      "[1597]\ttrain's auc: 0.834191\ttrain's binary_logloss: 0.351301\n",
      "[1598]\ttrain's auc: 0.834196\ttrain's binary_logloss: 0.351297\n",
      "[1599]\ttrain's auc: 0.834197\ttrain's binary_logloss: 0.351296\n",
      "[1600]\ttrain's auc: 0.834199\ttrain's binary_logloss: 0.351294\n",
      "[1601]\ttrain's auc: 0.834201\ttrain's binary_logloss: 0.351293\n",
      "[1602]\ttrain's auc: 0.834204\ttrain's binary_logloss: 0.35129\n",
      "[1603]\ttrain's auc: 0.834207\ttrain's binary_logloss: 0.351288\n",
      "[1604]\ttrain's auc: 0.834208\ttrain's binary_logloss: 0.351286\n",
      "[1605]\ttrain's auc: 0.83421\ttrain's binary_logloss: 0.351284\n",
      "[1606]\ttrain's auc: 0.834212\ttrain's binary_logloss: 0.351283\n",
      "[1607]\ttrain's auc: 0.834214\ttrain's binary_logloss: 0.351282\n",
      "[1608]\ttrain's auc: 0.834215\ttrain's binary_logloss: 0.35128\n",
      "[1609]\ttrain's auc: 0.834217\ttrain's binary_logloss: 0.351278\n",
      "[1610]\ttrain's auc: 0.834218\ttrain's binary_logloss: 0.351277\n",
      "[1611]\ttrain's auc: 0.834219\ttrain's binary_logloss: 0.351276\n",
      "[1612]\ttrain's auc: 0.834221\ttrain's binary_logloss: 0.351275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1613]\ttrain's auc: 0.834222\ttrain's binary_logloss: 0.351273\n",
      "[1614]\ttrain's auc: 0.834224\ttrain's binary_logloss: 0.351272\n",
      "[1615]\ttrain's auc: 0.834226\ttrain's binary_logloss: 0.351271\n",
      "[1616]\ttrain's auc: 0.834228\ttrain's binary_logloss: 0.351269\n",
      "[1617]\ttrain's auc: 0.83423\ttrain's binary_logloss: 0.351268\n",
      "[1618]\ttrain's auc: 0.834231\ttrain's binary_logloss: 0.351266\n",
      "[1619]\ttrain's auc: 0.834234\ttrain's binary_logloss: 0.351264\n",
      "[1620]\ttrain's auc: 0.834236\ttrain's binary_logloss: 0.351262\n",
      "[1621]\ttrain's auc: 0.834239\ttrain's binary_logloss: 0.35126\n",
      "[1622]\ttrain's auc: 0.83424\ttrain's binary_logloss: 0.351258\n",
      "[1623]\ttrain's auc: 0.834242\ttrain's binary_logloss: 0.351257\n",
      "[1624]\ttrain's auc: 0.834244\ttrain's binary_logloss: 0.351255\n",
      "[1625]\ttrain's auc: 0.834246\ttrain's binary_logloss: 0.351254\n",
      "[1626]\ttrain's auc: 0.834247\ttrain's binary_logloss: 0.351253\n",
      "[1627]\ttrain's auc: 0.834262\ttrain's binary_logloss: 0.351241\n",
      "[1628]\ttrain's auc: 0.834266\ttrain's binary_logloss: 0.351238\n",
      "[1629]\ttrain's auc: 0.834268\ttrain's binary_logloss: 0.351236\n",
      "[1630]\ttrain's auc: 0.83427\ttrain's binary_logloss: 0.351234\n",
      "[1631]\ttrain's auc: 0.834272\ttrain's binary_logloss: 0.351233\n",
      "[1632]\ttrain's auc: 0.834274\ttrain's binary_logloss: 0.351231\n",
      "[1633]\ttrain's auc: 0.834275\ttrain's binary_logloss: 0.35123\n",
      "[1634]\ttrain's auc: 0.834277\ttrain's binary_logloss: 0.351229\n",
      "[1635]\ttrain's auc: 0.834279\ttrain's binary_logloss: 0.351227\n",
      "[1636]\ttrain's auc: 0.834281\ttrain's binary_logloss: 0.351224\n",
      "[1637]\ttrain's auc: 0.834285\ttrain's binary_logloss: 0.351221\n",
      "[1638]\ttrain's auc: 0.834287\ttrain's binary_logloss: 0.351219\n",
      "[1639]\ttrain's auc: 0.834289\ttrain's binary_logloss: 0.351218\n",
      "[1640]\ttrain's auc: 0.834295\ttrain's binary_logloss: 0.351213\n",
      "[1641]\ttrain's auc: 0.834298\ttrain's binary_logloss: 0.351211\n",
      "[1642]\ttrain's auc: 0.834299\ttrain's binary_logloss: 0.35121\n",
      "[1643]\ttrain's auc: 0.834301\ttrain's binary_logloss: 0.351208\n",
      "[1644]\ttrain's auc: 0.834303\ttrain's binary_logloss: 0.351206\n",
      "[1645]\ttrain's auc: 0.834305\ttrain's binary_logloss: 0.351204\n",
      "[1646]\ttrain's auc: 0.834308\ttrain's binary_logloss: 0.351202\n",
      "[1647]\ttrain's auc: 0.834309\ttrain's binary_logloss: 0.351201\n",
      "[1648]\ttrain's auc: 0.834311\ttrain's binary_logloss: 0.3512\n",
      "[1649]\ttrain's auc: 0.834313\ttrain's binary_logloss: 0.351198\n",
      "[1650]\ttrain's auc: 0.83432\ttrain's binary_logloss: 0.351192\n",
      "[1651]\ttrain's auc: 0.834322\ttrain's binary_logloss: 0.35119\n",
      "[1652]\ttrain's auc: 0.834324\ttrain's binary_logloss: 0.351188\n",
      "[1653]\ttrain's auc: 0.834325\ttrain's binary_logloss: 0.351187\n",
      "[1654]\ttrain's auc: 0.834326\ttrain's binary_logloss: 0.351186\n",
      "[1655]\ttrain's auc: 0.834328\ttrain's binary_logloss: 0.351185\n",
      "[1656]\ttrain's auc: 0.83433\ttrain's binary_logloss: 0.351182\n",
      "[1657]\ttrain's auc: 0.834333\ttrain's binary_logloss: 0.35118\n",
      "[1658]\ttrain's auc: 0.834337\ttrain's binary_logloss: 0.351177\n",
      "[1659]\ttrain's auc: 0.83434\ttrain's binary_logloss: 0.351174\n",
      "[1660]\ttrain's auc: 0.834347\ttrain's binary_logloss: 0.351168\n",
      "[1661]\ttrain's auc: 0.834349\ttrain's binary_logloss: 0.351166\n",
      "[1662]\ttrain's auc: 0.834351\ttrain's binary_logloss: 0.351164\n",
      "[1663]\ttrain's auc: 0.834353\ttrain's binary_logloss: 0.351162\n",
      "[1664]\ttrain's auc: 0.834355\ttrain's binary_logloss: 0.351161\n",
      "[1665]\ttrain's auc: 0.834357\ttrain's binary_logloss: 0.351159\n",
      "[1666]\ttrain's auc: 0.834358\ttrain's binary_logloss: 0.351158\n",
      "[1667]\ttrain's auc: 0.83436\ttrain's binary_logloss: 0.351157\n",
      "[1668]\ttrain's auc: 0.834362\ttrain's binary_logloss: 0.351155\n",
      "[1669]\ttrain's auc: 0.834363\ttrain's binary_logloss: 0.351154\n",
      "[1670]\ttrain's auc: 0.834365\ttrain's binary_logloss: 0.351152\n",
      "[1671]\ttrain's auc: 0.834367\ttrain's binary_logloss: 0.35115\n",
      "[1672]\ttrain's auc: 0.834368\ttrain's binary_logloss: 0.351149\n",
      "[1673]\ttrain's auc: 0.83437\ttrain's binary_logloss: 0.351147\n",
      "[1674]\ttrain's auc: 0.834372\ttrain's binary_logloss: 0.351146\n",
      "[1675]\ttrain's auc: 0.834374\ttrain's binary_logloss: 0.351144\n",
      "[1676]\ttrain's auc: 0.834377\ttrain's binary_logloss: 0.351142\n",
      "[1677]\ttrain's auc: 0.834383\ttrain's binary_logloss: 0.351136\n",
      "[1678]\ttrain's auc: 0.834384\ttrain's binary_logloss: 0.351135\n",
      "[1679]\ttrain's auc: 0.834388\ttrain's binary_logloss: 0.351133\n",
      "[1680]\ttrain's auc: 0.834389\ttrain's binary_logloss: 0.351131\n",
      "[1681]\ttrain's auc: 0.834399\ttrain's binary_logloss: 0.351123\n",
      "[1682]\ttrain's auc: 0.8344\ttrain's binary_logloss: 0.351122\n",
      "[1683]\ttrain's auc: 0.834404\ttrain's binary_logloss: 0.351119\n",
      "[1684]\ttrain's auc: 0.834408\ttrain's binary_logloss: 0.351116\n",
      "[1685]\ttrain's auc: 0.834421\ttrain's binary_logloss: 0.351106\n",
      "[1686]\ttrain's auc: 0.834423\ttrain's binary_logloss: 0.351105\n",
      "[1687]\ttrain's auc: 0.834424\ttrain's binary_logloss: 0.351103\n",
      "[1688]\ttrain's auc: 0.834429\ttrain's binary_logloss: 0.351099\n",
      "[1689]\ttrain's auc: 0.83443\ttrain's binary_logloss: 0.351098\n",
      "[1690]\ttrain's auc: 0.834433\ttrain's binary_logloss: 0.351096\n",
      "[1691]\ttrain's auc: 0.834434\ttrain's binary_logloss: 0.351094\n",
      "[1692]\ttrain's auc: 0.834436\ttrain's binary_logloss: 0.351093\n",
      "[1693]\ttrain's auc: 0.834438\ttrain's binary_logloss: 0.351091\n",
      "[1694]\ttrain's auc: 0.83444\ttrain's binary_logloss: 0.35109\n",
      "[1695]\ttrain's auc: 0.834442\ttrain's binary_logloss: 0.351087\n",
      "[1696]\ttrain's auc: 0.834444\ttrain's binary_logloss: 0.351086\n",
      "[1697]\ttrain's auc: 0.834446\ttrain's binary_logloss: 0.351084\n",
      "[1698]\ttrain's auc: 0.834448\ttrain's binary_logloss: 0.351083\n",
      "[1699]\ttrain's auc: 0.83445\ttrain's binary_logloss: 0.351081\n",
      "[1700]\ttrain's auc: 0.834454\ttrain's binary_logloss: 0.351077\n",
      "[1701]\ttrain's auc: 0.834456\ttrain's binary_logloss: 0.351075\n",
      "[1702]\ttrain's auc: 0.834458\ttrain's binary_logloss: 0.351074\n",
      "[1703]\ttrain's auc: 0.83446\ttrain's binary_logloss: 0.351072\n",
      "[1704]\ttrain's auc: 0.834461\ttrain's binary_logloss: 0.351071\n",
      "[1705]\ttrain's auc: 0.834463\ttrain's binary_logloss: 0.351069\n",
      "[1706]\ttrain's auc: 0.834465\ttrain's binary_logloss: 0.351068\n",
      "[1707]\ttrain's auc: 0.834466\ttrain's binary_logloss: 0.351066\n",
      "[1708]\ttrain's auc: 0.834468\ttrain's binary_logloss: 0.351065\n",
      "[1709]\ttrain's auc: 0.834471\ttrain's binary_logloss: 0.351062\n",
      "[1710]\ttrain's auc: 0.834472\ttrain's binary_logloss: 0.35106\n",
      "[1711]\ttrain's auc: 0.834475\ttrain's binary_logloss: 0.351059\n",
      "[1712]\ttrain's auc: 0.834476\ttrain's binary_logloss: 0.351057\n",
      "[1713]\ttrain's auc: 0.834478\ttrain's binary_logloss: 0.351056\n",
      "[1714]\ttrain's auc: 0.834479\ttrain's binary_logloss: 0.351055\n",
      "[1715]\ttrain's auc: 0.834483\ttrain's binary_logloss: 0.351051\n",
      "[1716]\ttrain's auc: 0.834486\ttrain's binary_logloss: 0.351049\n",
      "[1717]\ttrain's auc: 0.834488\ttrain's binary_logloss: 0.351048\n",
      "[1718]\ttrain's auc: 0.83449\ttrain's binary_logloss: 0.351047\n",
      "[1719]\ttrain's auc: 0.834492\ttrain's binary_logloss: 0.351045\n",
      "[1720]\ttrain's auc: 0.834494\ttrain's binary_logloss: 0.351043\n",
      "[1721]\ttrain's auc: 0.834496\ttrain's binary_logloss: 0.351042\n",
      "[1722]\ttrain's auc: 0.834497\ttrain's binary_logloss: 0.35104\n",
      "[1723]\ttrain's auc: 0.834499\ttrain's binary_logloss: 0.351039\n",
      "[1724]\ttrain's auc: 0.834501\ttrain's binary_logloss: 0.351037\n",
      "[1725]\ttrain's auc: 0.834503\ttrain's binary_logloss: 0.351036\n",
      "[1726]\ttrain's auc: 0.834505\ttrain's binary_logloss: 0.351033\n",
      "[1727]\ttrain's auc: 0.834506\ttrain's binary_logloss: 0.351032\n",
      "[1728]\ttrain's auc: 0.834508\ttrain's binary_logloss: 0.35103\n",
      "[1729]\ttrain's auc: 0.83451\ttrain's binary_logloss: 0.351029\n",
      "[1730]\ttrain's auc: 0.834511\ttrain's binary_logloss: 0.351027\n",
      "[1731]\ttrain's auc: 0.834513\ttrain's binary_logloss: 0.351025\n",
      "[1732]\ttrain's auc: 0.834515\ttrain's binary_logloss: 0.351023\n",
      "[1733]\ttrain's auc: 0.834517\ttrain's binary_logloss: 0.351021\n",
      "[1734]\ttrain's auc: 0.834518\ttrain's binary_logloss: 0.35102\n",
      "[1735]\ttrain's auc: 0.83452\ttrain's binary_logloss: 0.351019\n",
      "[1736]\ttrain's auc: 0.834522\ttrain's binary_logloss: 0.351017\n",
      "[1737]\ttrain's auc: 0.834524\ttrain's binary_logloss: 0.351015\n",
      "[1738]\ttrain's auc: 0.834526\ttrain's binary_logloss: 0.351013\n",
      "[1739]\ttrain's auc: 0.834527\ttrain's binary_logloss: 0.351012\n",
      "[1740]\ttrain's auc: 0.834531\ttrain's binary_logloss: 0.351008\n",
      "[1741]\ttrain's auc: 0.834534\ttrain's binary_logloss: 0.351006\n",
      "[1742]\ttrain's auc: 0.834535\ttrain's binary_logloss: 0.351005\n",
      "[1743]\ttrain's auc: 0.834538\ttrain's binary_logloss: 0.351003\n",
      "[1744]\ttrain's auc: 0.834539\ttrain's binary_logloss: 0.351001\n",
      "[1745]\ttrain's auc: 0.83454\ttrain's binary_logloss: 0.351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1746]\ttrain's auc: 0.834541\ttrain's binary_logloss: 0.350998\n",
      "[1747]\ttrain's auc: 0.834542\ttrain's binary_logloss: 0.350997\n",
      "[1748]\ttrain's auc: 0.834546\ttrain's binary_logloss: 0.350994\n",
      "[1749]\ttrain's auc: 0.834548\ttrain's binary_logloss: 0.350992\n",
      "[1750]\ttrain's auc: 0.834549\ttrain's binary_logloss: 0.350991\n",
      "[1751]\ttrain's auc: 0.83455\ttrain's binary_logloss: 0.350989\n",
      "[1752]\ttrain's auc: 0.834553\ttrain's binary_logloss: 0.350987\n",
      "[1753]\ttrain's auc: 0.834554\ttrain's binary_logloss: 0.350986\n",
      "[1754]\ttrain's auc: 0.834556\ttrain's binary_logloss: 0.350985\n",
      "[1755]\ttrain's auc: 0.834563\ttrain's binary_logloss: 0.350979\n",
      "[1756]\ttrain's auc: 0.834565\ttrain's binary_logloss: 0.350977\n",
      "[1757]\ttrain's auc: 0.834567\ttrain's binary_logloss: 0.350975\n",
      "[1758]\ttrain's auc: 0.834569\ttrain's binary_logloss: 0.350973\n",
      "[1759]\ttrain's auc: 0.834571\ttrain's binary_logloss: 0.350971\n",
      "[1760]\ttrain's auc: 0.834573\ttrain's binary_logloss: 0.35097\n",
      "[1761]\ttrain's auc: 0.834574\ttrain's binary_logloss: 0.350969\n",
      "[1762]\ttrain's auc: 0.834575\ttrain's binary_logloss: 0.350968\n",
      "[1763]\ttrain's auc: 0.834582\ttrain's binary_logloss: 0.350962\n",
      "[1764]\ttrain's auc: 0.834583\ttrain's binary_logloss: 0.350961\n",
      "[1765]\ttrain's auc: 0.834584\ttrain's binary_logloss: 0.350959\n",
      "[1766]\ttrain's auc: 0.834586\ttrain's binary_logloss: 0.350957\n",
      "[1767]\ttrain's auc: 0.834587\ttrain's binary_logloss: 0.350956\n",
      "[1768]\ttrain's auc: 0.834589\ttrain's binary_logloss: 0.350955\n",
      "[1769]\ttrain's auc: 0.83459\ttrain's binary_logloss: 0.350954\n",
      "[1770]\ttrain's auc: 0.834593\ttrain's binary_logloss: 0.35095\n",
      "[1771]\ttrain's auc: 0.834595\ttrain's binary_logloss: 0.350949\n",
      "[1772]\ttrain's auc: 0.834596\ttrain's binary_logloss: 0.350948\n",
      "[1773]\ttrain's auc: 0.834598\ttrain's binary_logloss: 0.350946\n",
      "[1774]\ttrain's auc: 0.8346\ttrain's binary_logloss: 0.350944\n",
      "[1775]\ttrain's auc: 0.834602\ttrain's binary_logloss: 0.350942\n",
      "[1776]\ttrain's auc: 0.834603\ttrain's binary_logloss: 0.350941\n",
      "[1777]\ttrain's auc: 0.834605\ttrain's binary_logloss: 0.35094\n",
      "[1778]\ttrain's auc: 0.834607\ttrain's binary_logloss: 0.350938\n",
      "[1779]\ttrain's auc: 0.834608\ttrain's binary_logloss: 0.350937\n",
      "[1780]\ttrain's auc: 0.83461\ttrain's binary_logloss: 0.350936\n",
      "[1781]\ttrain's auc: 0.834611\ttrain's binary_logloss: 0.350934\n",
      "[1782]\ttrain's auc: 0.834614\ttrain's binary_logloss: 0.350932\n",
      "[1783]\ttrain's auc: 0.834615\ttrain's binary_logloss: 0.350931\n",
      "[1784]\ttrain's auc: 0.834617\ttrain's binary_logloss: 0.35093\n",
      "[1785]\ttrain's auc: 0.834619\ttrain's binary_logloss: 0.350928\n",
      "[1786]\ttrain's auc: 0.834621\ttrain's binary_logloss: 0.350926\n",
      "[1787]\ttrain's auc: 0.834622\ttrain's binary_logloss: 0.350925\n",
      "[1788]\ttrain's auc: 0.834629\ttrain's binary_logloss: 0.35092\n",
      "[1789]\ttrain's auc: 0.834631\ttrain's binary_logloss: 0.350918\n",
      "[1790]\ttrain's auc: 0.834633\ttrain's binary_logloss: 0.350916\n",
      "[1791]\ttrain's auc: 0.834634\ttrain's binary_logloss: 0.350914\n",
      "[1792]\ttrain's auc: 0.834636\ttrain's binary_logloss: 0.350913\n",
      "[1793]\ttrain's auc: 0.834637\ttrain's binary_logloss: 0.350912\n",
      "[1794]\ttrain's auc: 0.834639\ttrain's binary_logloss: 0.350911\n",
      "[1795]\ttrain's auc: 0.834647\ttrain's binary_logloss: 0.350905\n",
      "[1796]\ttrain's auc: 0.834648\ttrain's binary_logloss: 0.350904\n",
      "[1797]\ttrain's auc: 0.83465\ttrain's binary_logloss: 0.350902\n",
      "[1798]\ttrain's auc: 0.834657\ttrain's binary_logloss: 0.350896\n",
      "[1799]\ttrain's auc: 0.834661\ttrain's binary_logloss: 0.350894\n",
      "[1800]\ttrain's auc: 0.834662\ttrain's binary_logloss: 0.350893\n",
      "[1801]\ttrain's auc: 0.834663\ttrain's binary_logloss: 0.350891\n",
      "[1802]\ttrain's auc: 0.834665\ttrain's binary_logloss: 0.35089\n",
      "[1803]\ttrain's auc: 0.834666\ttrain's binary_logloss: 0.350889\n",
      "[1804]\ttrain's auc: 0.834672\ttrain's binary_logloss: 0.350884\n",
      "[1805]\ttrain's auc: 0.834674\ttrain's binary_logloss: 0.350882\n",
      "[1806]\ttrain's auc: 0.834675\ttrain's binary_logloss: 0.350881\n",
      "[1807]\ttrain's auc: 0.834677\ttrain's binary_logloss: 0.350879\n",
      "[1808]\ttrain's auc: 0.834678\ttrain's binary_logloss: 0.350878\n",
      "[1809]\ttrain's auc: 0.83468\ttrain's binary_logloss: 0.350877\n",
      "[1810]\ttrain's auc: 0.834681\ttrain's binary_logloss: 0.350876\n",
      "[1811]\ttrain's auc: 0.834686\ttrain's binary_logloss: 0.350872\n",
      "[1812]\ttrain's auc: 0.834687\ttrain's binary_logloss: 0.350871\n",
      "[1813]\ttrain's auc: 0.834687\ttrain's binary_logloss: 0.35087\n",
      "[1814]\ttrain's auc: 0.834689\ttrain's binary_logloss: 0.350869\n",
      "[1815]\ttrain's auc: 0.83469\ttrain's binary_logloss: 0.350867\n",
      "[1816]\ttrain's auc: 0.834692\ttrain's binary_logloss: 0.350866\n",
      "[1817]\ttrain's auc: 0.834699\ttrain's binary_logloss: 0.350861\n",
      "[1818]\ttrain's auc: 0.8347\ttrain's binary_logloss: 0.350859\n",
      "[1819]\ttrain's auc: 0.834703\ttrain's binary_logloss: 0.350858\n",
      "[1820]\ttrain's auc: 0.834704\ttrain's binary_logloss: 0.350856\n",
      "[1821]\ttrain's auc: 0.834706\ttrain's binary_logloss: 0.350855\n",
      "[1822]\ttrain's auc: 0.834707\ttrain's binary_logloss: 0.350854\n",
      "[1823]\ttrain's auc: 0.834708\ttrain's binary_logloss: 0.350853\n",
      "[1824]\ttrain's auc: 0.834709\ttrain's binary_logloss: 0.350852\n",
      "[1825]\ttrain's auc: 0.834711\ttrain's binary_logloss: 0.35085\n",
      "[1826]\ttrain's auc: 0.834712\ttrain's binary_logloss: 0.350849\n",
      "[1827]\ttrain's auc: 0.834713\ttrain's binary_logloss: 0.350848\n",
      "[1828]\ttrain's auc: 0.834718\ttrain's binary_logloss: 0.350844\n",
      "[1829]\ttrain's auc: 0.83472\ttrain's binary_logloss: 0.350842\n",
      "[1830]\ttrain's auc: 0.834726\ttrain's binary_logloss: 0.350837\n",
      "[1831]\ttrain's auc: 0.834728\ttrain's binary_logloss: 0.350835\n",
      "[1832]\ttrain's auc: 0.834736\ttrain's binary_logloss: 0.350828\n",
      "[1833]\ttrain's auc: 0.834741\ttrain's binary_logloss: 0.350824\n",
      "[1834]\ttrain's auc: 0.834742\ttrain's binary_logloss: 0.350822\n",
      "[1835]\ttrain's auc: 0.834754\ttrain's binary_logloss: 0.350813\n",
      "[1836]\ttrain's auc: 0.834757\ttrain's binary_logloss: 0.350811\n",
      "[1837]\ttrain's auc: 0.834767\ttrain's binary_logloss: 0.350803\n",
      "[1838]\ttrain's auc: 0.834768\ttrain's binary_logloss: 0.350802\n",
      "[1839]\ttrain's auc: 0.834771\ttrain's binary_logloss: 0.350799\n",
      "[1840]\ttrain's auc: 0.834772\ttrain's binary_logloss: 0.350798\n",
      "[1841]\ttrain's auc: 0.83478\ttrain's binary_logloss: 0.350792\n",
      "[1842]\ttrain's auc: 0.834782\ttrain's binary_logloss: 0.350791\n",
      "[1843]\ttrain's auc: 0.834783\ttrain's binary_logloss: 0.35079\n",
      "[1844]\ttrain's auc: 0.834794\ttrain's binary_logloss: 0.350781\n",
      "[1845]\ttrain's auc: 0.834795\ttrain's binary_logloss: 0.35078\n",
      "[1846]\ttrain's auc: 0.834797\ttrain's binary_logloss: 0.350779\n",
      "[1847]\ttrain's auc: 0.834798\ttrain's binary_logloss: 0.350778\n",
      "[1848]\ttrain's auc: 0.8348\ttrain's binary_logloss: 0.350776\n",
      "[1849]\ttrain's auc: 0.834802\ttrain's binary_logloss: 0.350774\n",
      "[1850]\ttrain's auc: 0.834804\ttrain's binary_logloss: 0.350773\n",
      "[1851]\ttrain's auc: 0.834805\ttrain's binary_logloss: 0.350771\n",
      "[1852]\ttrain's auc: 0.834808\ttrain's binary_logloss: 0.35077\n",
      "[1853]\ttrain's auc: 0.834811\ttrain's binary_logloss: 0.350767\n",
      "[1854]\ttrain's auc: 0.834819\ttrain's binary_logloss: 0.35076\n",
      "[1855]\ttrain's auc: 0.83482\ttrain's binary_logloss: 0.350759\n",
      "[1856]\ttrain's auc: 0.834822\ttrain's binary_logloss: 0.350757\n",
      "[1857]\ttrain's auc: 0.834828\ttrain's binary_logloss: 0.350752\n",
      "[1858]\ttrain's auc: 0.834829\ttrain's binary_logloss: 0.350751\n",
      "[1859]\ttrain's auc: 0.834832\ttrain's binary_logloss: 0.350749\n",
      "[1860]\ttrain's auc: 0.834833\ttrain's binary_logloss: 0.350748\n",
      "[1861]\ttrain's auc: 0.834835\ttrain's binary_logloss: 0.350747\n",
      "[1862]\ttrain's auc: 0.834836\ttrain's binary_logloss: 0.350746\n",
      "[1863]\ttrain's auc: 0.834839\ttrain's binary_logloss: 0.350743\n",
      "[1864]\ttrain's auc: 0.83484\ttrain's binary_logloss: 0.350742\n",
      "[1865]\ttrain's auc: 0.834842\ttrain's binary_logloss: 0.350741\n",
      "[1866]\ttrain's auc: 0.834843\ttrain's binary_logloss: 0.350739\n",
      "[1867]\ttrain's auc: 0.834845\ttrain's binary_logloss: 0.350738\n",
      "[1868]\ttrain's auc: 0.83485\ttrain's binary_logloss: 0.350733\n",
      "[1869]\ttrain's auc: 0.834852\ttrain's binary_logloss: 0.350732\n",
      "[1870]\ttrain's auc: 0.834854\ttrain's binary_logloss: 0.350729\n",
      "[1871]\ttrain's auc: 0.834856\ttrain's binary_logloss: 0.350728\n",
      "[1872]\ttrain's auc: 0.834857\ttrain's binary_logloss: 0.350727\n",
      "[1873]\ttrain's auc: 0.834858\ttrain's binary_logloss: 0.350725\n",
      "[1874]\ttrain's auc: 0.83486\ttrain's binary_logloss: 0.350724\n",
      "[1875]\ttrain's auc: 0.834863\ttrain's binary_logloss: 0.350722\n",
      "[1876]\ttrain's auc: 0.834865\ttrain's binary_logloss: 0.35072\n",
      "[1877]\ttrain's auc: 0.83487\ttrain's binary_logloss: 0.350715\n",
      "[1878]\ttrain's auc: 0.834871\ttrain's binary_logloss: 0.350713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1879]\ttrain's auc: 0.834878\ttrain's binary_logloss: 0.350709\n",
      "[1880]\ttrain's auc: 0.834881\ttrain's binary_logloss: 0.350706\n",
      "[1881]\ttrain's auc: 0.834886\ttrain's binary_logloss: 0.350701\n",
      "[1882]\ttrain's auc: 0.834888\ttrain's binary_logloss: 0.3507\n",
      "[1883]\ttrain's auc: 0.83489\ttrain's binary_logloss: 0.350698\n",
      "[1884]\ttrain's auc: 0.834891\ttrain's binary_logloss: 0.350697\n",
      "[1885]\ttrain's auc: 0.834893\ttrain's binary_logloss: 0.350695\n",
      "[1886]\ttrain's auc: 0.834901\ttrain's binary_logloss: 0.350688\n",
      "[1887]\ttrain's auc: 0.834903\ttrain's binary_logloss: 0.350686\n",
      "[1888]\ttrain's auc: 0.834905\ttrain's binary_logloss: 0.350684\n",
      "[1889]\ttrain's auc: 0.834906\ttrain's binary_logloss: 0.350683\n",
      "[1890]\ttrain's auc: 0.834908\ttrain's binary_logloss: 0.350681\n",
      "[1891]\ttrain's auc: 0.83491\ttrain's binary_logloss: 0.35068\n",
      "[1892]\ttrain's auc: 0.834911\ttrain's binary_logloss: 0.350678\n",
      "[1893]\ttrain's auc: 0.834912\ttrain's binary_logloss: 0.350678\n",
      "[1894]\ttrain's auc: 0.834914\ttrain's binary_logloss: 0.350676\n",
      "[1895]\ttrain's auc: 0.834915\ttrain's binary_logloss: 0.350675\n",
      "[1896]\ttrain's auc: 0.834918\ttrain's binary_logloss: 0.350672\n",
      "[1897]\ttrain's auc: 0.83492\ttrain's binary_logloss: 0.35067\n",
      "[1898]\ttrain's auc: 0.83492\ttrain's binary_logloss: 0.35067\n",
      "[1899]\ttrain's auc: 0.834922\ttrain's binary_logloss: 0.350669\n",
      "[1900]\ttrain's auc: 0.834923\ttrain's binary_logloss: 0.350668\n",
      "[1901]\ttrain's auc: 0.834926\ttrain's binary_logloss: 0.350666\n",
      "[1902]\ttrain's auc: 0.834927\ttrain's binary_logloss: 0.350664\n",
      "[1903]\ttrain's auc: 0.834928\ttrain's binary_logloss: 0.350664\n",
      "[1904]\ttrain's auc: 0.834929\ttrain's binary_logloss: 0.350661\n",
      "[1905]\ttrain's auc: 0.834931\ttrain's binary_logloss: 0.35066\n",
      "[1906]\ttrain's auc: 0.834932\ttrain's binary_logloss: 0.350659\n",
      "[1907]\ttrain's auc: 0.834934\ttrain's binary_logloss: 0.350657\n",
      "[1908]\ttrain's auc: 0.834936\ttrain's binary_logloss: 0.350655\n",
      "[1909]\ttrain's auc: 0.834937\ttrain's binary_logloss: 0.350653\n",
      "[1910]\ttrain's auc: 0.834939\ttrain's binary_logloss: 0.350652\n",
      "[1911]\ttrain's auc: 0.834945\ttrain's binary_logloss: 0.350647\n",
      "[1912]\ttrain's auc: 0.834946\ttrain's binary_logloss: 0.350646\n",
      "[1913]\ttrain's auc: 0.834948\ttrain's binary_logloss: 0.350644\n",
      "[1914]\ttrain's auc: 0.834954\ttrain's binary_logloss: 0.350639\n",
      "[1915]\ttrain's auc: 0.834956\ttrain's binary_logloss: 0.350637\n",
      "[1916]\ttrain's auc: 0.834958\ttrain's binary_logloss: 0.350635\n",
      "[1917]\ttrain's auc: 0.834959\ttrain's binary_logloss: 0.350634\n",
      "[1918]\ttrain's auc: 0.83496\ttrain's binary_logloss: 0.350633\n",
      "[1919]\ttrain's auc: 0.834962\ttrain's binary_logloss: 0.350632\n",
      "[1920]\ttrain's auc: 0.834963\ttrain's binary_logloss: 0.350631\n",
      "[1921]\ttrain's auc: 0.834965\ttrain's binary_logloss: 0.350628\n",
      "[1922]\ttrain's auc: 0.834966\ttrain's binary_logloss: 0.350628\n",
      "[1923]\ttrain's auc: 0.834968\ttrain's binary_logloss: 0.350626\n",
      "[1924]\ttrain's auc: 0.834969\ttrain's binary_logloss: 0.350625\n",
      "[1925]\ttrain's auc: 0.834971\ttrain's binary_logloss: 0.350623\n",
      "[1926]\ttrain's auc: 0.834973\ttrain's binary_logloss: 0.350622\n",
      "[1927]\ttrain's auc: 0.834975\ttrain's binary_logloss: 0.35062\n",
      "[1928]\ttrain's auc: 0.834977\ttrain's binary_logloss: 0.350618\n",
      "[1929]\ttrain's auc: 0.834978\ttrain's binary_logloss: 0.350617\n",
      "[1930]\ttrain's auc: 0.834979\ttrain's binary_logloss: 0.350616\n",
      "[1931]\ttrain's auc: 0.83498\ttrain's binary_logloss: 0.350615\n",
      "[1932]\ttrain's auc: 0.834981\ttrain's binary_logloss: 0.350613\n",
      "[1933]\ttrain's auc: 0.834982\ttrain's binary_logloss: 0.350612\n",
      "[1934]\ttrain's auc: 0.834984\ttrain's binary_logloss: 0.350611\n",
      "[1935]\ttrain's auc: 0.834987\ttrain's binary_logloss: 0.350609\n",
      "[1936]\ttrain's auc: 0.834988\ttrain's binary_logloss: 0.350607\n",
      "[1937]\ttrain's auc: 0.83499\ttrain's binary_logloss: 0.350605\n",
      "[1938]\ttrain's auc: 0.834994\ttrain's binary_logloss: 0.350602\n",
      "[1939]\ttrain's auc: 0.834996\ttrain's binary_logloss: 0.350601\n",
      "[1940]\ttrain's auc: 0.834997\ttrain's binary_logloss: 0.3506\n",
      "[1941]\ttrain's auc: 0.834998\ttrain's binary_logloss: 0.350598\n",
      "[1942]\ttrain's auc: 0.835\ttrain's binary_logloss: 0.350596\n",
      "[1943]\ttrain's auc: 0.835002\ttrain's binary_logloss: 0.350594\n",
      "[1944]\ttrain's auc: 0.835003\ttrain's binary_logloss: 0.350594\n",
      "[1945]\ttrain's auc: 0.835006\ttrain's binary_logloss: 0.350592\n",
      "[1946]\ttrain's auc: 0.835011\ttrain's binary_logloss: 0.350587\n",
      "[1947]\ttrain's auc: 0.835013\ttrain's binary_logloss: 0.350585\n",
      "[1948]\ttrain's auc: 0.835017\ttrain's binary_logloss: 0.350581\n",
      "[1949]\ttrain's auc: 0.835018\ttrain's binary_logloss: 0.35058\n",
      "[1950]\ttrain's auc: 0.835024\ttrain's binary_logloss: 0.350575\n",
      "[1951]\ttrain's auc: 0.835026\ttrain's binary_logloss: 0.350573\n",
      "[1952]\ttrain's auc: 0.835028\ttrain's binary_logloss: 0.350572\n",
      "[1953]\ttrain's auc: 0.83503\ttrain's binary_logloss: 0.35057\n",
      "[1954]\ttrain's auc: 0.835031\ttrain's binary_logloss: 0.350569\n",
      "[1955]\ttrain's auc: 0.835032\ttrain's binary_logloss: 0.350568\n",
      "[1956]\ttrain's auc: 0.835034\ttrain's binary_logloss: 0.350566\n",
      "[1957]\ttrain's auc: 0.835036\ttrain's binary_logloss: 0.350565\n",
      "[1958]\ttrain's auc: 0.835037\ttrain's binary_logloss: 0.350563\n",
      "[1959]\ttrain's auc: 0.835038\ttrain's binary_logloss: 0.350562\n",
      "[1960]\ttrain's auc: 0.83504\ttrain's binary_logloss: 0.350561\n",
      "[1961]\ttrain's auc: 0.835042\ttrain's binary_logloss: 0.350559\n",
      "[1962]\ttrain's auc: 0.835043\ttrain's binary_logloss: 0.350558\n",
      "[1963]\ttrain's auc: 0.835044\ttrain's binary_logloss: 0.350557\n",
      "[1964]\ttrain's auc: 0.835046\ttrain's binary_logloss: 0.350555\n",
      "[1965]\ttrain's auc: 0.835048\ttrain's binary_logloss: 0.350553\n",
      "[1966]\ttrain's auc: 0.83505\ttrain's binary_logloss: 0.350552\n",
      "[1967]\ttrain's auc: 0.835055\ttrain's binary_logloss: 0.350547\n",
      "[1968]\ttrain's auc: 0.835058\ttrain's binary_logloss: 0.350545\n",
      "[1969]\ttrain's auc: 0.835065\ttrain's binary_logloss: 0.350539\n",
      "[1970]\ttrain's auc: 0.835067\ttrain's binary_logloss: 0.350537\n",
      "[1971]\ttrain's auc: 0.835071\ttrain's binary_logloss: 0.350534\n",
      "[1972]\ttrain's auc: 0.835073\ttrain's binary_logloss: 0.350532\n",
      "[1973]\ttrain's auc: 0.835074\ttrain's binary_logloss: 0.350531\n",
      "[1974]\ttrain's auc: 0.835076\ttrain's binary_logloss: 0.35053\n",
      "[1975]\ttrain's auc: 0.835078\ttrain's binary_logloss: 0.350528\n",
      "[1976]\ttrain's auc: 0.835079\ttrain's binary_logloss: 0.350527\n",
      "[1977]\ttrain's auc: 0.835081\ttrain's binary_logloss: 0.350525\n",
      "[1978]\ttrain's auc: 0.835082\ttrain's binary_logloss: 0.350524\n",
      "[1979]\ttrain's auc: 0.835083\ttrain's binary_logloss: 0.350523\n",
      "[1980]\ttrain's auc: 0.835088\ttrain's binary_logloss: 0.35052\n",
      "[1981]\ttrain's auc: 0.83509\ttrain's binary_logloss: 0.350518\n",
      "[1982]\ttrain's auc: 0.835092\ttrain's binary_logloss: 0.350516\n",
      "[1983]\ttrain's auc: 0.835093\ttrain's binary_logloss: 0.350515\n",
      "[1984]\ttrain's auc: 0.835095\ttrain's binary_logloss: 0.350513\n",
      "[1985]\ttrain's auc: 0.835096\ttrain's binary_logloss: 0.350513\n",
      "[1986]\ttrain's auc: 0.835097\ttrain's binary_logloss: 0.350512\n",
      "[1987]\ttrain's auc: 0.835098\ttrain's binary_logloss: 0.35051\n",
      "[1988]\ttrain's auc: 0.8351\ttrain's binary_logloss: 0.350509\n",
      "[1989]\ttrain's auc: 0.835101\ttrain's binary_logloss: 0.350508\n",
      "[1990]\ttrain's auc: 0.835103\ttrain's binary_logloss: 0.350507\n",
      "[1991]\ttrain's auc: 0.835104\ttrain's binary_logloss: 0.350505\n",
      "[1992]\ttrain's auc: 0.835106\ttrain's binary_logloss: 0.350504\n",
      "[1993]\ttrain's auc: 0.835111\ttrain's binary_logloss: 0.350499\n",
      "[1994]\ttrain's auc: 0.835115\ttrain's binary_logloss: 0.350496\n",
      "[1995]\ttrain's auc: 0.835117\ttrain's binary_logloss: 0.350495\n",
      "[1996]\ttrain's auc: 0.835119\ttrain's binary_logloss: 0.350493\n",
      "[1997]\ttrain's auc: 0.83512\ttrain's binary_logloss: 0.350491\n",
      "[1998]\ttrain's auc: 0.835123\ttrain's binary_logloss: 0.35049\n",
      "[1999]\ttrain's auc: 0.835125\ttrain's binary_logloss: 0.350487\n",
      "[2000]\ttrain's auc: 0.835126\ttrain's binary_logloss: 0.350486\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's auc: 0.835126\ttrain's binary_logloss: 0.350486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1,\n",
       "               importance_type='split', learning_rate=0.01, max_bin=425,\n",
       "               max_depth=-1, min_child_samples=10, min_child_weight=5,\n",
       "               min_split_gain=0, n_estimators=2000, n_jobs=-1, num_leaves=64,\n",
       "               objective='binary', random_state=None, reg_alpha=3, reg_lambda=5,\n",
       "               seed=1000, silent=True, subsample=0.8, subsample_for_bin=50000,\n",
       "               subsample_freq=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb.fit(train_x, train_y, \n",
    "                  eval_names=['train'],\n",
    "                  eval_metric=['logloss','auc'],\n",
    "                  eval_set=[(train_x, train_y)],\n",
    "                  early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f563b2fbad0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存分类器\n",
    "model_lgb.booster_.save_model('%s/lgbmodel_112010.txt' % STORAGE_DIR)  # 存入模型\n",
    "# lgmodel = lgb.Booster(model_file='%s/lgbmodel_112010.txt' % STORAGE_DIR)  # 读出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01563778, 0.00134601, 0.01341078, ..., 0.01722789, 0.02916311,\n",
       "       0.00342512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_lgb.predict_proba(test_x)[:, 1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zengrui/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "q_id                  Q1493039281\n",
       "u_id                    M64135255\n",
       "do_answer               0.0156378\n",
       "follow_topic_hit        -0.438017\n",
       "interest_topic_hit        1.37349\n",
       "bin_feat_a                -1.4043\n",
       "salt                    -0.490024\n",
       "u_answer                -0.400849\n",
       "u_image_answer            4.64295\n",
       "u_video_answer          -0.103026\n",
       "u_word_avg                3.14211\n",
       "q_answer                -0.204937\n",
       "q_good_answer          -0.0647244\n",
       "q_image_answer          -0.153848\n",
       "q_video_answer         -0.0639039\n",
       "q_word_avg              -0.437234\n",
       "q_like                 -0.0547829\n",
       "q_comment              -0.0742448\n",
       "q_collect              -0.0288203\n",
       "q_thanks               -0.0442414\n",
       "sex                             2\n",
       "access_freq                     4\n",
       "multi_feat_a                 1092\n",
       "multi_feat_b                  115\n",
       "multi_feat_c                  187\n",
       "multi_feat_d                 1193\n",
       "multi_feat_e                    1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = data[data['do_answer'] == -1]\n",
    "result.loc[:, 'do_answer'] = y_pred\n",
    "result.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "invite_info_evaluate = pd.read_csv('invite_info_evaluate_1_0926.txt', \n",
    "                                   header=None, sep='\\t')\n",
    "invite_info_evaluate.columns = ['q_id1', 'u_id1', 'invite_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1141683"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_out = pd.concat([result[['q_id', 'u_id', 'do_answer']], invite_info_evaluate],\n",
    "                       axis=1)\n",
    "len(result_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_out[['q_id', 'u_id', 'invite_time', \n",
    "        'do_answer']].to_csv(RESULT_DIR_OUT, index=False, header=False, sep='\\t')  # 导出数据\n",
    "\n",
    "'ok'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 导出 test 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q_id                  Q2590286630\n",
       "u_id                  M3168697168\n",
       "do_answer                      -1\n",
       "follow_topic_hit        -0.438017\n",
       "interest_topic_hit      -0.274834\n",
       "bin_feat_a                 0.7121\n",
       "salt                      1.73948\n",
       "u_answer                 -0.27225\n",
       "u_image_answer            1.61585\n",
       "u_video_answer          -0.103026\n",
       "u_word_avg                1.47854\n",
       "q_answer                -0.204937\n",
       "q_good_answer          -0.0647244\n",
       "q_image_answer          -0.153848\n",
       "q_video_answer         -0.0639039\n",
       "q_word_avg              -0.437234\n",
       "q_like                 -0.0547829\n",
       "q_comment              -0.0742448\n",
       "q_collect              -0.0288203\n",
       "q_thanks               -0.0442414\n",
       "sex                             1\n",
       "access_freq                     0\n",
       "multi_feat_a                 1092\n",
       "multi_feat_b                  115\n",
       "multi_feat_c                    6\n",
       "multi_feat_d                  980\n",
       "multi_feat_e                    1\n",
       "Name: 1141682, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = data[data['do_answer'] == -1]\n",
    "result.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  4.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# from my_model import MyNet_v2_2\n",
    "\n",
    "net = MyNet_v2(len(good_col_list + other_col_list)).to(DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    net.load_state_dict(torch.load(PKL_DIR_READ))\n",
    "else:\n",
    "    net.load_state_dict(torch.load(PKL_DIR_READ, map_location='cpu'))\n",
    "net.eval()\n",
    "\n",
    "res_list = []\n",
    "with tqdm(total=test_len) as pbar:\n",
    "    for step, (bx, by) in enumerate(data_loader['test']):\n",
    "        bx = bx.float().to(DEVICE)\n",
    "        by = by.long().to(DEVICE)\n",
    "        \n",
    "        prediction = net(bx)\n",
    "        \n",
    "        # 计算结果\n",
    "        pre = torch.argmax(torch.softmax(prediction, dim=1), dim=1)\n",
    "        res_list.extend(pre.cpu().numpy())\n",
    "        pbar.update(1)\n",
    "        \n",
    "result.loc[:, 'do_answer'] = res_list\n",
    "result[['do_answer']] = result[['do_answer']].astype(int)  # 数据类型转换为int\n",
    "\n",
    "'ok'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "invite_info_evaluate = pd.read_csv('invite_info_evaluate_1_0926.txt', \n",
    "                                   header=None, sep='\\t')\n",
    "invite_info_evaluate.columns = ['q_id1', 'u_id1', 'invite_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1141683"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_out = pd.concat([result[['q_id', 'u_id', 'do_answer']], invite_info_evaluate],\n",
    "                       axis=1)\n",
    "len(result_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_out[['q_id', 'u_id', 'invite_time', \n",
    "        'do_answer']].to_csv(RESULT_DIR_OUT, index=False, header=False, sep='\\t')  # 导出数据\n",
    "\n",
    "'ok'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
